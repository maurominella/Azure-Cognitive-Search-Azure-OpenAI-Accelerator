{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7813d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect constants\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials_my.env\")\n",
    "\n",
    "# Text-based Indexes that we are going to query (from Notebook 01 and 02)\n",
    "index   = \"projection-index2\"\n",
    "\n",
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"]    = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"]     = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"]    = os.environ[\"OPENAI_API_TYPE\"]\n",
    "MODEL                            = os.environ[\"COMPLETION432_DEPLOYMENT\"]\n",
    "COMPLETION_TOKENS                = 1000\n",
    "\n",
    "top_search_vector_k              = 5\n",
    "\n",
    "# the question to ask - enable just one\n",
    "# QUESTION = \"Tell me briefly what are the advantages of defining compositionality using MDL.\"\n",
    "# QUESTION = \"What is a meaning function?\"\n",
    "QUESTION = \"Why is von Neumann is considered as one of fathers of modern computers?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Search query\n",
    "\n",
    "import requests, json\n",
    "\n",
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params  = {'api-version': os.environ['AZURE_SEARCH_API_VERSION_NEW']} # NEW VERSION!!!\n",
    "\n",
    "# search query payload\n",
    "search_payload = {\n",
    "  \"count\": \"true\",\n",
    "  \"speller\": \"lexicon\",\n",
    "  \"queryLanguage\": \"en-us\",\n",
    "\n",
    "  \"top\": top_search_vector_k,\n",
    "  \"select\": \"id, name, title, location, chunk\",\n",
    "  \"vectorQueries\": [\n",
    "    {\n",
    "      \"kind\": \"text\",\n",
    "      \"k\": top_search_vector_k,\n",
    "      \"fields\": \"chunkVector\",\n",
    "      \"text\": QUESTION\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index + \"/docs/search\",\n",
    "                     data=json.dumps(search_payload), headers=headers, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a62220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Azure AI Search results as an ordered dictionary\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "ordered_results = OrderedDict()\n",
    "\n",
    "for result in r.json()['value']:\n",
    "    if result['@search.score'] > 0.25:# Show answers that are at least 25% of the max possible score=1\n",
    "        ordered_results[result['id']]={\n",
    "            \"title\": result['title'],\n",
    "            \"name\": result['name'],\n",
    "            \"location\": result['location'],\n",
    "            \"index\": index,\n",
    "            \"chunk\": result['chunk'],\n",
    "            \"score\": result['@search.score']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the ordered dictionary, build the \"Documents\" array, needed by langchain \"qa_with_sources\" chain\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] + os.environ['BLOB_SAS_TOKEN'] # to create \"citations\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938557c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Open AI deployment\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cf63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the specific answer from the Documents array, using Open AI through Langchain\n",
    "\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "# Choose either \"stuff\" or \"map_reduce\", depending on how long the text is. Leave just one uncommented:\n",
    "chain_type = \"stuff\" # the LLM is able to manage the promtp + request + response in a single call\n",
    "# chain_type = \"map_reduce\" # the LLM needs to split the promtp + request in multiple calls\n",
    "\n",
    "if chain_type == \"stuff\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type)\n",
    "elif chain_type == \"map_reduce\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, return_intermediate_steps=True)\n",
    "    \n",
    "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"English\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final result, including the citation(s)\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "if chain_type == \"map_reduce\":\n",
    "    for step in response['intermediate_steps']:\n",
    "        display(HTML(\"<b>Chunk Summary:</b> \" + step))\n",
    "\n",
    "display(HTML(f\"<br/><br/><b>FINAL ANSWER with --{chain_type}-- chain type:</b>\"))\n",
    "display(Markdown(response['output_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Search query\n",
    "\n",
    "import requests, json\n",
    "\n",
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_OPENAI_API_KEY']}\n",
    "params  = {'api-version': '2023-12-01-preview'}\n",
    "\n",
    "# search query payload\n",
    "search_payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": QUESTION\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1.0,    \n",
    "    \"max_tokens\": 1000,\n",
    "    \"dataSources\": [\n",
    "        {            \n",
    "            \"type\": \"AzureCognitiveSearch\",\n",
    "            \"parameters\": {                \n",
    "                \"endpoint\": os.environ['AZURE_SEARCH_ENDPOINT'],\n",
    "                \"key\": os.environ['AZURE_SEARCH_KEY'],\n",
    "                \"indexName\": index\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "r = requests.post(\n",
    "    f\"{os.environ['AZURE_OPENAI_ENDPOINT']}openai/deployments/{MODEL}/extensions/chat/completions\",\n",
    "    data=json.dumps(search_payload), headers=headers, params=params\n",
    ")\n",
    "\n",
    "print(r.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivbd_20231215",
   "language": "python",
   "name": "openaivbd_20231215"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
