{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb",
   "metadata": {},
   "source": [
    "# Understanding Memory in LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292",
   "metadata": {},
   "source": [
    "In the previous Notebook, we successfully explored how OpenAI models can enhance the results from Azure Cognitive Search. \n",
    "\n",
    "However, we have yet to discover how to engage in a conversation with the LLM. With [Bing Chat](http://chat.bing.com/), for example, this is possible, as it can understand and reference the previous responses.\n",
    "\n",
    "There is a common misconception that GPT models have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
    "\n",
    "In this Notebook, our goal is to illustrate how we can effectively \"endow the LLM with memory\" by employing prompts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733c782e-204c-47d0-8dae-c9df7091ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from openai.error import OpenAIError\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import CosmosDBChatMessageHistory\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    update_vector_indexes,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    num_tokens_from_string,\n",
    "    get_answer,\n",
    ")\n",
    "\n",
    "from common.prompts import COMBINE_CHAT_PROMPT_TEMPLATE\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials (my).env\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to a higher level to ignore INFO messages\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"]    = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"]     = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"]    = os.environ[\"OPENAI_API_TYPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc72b22-11c2-4df0-91b8-033d01829663",
   "metadata": {},
   "source": [
    "### Let's start with the basics\n",
    "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me some use cases for reinforcement learning?\"\n",
    "FOLLOW_UP_QUESTION = \"Give me the main points of our conversation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "MODEL = os.environ[\"COMPLETION3516_DEPLOYMENT\"] # we DO have chatgpt-4, but not needed in this case\n",
    "COMPLETION_TOKENS = 500\n",
    "# Create an OpenAI instance\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a very simple prompt template, just the question as is:\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"{question}\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has numerous use cases across various domains. Here are some examples:\n",
       "\n",
       "1. Game playing: Reinforcement learning has been successfully used to train agents to play complex games such as chess, Go, and poker. AlphaGo, a famous example, defeated world champion Go player Lee Sedol.\n",
       "\n",
       "2. Robotics: Reinforcement learning enables robots to learn complex tasks such as grasping objects, walking, and navigation in dynamic environments.\n",
       "\n",
       "3. Autonomous vehicles: Reinforcement learning can be used to train self-driving cars to make decisions in real-time, such as lane changing, merging, and handling complex traffic scenarios.\n",
       "\n",
       "4. Recommendation systems: Reinforcement learning can be utilized to optimize personalized recommendations for users based on their preferences and historical data.\n",
       "\n",
       "5. Finance: Reinforcement learning can be applied to algorithmic trading, portfolio management, and risk assessment, where agents learn to make optimal decisions in dynamic market environments.\n",
       "\n",
       "6. Healthcare: Reinforcement learning can assist in optimizing treatment plans, drug dosage determination, and disease diagnosis by learning from patient data and medical records.\n",
       "\n",
       "7. Energy management: Reinforcement learning can optimize energy consumption in smart grids, demand response, and energy-efficient systems by learning to make decisions that minimize costs and maximize efficiency.\n",
       "\n",
       "8. Resource allocation: Reinforcement learning can be used to optimize resource allocation in various scenarios, such as scheduling tasks in cloud computing, optimizing network routing, and managing inventory in supply chains.\n",
       "\n",
       "9. Advertising: Reinforcement learning can be employed to optimize online advertising strategies, such as selecting the most effective ads and determining bidding strategies to maximize conversions.\n",
       "\n",
       "10. Education: Reinforcement learning can be used to design intelligent tutoring systems that adapt to individual students' learning styles and provide personalized recommendations for effective learning.\n",
       "\n",
       "These are just a few examples, and reinforcement learning has potential applications in many other domains where decision-making in dynamic environments is involved."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the GPT model responds\n",
    "response = chain.run(QUESTION)\n",
    "printmd(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI language model, I do not have the ability to recall previous conversations or access any information about them. Each interaction with me is treated as a separate and independent conversation. Is there anything specific you would like to discuss or ask about?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's ask a follow up question\n",
    "chain.run(FOLLOW_UP_QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As you can see, it doesn't remember what it just responded, sometimes it responds based only on the system prompt, or just randomly. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "hist_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "                {history}\n",
    "                Human: {question}\n",
    "                AI:\n",
    "            \"\"\"\n",
    "    )\n",
    "chain = LLMChain(llm=llm, prompt=hist_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d088e51-e5eb-4143-b87d-b2be429eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = \"\"\"\n",
    "Human: {question}\n",
    "AI: {response}\n",
    "\"\"\".format(question=QUESTION, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Reinforcement learning has numerous use cases across various domains.\n",
       "- Some examples include game playing, robotics, autonomous vehicles, recommendation systems, finance, healthcare, energy management, resource allocation, advertising, and education.\n",
       "- Reinforcement learning can be used to train agents to play complex games, enable robots to learn complex tasks, train self-driving cars, optimize personalized recommendations, assist in finance and healthcare decision-making, optimize energy consumption, optimize resource allocation, optimize online advertising strategies, and design intelligent tutoring systems.\n",
       "- These are just a few examples, and reinforcement learning has potential applications in many other domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(chain.run({\"history\": conversation_history, \"question\": FOLLOW_UP_QUESTION}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e5af6-55d6-4353-b3f6-3275c95db00a",
   "metadata": {},
   "source": [
    "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3",
   "metadata": {},
   "source": [
    "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba257e86-fd90-4a51-a72d-27000913e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Memory adds tokens to the prompt, we would need a better model that allows more space on the prompt\n",
    "COMPLETION_TOKENS = 1000\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)\n",
    "embedder = OpenAIEmbeddings(deployment=os.environ[\"EMBEDDING_DEPLOYMENT\"], chunk_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9f459b-e8b8-40b9-a94d-80c079968594",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name    = \"cogsrch-index-files\"\n",
    "index2_name    = \"cogsrch-index-csv\"\n",
    "index3_name    = \"cogsrch-index-books-vector\"\n",
    "text_indexes   = [index1_name, index2_name]\n",
    "vector_indexes = [index+\"-vector\" for index in text_indexes] + [index3_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b01852c2-6192-496c-adff-4270f9380469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 5\n",
      "CPU times: total: 203 ms\n",
      "Wall time: 4.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Search in text-based indexes first and update vector indexes\n",
    "k=10 # Top k results per each text-based index\n",
    "ordered_results = get_search_results(QUESTION, text_indexes, k=k, reranker_threshold=1, vector_search=False)\n",
    "update_vector_indexes(ordered_search_results=ordered_results, embedder=embedder)\n",
    "\n",
    "# Search in all vector-based indexes available\n",
    "similarity_k = 5 # top results from multi-vector-index similarity search\n",
    "ordered_results = get_search_results(QUESTION, vector_indexes, k=k, vector_search=True,\n",
    "                                        similarity_k=similarity_k,\n",
    "                                        query_vector = embedder.embed_query(QUESTION))\n",
    "\n",
    "print(\"Number of results:\", len(ordered_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca500dd8-148c-4d8a-b58b-2df4c957459d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('aHR0cHM6Ly9ibG9ic3RvcmFnZWx3YmFzbnM3bHMzdHkuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDA4djIucGRm0_12',\n",
       "              {'title': 'arXiv:cs/0001008v2  [cs.MA]  17 Jan 2000_chunk_12',\n",
       "               'name': '0001008v2.pdf',\n",
       "               'location': 'https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf',\n",
       "               'caption': 'Matarić [1995] has studied reinforcement learning in multi-robot domains. She notes, for example, how learning can give rise to social behaviors (Matarić [1997]). The work shows how robots can be individually programmed to pro- duce certain group behaviors.',\n",
       "               'index': 'cogsrch-index-files-vector',\n",
       "               'chunk': 'predictive strategies, such as “if the state of the world was x ten time units\\nbefore, then it will be x next time so take action a”. The authors later show\\nhow learning can be used to eliminate these chaotic global fluctuations.\\n\\nMatarić [1995] has studied reinforcement learning in multi-robot domains.\\nShe notes, for example, how learning can give rise to social behaviors (Matarić\\n[1997]). The work shows how robots can be individually programmed to pro-\\nduce certain group behaviors. It represents a good example of the usefulness\\nand flexibility of learning agents in multi-agent domains. However, the author\\ndoes not offer a mathematical justification for the chosen individual learning\\nalgorithms, nor does she explain why the agents were able to converge to the\\nglobal behaviors. Our research hopes to provide the first steps in this direction.\\n\\nOne particularly interesting approach is taken by Carmel and Markovitch\\n[1997]. They work on model-based learning, that is, agents build models of other\\nagents via observations. They use models based on finite state machines. The\\nauthors show how some of these models can be effectively learned via observation\\nof the other agent’s actions. The authors concentrate on the development of\\nlearning algorithms that would let one agent learn a finite-state machine model\\nof another agent. They have not considered the case where two or more agents\\nare simultaneously learning about each other, which we study in this article.\\nHowever, their work is more general in the sense that they model agents as\\nstate machines, rather than the state-action pairs we use.\\n\\nFinally, a lot of experimental work has been done in the area of agents learn-\\ning about agents (Sen [1996], Weiß [1997]). For example, Sen and Sekaran [1998]\\nshow how learning agents in simple MAS converge to system-wide optimal be-\\nhavior. Their agents use Q-learning or modified classifier systems in order to\\nlearn. The authors implement these agents and compare the performance of the\\ndifferent learning algorithms for developing agent coordination. Hu and Well-\\nman [1998b, 1996] have studied reinforcement learning in market-base MASs,\\nshowing how certain initial learning biases can be self-fulfilling, and how learn-\\ning can be useful but is affected by an agent’s models of other agents. Claus\\nand Boutilier [1997] have also carried out experimental studies of the behavior of\\nreinforcement learning agents. We have been able to use the CLRI framework\\nto predict some of their experimental results Vidal [1998]. Other researchers\\nsuch as Stone and Veloso [1999], Littman [1994], and Hu and Wellman [1998a]\\nhave extended the basic Q-learning Watkins and Dayan [1992] algorithm for use\\nwith MASs in an effort to either improve or prove convergence to the optimal\\nbehavior.\\n\\nWe have also successfully experimented with reinforcement learning simu-\\nlations (Vidal and Durfee [1998]), but we believe that the formal treatment\\nelucidated in these pages will shed more light into the real nature of the prob-\\nlem and the relative importance of the various parameters that describe the\\n\\n25\\n\\n\\n\\ncapabilities of an agent’s learning algorithm.\\n\\n11 Summary\\n\\nWe have presented a framework for studying and predicting the behavior of\\nMASs composed of learning agents. We believe that this framework captures the\\nmost important parameters that describe an agents’ learning and the system’s\\nrules of encounter. Various comparisons between the framework’s predictions\\nand experimental results were given. These comparisons showed that the theo-\\nretical predictions closely match our experimental results and the experimental\\nresults published by others. Our success in reproducing these results allows us\\nto confidently state the effectiveness and accuracy of our theory in predicting\\nthe expected error of machine learning agents in MASs.\\n\\nSince our theory describes an agent’s behavior at a high-level (i.e., the agent’s\\nerror), it is not capable of making system-specific predictions (e.g., predicting\\nthe particular actions that are favored). These types of system-specific predic-\\ntions can only be arrived at by the traditional method of implementing popula-\\ntions of such agents and testing their behaviors. However, we expect that there\\nwill be times when the predictions from our theory will be enough to answer a\\ndesigner’s questions. A MAS designer that only needs to determine how “good”\\nthe agent’s behavior will be could probably use the CLRI framework. A de-\\nsigner that needs to know which particular emergent behaviors will be favored\\nby his agents will need to implement the agents.\\n\\nFinally, while we have given some examples as to how learning rates can be\\ndetermined for particular machine learning implementations, we do not have\\nany general method for determining these rates. However, we showed how to\\nuse the sample complexity of a learning problem to determine a lower bound on\\nthe learning rate of a consistent learning agent. This bound is useful for quickly\\n',\n",
       "               'score': 0.03279569745063782}),\n",
       "             ('z4cagypm_0',\n",
       "              {'title': 'Deep reinforcement learning for large-scale epidemic control_chunk_0',\n",
       "               'name': 'metadata_FULL.csv',\n",
       "               'location': 'https://arxiv.org/pdf/2003.13676v1.pdf',\n",
       "               'caption': 'This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies..\\x00',\n",
       "               'index': 'cogsrch-index-csv-vector',\n",
       "               'chunk': \"Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.\",\n",
       "               'score': 0.03253968432545662}),\n",
       "             ('aHR0cHM6Ly9ibG9ic3RvcmFnZWx3YmFzbnM3bHMzdHkuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDA4djMucGRm0_12',\n",
       "              {'title': 'Predicting the Expected Behavior of Agents that Learn About Agents: The CLRI Framework_chunk_12',\n",
       "               'name': '0001008v3.pdf',\n",
       "               'location': 'https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf',\n",
       "               'caption': '1. The values of ci, li, ri, and Iij cannot, in all situations, be mathematically determined from the system’s description. We have found that bounds for the ci, li, and ri values can often be determined when using reinforcement learning or supervised learning. However, the bounds are often very loose. .\\x00',\n",
       "               'index': 'cogsrch-index-files-vector',\n",
       "               'chunk': 'partially relevant to our work. Our emphasis is on finding ways to predict the\\nbehavior of MASs composed of machine-learning agents. We are only concerned\\nwith the behavior of simpler artificial programmable agents, rather than the\\ncomplex behavior of humans or the unpredictable behavior of animals.\\n\\nThe dynamics of MASs have also been studied by Kephart et. al. [18]. In\\nthis work the authors show how simple predictive agents can lead to globally\\ncyclic or chaotic behaviors. As the authors explain, the chaotic behaviors were a\\nresult of the simple predictive strategies used by the agents. Unlike our agents,\\nmost of their agents are not engaged in learning, instead they use simple fixed\\npredictive strategies, such as “if the state of the world was x ten time units\\nbefore, then it will be x next time so take action a”. The authors later show\\nhow learning can be used to eliminate these chaotic global fluctuations.\\n\\nMatarić [22] has studied reinforcement learning in multi-robot domains. She\\nnotes, for example, how learning can give rise to social behaviors [23]. The\\nwork shows how robots can be individually programmed to produce certain\\ngroup behaviors. It represents a good example of the usefulness and flexibility\\nof learning agents in multi-agent domains. However, the author does not offer\\na mathematical justification for the chosen individual learning algorithms, nor\\ndoes she explain why the agents were able to converge to the global behaviors.\\nOur research hopes to provide the first steps in this direction.\\n\\nOne particularly interesting approach is taken by Carmel and Markovitch\\n[4]. They work on model-based learning, that is, agents build models of other\\nagents via observations. They use models based on finite state machines. The\\nauthors show how some of these models can be effectively learned via observation\\nof the other agent’s actions. The authors concentrate on the development of\\nlearning algorithms that would let one agent learn a finite-state machine model\\nof another agent. They have not considered the case where two or more agents\\nare simultaneously learning about each other, which we study in this article.\\nHowever, their work is more general in the sense that they model agents as\\nstate machines, rather than the state-action pairs we use.\\n\\nFinally, a lot of experimental work has been done in the area of agents\\nlearning about agents [27, 36]. For example, Sen and Sekaran [28] show how\\nlearning agents in simple MAS converge to system-wide optimal behavior. Their\\nagents use Q-learning or modified classifier systems in order to learn. The\\nauthors implement these agents and compare the performance of the different\\nlearning algorithms for developing agent coordination. Hu and Wellman [14, 12]\\nhave studied reinforcement learning in market-base MASs, showing how certain\\ninitial learning biases can be self-fulfilling, and how learning can be useful but\\nis affected by an agent’s models of other agents. Claus and Boutilier [6] have\\nalso carried out experimental studies of the behavior of reinforcement learning\\nagents. We have been able to use the CLRI framework to predict some of their\\nexperimental results [33]. Other researchers [32, 20, 13] have extended the basic\\nQ-learning [35] algorithm for use with MASs in an effort to either improve or\\n\\n25\\n\\n\\n\\nprove convergence to the optimal behavior.\\nWe have also successfully experimented with reinforcement learning simula-\\n\\ntions [34], but we believe that the formal treatment elucidated in these pages\\nwill shed more light into the real nature of the problem and the relative im-\\nportance of the various parameters that describe the capabilities of an agent’s\\nlearning algorithm.\\n\\n11 Limitations and Future Work\\n\\nThe CLRI framework places some constraints on the type of systems it can\\nmodel, which limits its usability. However, it is important to understand that,\\nas we remove the limitations from the CLRI framework, the dynamics of the\\nsystem become much harder to predict. In the extreme, without any limitations\\non the agents’ abilities, the system becomes a complex adaptive system, as\\nstudied by Holland [11] and others in the field of complexity. The dynamic\\nbehavior of these systems continues to be studied by complexity researchers\\nwith only modest progress. It is only by placing limitations on the system that\\nwe were able to predict the expected error of agents in the systems modeled by\\nthe CLRI framework.\\n\\nOur ongoing work involves the relaxation of some of the constraints made by\\nthe CLRI framework so that it may become more easily and widely applicable,\\nwithout making the system dynamics impossible to analyze. We are targeting\\nthree specific constraints.\\n\\n1. The values of ci, li, ri, and Iij cannot, in all situations, be mathematically\\ndetermined from the system’s description. We have found that bounds for\\nthe ci, li, and ri values can often be determined when using reinforcement\\nlearning or supervised learning. However, the bounds are often very loose.\\n',\n",
       "               'score': 0.032522473484277725}),\n",
       "             ('3s3vfgb1_0',\n",
       "              {'title': 'Optimising Lockdown Policies for Epidemic Control using Reinforcement Learning_chunk_0',\n",
       "               'name': 'metadata_FULL.csv',\n",
       "               'location': 'https://arxiv.org/pdf/2003.14093v2.pdf',\n",
       "               'caption': 'Furthermore, these policies are learnt automatically by the proposed algorithm, as a function of disease parameters (infectiousness, gestation period, duration of symptoms, probability of death) and population characteristics (density, movement propensity).',\n",
       "               'index': 'cogsrch-index-csv-vector',\n",
       "               'chunk': 'In the context of the ongoing Covid-19 pandemic, several reports and studies have attempted to model and predict the spread of the disease. There is also intense debate about policies for limiting the damage, both to health and to the economy. On the one hand, the health and safety of the population is the principal consideration for most countries. On the other hand, we cannot ignore the potential for long-term economic damage caused by strict nation-wide lockdowns. In this working paper, we present a quantitative way to compute lockdown decisions for individual cities or regions, while balancing health and economic considerations. Furthermore, these policies are learnt automatically by the proposed algorithm, as a function of disease parameters (infectiousness, gestation period, duration of symptoms, probability of death) and population characteristics (density, movement propensity). We account for realistic considerations such as imperfect lockdowns, and show that the policy obtained using reinforcement learning is a viable quantitative approach towards lockdowns.',\n",
       "               'score': 0.03181818127632141}),\n",
       "             ('8gaeosyr_0',\n",
       "              {'title': 'A Hybrid Recommendation for Music Based on Reinforcement Learning_chunk_0',\n",
       "               'name': 'metadata_FULL.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/',\n",
       "               'caption': 'In this paper, we propose a personalized hybrid recommendation algorithm for music based on reinforcement learning (PHRR) to recommend song sequences that match listeners’ preferences better. We firstly use weighted matrix factorization (WMF) and convolutional neural network (CNN) to learn and extract the song feature vectors.',\n",
       "               'index': 'cogsrch-index-csv-vector',\n",
       "               'chunk': 'The key to personalized recommendation system is the prediction of users’ preferences. However, almost all existing music recommendation approaches only learn listeners’ preferences based on their historical records or explicit feedback, without considering the simulation of interaction process which can capture the minor changes of listeners’ preferences sensitively. In this paper, we propose a personalized hybrid recommendation algorithm for music based on reinforcement learning (PHRR) to recommend song sequences that match listeners’ preferences better. We firstly use weighted matrix factorization (WMF) and convolutional neural network (CNN) to learn and extract the song feature vectors. In order to capture the changes of listeners’ preferences sensitively, we innovatively enhance simulating interaction process of listeners and update the model continuously based on their preferences both for songs and song transitions. The extensive experiments on real-world datasets validate the effectiveness of the proposed PHRR on song sequence recommendation compared with the state-of-the-art recommendation approaches.',\n",
       "               'score': 0.03151364624500275})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the below line if you want to inspect the ordered results\n",
    "ordered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2a3595-c3b7-4376-b9c5-0db7a42b3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5\n"
     ]
    }
   ],
   "source": [
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location+os.environ['BLOB_SAS_TOKEN']}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(top_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db52ccb4-3112-4c48-ab95-5b6816dd51c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of elements in top_docs: 5. Here they are:\n",
      "[Document(page_content='predictive strategies, such as “if the state of the world was x ten time units\\nbefore, then it will be x next time so take action a”. The authors later show\\nhow learning can be used to eliminate these chaotic global fluctuations.\\n\\nMatarić [1995] has studied reinforcement learning in multi-robot domains.\\nShe notes, for example, how learning can give rise to social behaviors (Matarić\\n[1997]). The work shows how robots can be individually programmed to pro-\\nduce certain group behaviors. It represents a good example of the usefulness\\nand flexibility of learning agents in multi-agent domains. However, the author\\ndoes not offer a mathematical justification for the chosen individual learning\\nalgorithms, nor does she explain why the agents were able to converge to the\\nglobal behaviors. Our research hopes to provide the first steps in this direction.\\n\\nOne particularly interesting approach is taken by Carmel and Markovitch\\n[1997]. They work on model-based learning, that is, agents build models of other\\nagents via observations. They use models based on finite state machines. The\\nauthors show how some of these models can be effectively learned via observation\\nof the other agent’s actions. The authors concentrate on the development of\\nlearning algorithms that would let one agent learn a finite-state machine model\\nof another agent. They have not considered the case where two or more agents\\nare simultaneously learning about each other, which we study in this article.\\nHowever, their work is more general in the sense that they model agents as\\nstate machines, rather than the state-action pairs we use.\\n\\nFinally, a lot of experimental work has been done in the area of agents learn-\\ning about agents (Sen [1996], Weiß [1997]). For example, Sen and Sekaran [1998]\\nshow how learning agents in simple MAS converge to system-wide optimal be-\\nhavior. Their agents use Q-learning or modified classifier systems in order to\\nlearn. The authors implement these agents and compare the performance of the\\ndifferent learning algorithms for developing agent coordination. Hu and Well-\\nman [1998b, 1996] have studied reinforcement learning in market-base MASs,\\nshowing how certain initial learning biases can be self-fulfilling, and how learn-\\ning can be useful but is affected by an agent’s models of other agents. Claus\\nand Boutilier [1997] have also carried out experimental studies of the behavior of\\nreinforcement learning agents. We have been able to use the CLRI framework\\nto predict some of their experimental results Vidal [1998]. Other researchers\\nsuch as Stone and Veloso [1999], Littman [1994], and Hu and Wellman [1998a]\\nhave extended the basic Q-learning Watkins and Dayan [1992] algorithm for use\\nwith MASs in an effort to either improve or prove convergence to the optimal\\nbehavior.\\n\\nWe have also successfully experimented with reinforcement learning simu-\\nlations (Vidal and Durfee [1998]), but we believe that the formal treatment\\nelucidated in these pages will shed more light into the real nature of the prob-\\nlem and the relative importance of the various parameters that describe the\\n\\n25\\n\\n\\n\\ncapabilities of an agent’s learning algorithm.\\n\\n11 Summary\\n\\nWe have presented a framework for studying and predicting the behavior of\\nMASs composed of learning agents. We believe that this framework captures the\\nmost important parameters that describe an agents’ learning and the system’s\\nrules of encounter. Various comparisons between the framework’s predictions\\nand experimental results were given. These comparisons showed that the theo-\\nretical predictions closely match our experimental results and the experimental\\nresults published by others. Our success in reproducing these results allows us\\nto confidently state the effectiveness and accuracy of our theory in predicting\\nthe expected error of machine learning agents in MASs.\\n\\nSince our theory describes an agent’s behavior at a high-level (i.e., the agent’s\\nerror), it is not capable of making system-specific predictions (e.g., predicting\\nthe particular actions that are favored). These types of system-specific predic-\\ntions can only be arrived at by the traditional method of implementing popula-\\ntions of such agents and testing their behaviors. However, we expect that there\\nwill be times when the predictions from our theory will be enough to answer a\\ndesigner’s questions. A MAS designer that only needs to determine how “good”\\nthe agent’s behavior will be could probably use the CLRI framework. A de-\\nsigner that needs to know which particular emergent behaviors will be favored\\nby his agents will need to implement the agents.\\n\\nFinally, while we have given some examples as to how learning rates can be\\ndetermined for particular machine learning implementations, we do not have\\nany general method for determining these rates. However, we showed how to\\nuse the sample complexity of a learning problem to determine a lower bound on\\nthe learning rate of a consistent learning agent. This bound is useful for quickly\\n', metadata={'source': 'https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D'}), Document(page_content=\"Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.\", metadata={'source': 'https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D'}), Document(page_content='partially relevant to our work. Our emphasis is on finding ways to predict the\\nbehavior of MASs composed of machine-learning agents. We are only concerned\\nwith the behavior of simpler artificial programmable agents, rather than the\\ncomplex behavior of humans or the unpredictable behavior of animals.\\n\\nThe dynamics of MASs have also been studied by Kephart et. al. [18]. In\\nthis work the authors show how simple predictive agents can lead to globally\\ncyclic or chaotic behaviors. As the authors explain, the chaotic behaviors were a\\nresult of the simple predictive strategies used by the agents. Unlike our agents,\\nmost of their agents are not engaged in learning, instead they use simple fixed\\npredictive strategies, such as “if the state of the world was x ten time units\\nbefore, then it will be x next time so take action a”. The authors later show\\nhow learning can be used to eliminate these chaotic global fluctuations.\\n\\nMatarić [22] has studied reinforcement learning in multi-robot domains. She\\nnotes, for example, how learning can give rise to social behaviors [23]. The\\nwork shows how robots can be individually programmed to produce certain\\ngroup behaviors. It represents a good example of the usefulness and flexibility\\nof learning agents in multi-agent domains. However, the author does not offer\\na mathematical justification for the chosen individual learning algorithms, nor\\ndoes she explain why the agents were able to converge to the global behaviors.\\nOur research hopes to provide the first steps in this direction.\\n\\nOne particularly interesting approach is taken by Carmel and Markovitch\\n[4]. They work on model-based learning, that is, agents build models of other\\nagents via observations. They use models based on finite state machines. The\\nauthors show how some of these models can be effectively learned via observation\\nof the other agent’s actions. The authors concentrate on the development of\\nlearning algorithms that would let one agent learn a finite-state machine model\\nof another agent. They have not considered the case where two or more agents\\nare simultaneously learning about each other, which we study in this article.\\nHowever, their work is more general in the sense that they model agents as\\nstate machines, rather than the state-action pairs we use.\\n\\nFinally, a lot of experimental work has been done in the area of agents\\nlearning about agents [27, 36]. For example, Sen and Sekaran [28] show how\\nlearning agents in simple MAS converge to system-wide optimal behavior. Their\\nagents use Q-learning or modified classifier systems in order to learn. The\\nauthors implement these agents and compare the performance of the different\\nlearning algorithms for developing agent coordination. Hu and Wellman [14, 12]\\nhave studied reinforcement learning in market-base MASs, showing how certain\\ninitial learning biases can be self-fulfilling, and how learning can be useful but\\nis affected by an agent’s models of other agents. Claus and Boutilier [6] have\\nalso carried out experimental studies of the behavior of reinforcement learning\\nagents. We have been able to use the CLRI framework to predict some of their\\nexperimental results [33]. Other researchers [32, 20, 13] have extended the basic\\nQ-learning [35] algorithm for use with MASs in an effort to either improve or\\n\\n25\\n\\n\\n\\nprove convergence to the optimal behavior.\\nWe have also successfully experimented with reinforcement learning simula-\\n\\ntions [34], but we believe that the formal treatment elucidated in these pages\\nwill shed more light into the real nature of the problem and the relative im-\\nportance of the various parameters that describe the capabilities of an agent’s\\nlearning algorithm.\\n\\n11 Limitations and Future Work\\n\\nThe CLRI framework places some constraints on the type of systems it can\\nmodel, which limits its usability. However, it is important to understand that,\\nas we remove the limitations from the CLRI framework, the dynamics of the\\nsystem become much harder to predict. In the extreme, without any limitations\\non the agents’ abilities, the system becomes a complex adaptive system, as\\nstudied by Holland [11] and others in the field of complexity. The dynamic\\nbehavior of these systems continues to be studied by complexity researchers\\nwith only modest progress. It is only by placing limitations on the system that\\nwe were able to predict the expected error of agents in the systems modeled by\\nthe CLRI framework.\\n\\nOur ongoing work involves the relaxation of some of the constraints made by\\nthe CLRI framework so that it may become more easily and widely applicable,\\nwithout making the system dynamics impossible to analyze. We are targeting\\nthree specific constraints.\\n\\n1. The values of ci, li, ri, and Iij cannot, in all situations, be mathematically\\ndetermined from the system’s description. We have found that bounds for\\nthe ci, li, and ri values can often be determined when using reinforcement\\nlearning or supervised learning. However, the bounds are often very loose.\\n', metadata={'source': 'https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D'}), Document(page_content='In the context of the ongoing Covid-19 pandemic, several reports and studies have attempted to model and predict the spread of the disease. There is also intense debate about policies for limiting the damage, both to health and to the economy. On the one hand, the health and safety of the population is the principal consideration for most countries. On the other hand, we cannot ignore the potential for long-term economic damage caused by strict nation-wide lockdowns. In this working paper, we present a quantitative way to compute lockdown decisions for individual cities or regions, while balancing health and economic considerations. Furthermore, these policies are learnt automatically by the proposed algorithm, as a function of disease parameters (infectiousness, gestation period, duration of symptoms, probability of death) and population characteristics (density, movement propensity). We account for realistic considerations such as imperfect lockdowns, and show that the policy obtained using reinforcement learning is a viable quantitative approach towards lockdowns.', metadata={'source': 'https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D'}), Document(page_content='The key to personalized recommendation system is the prediction of users’ preferences. However, almost all existing music recommendation approaches only learn listeners’ preferences based on their historical records or explicit feedback, without considering the simulation of interaction process which can capture the minor changes of listeners’ preferences sensitively. In this paper, we propose a personalized hybrid recommendation algorithm for music based on reinforcement learning (PHRR) to recommend song sequences that match listeners’ preferences better. We firstly use weighted matrix factorization (WMF) and convolutional neural network (CNN) to learn and extract the song feature vectors. In order to capture the changes of listeners’ preferences sensitively, we innovatively enhance simulating interaction process of listeners and update the model continuously based on their preferences both for songs and song transitions. The extensive experiments on real-world datasets validate the effectiveness of the proposed PHRR on song sequence recommendation compared with the state-of-the-art recommendation approaches.', metadata={'source': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D'})]\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the below line if you want to inspect the ordered top_docs\n",
    "print(f\"Nr. of elements in top_docs: {len(top_docs)}. Here they are:\\n{top_docs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c26d7540-feb8-4581-849e-003f4bf2a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt token count: 2464\n",
      "Max Completion Token count: 1000\n",
      "Combined docs (context) token count: 2666\n",
      "--------\n",
      "Requested token count: 6130\n",
      "Token limit for gpt-35-turbo-16k : 16384\n",
      "Chain Type selected: stuff\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of tokens of our docs\n",
    "if(len(top_docs)>0):\n",
    "    tokens_limit   = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
    "    prompt_tokens  = num_tokens_from_string(COMBINE_CHAT_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
    "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
    "    \n",
    "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
    "    \n",
    "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
    "    \n",
    "    print(\"System prompt token count:\", prompt_tokens)\n",
    "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
    "    print(\"Combined docs (context) token count:\", context_tokens)\n",
    "    print(\"--------\")\n",
    "    print(\"Requested token count:\", requested_tokens)\n",
    "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Chain Type selected:\", chain_type)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcc376-6ee2-4812-b182-52571cd01241",
   "metadata": {},
   "source": [
    "## Using load_qa_with_sources_chain\n",
    "The *get_answer* function in the next cell is equivalent to the next code, in case **chain_type = map_reduce**:\n",
    "\n",
    "```\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from common.prompts import (COMBINE_PROMPT, COMBINE_QUESTION_PROMPT)\n",
    "\n",
    "llm35 = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", temperature=0.5, max_tokens=COMPLETION_TOKENS)\n",
    "chain = load_qa_with_sources_chain(llm35, chain_type=\"map_reduce\",\n",
    "                                   combine_prompt = COMBINE_PROMPT,\n",
    "                                   question_prompt = COMBINE_QUESTION_PROMPT,\n",
    "                                   return_intermediate_steps = True)\n",
    "\n",
    "answer = chain( {\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"it\"}, return_only_outputs=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce6efa9-2b8f-4810-904d-5986b4ae0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has been applied to various use cases, including:\n",
       "\n",
       "1. Multi-robot domains: Reinforcement learning has been used to study social behaviors and group behaviors in multi-robot domains<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\n",
       "\n",
       "2. Model-based learning: Agents can build models of other agents via observations and learn effective models through reinforcement learning. This approach has been used to learn finite-state machine models of other agents<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[4]</a></sup>.\n",
       "\n",
       "3. Agent coordination in multi-agent systems (MASs): Reinforcement learning agents in MASs can learn system-wide optimal behavior and develop agent coordination<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\n",
       "\n",
       "4. Epidemic prevention strategies: Reinforcement learning has been used to learn prevention strategies in the context of pandemic influenza, balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[20]</a></sup>.\n",
       "\n",
       "5. Lockdown decisions during epidemics: Reinforcement learning has been used to compute lockdown decisions for individual cities or regions, considering health and economic factors<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[21]</a></sup>.\n",
       "\n",
       "6. Personalized recommendation systems: Reinforcement learning has been used to improve personalized music recommendation algorithms, capturing changes in listeners' preferences and song transitions<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the answer\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bafbbb47-d31a-4720-b6bb-0febb83143fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has been applied to various use cases, including:\n",
       "\n",
       "1. Multi-robot domains: Reinforcement learning has been used to study social behaviors and group behaviors in multi-robot domains<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\n",
       "\n",
       "2. Model-based learning: Agents can build models of other agents via observations and learn effective models through reinforcement learning. This approach has been used to learn finite-state machine models of other agents<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[4]</a></sup>.\n",
       "\n",
       "3. Agent coordination in multi-agent systems (MASs): Reinforcement learning agents in MASs can learn system-wide optimal behavior and develop agent coordination<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\n",
       "\n",
       "4. Epidemic prevention strategies: Reinforcement learning has been used to learn prevention strategies in the context of pandemic influenza, balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[20]</a></sup>.\n",
       "\n",
       "5. Lockdown decisions during epidemics: Reinforcement learning has been used to compute lockdown decisions for individual cities or regions, considering health and economic factors<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[21]</a></sup>.\n",
       "\n",
       "6. Personalized recommendation systems: Reinforcement learning has been used to improve personalized music recommendation algorithms, capturing changes in listeners' preferences and song transitions<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27501f1b-7db0-4ee3-9cb1-e609254ffa3d",
   "metadata": {},
   "source": [
    "And if we ask the follow up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cf5b323-3b9c-479b-8502-acfc4f7915dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "There is no information provided in the extracted parts about the main points of our conversation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# follow-up questions don't work!\n",
    "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fa6e6-226c-400f-a504-30255385f43b",
   "metadata": {},
   "source": [
    "You might get a different response from above, but it doesn't matter what response you get, it will be based on the context given, not on previous answers.\n",
    "\n",
    "Until now we just have the same as the prior Notebook 03: results from Azure Search enhanced by OpenAI model, with no memory\n",
    "\n",
    "**Now let's add memory to it:**\n",
    "\n",
    "Reference: https://python.langchain.com/docs/modules/memory/how_to/adding_memory_chain_multiple_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d98b876e-d264-48ae-b5ed-9801d6a9152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has several use cases across different domains. Here are some examples:\n",
       "\n",
       "1. **Robotics**: Reinforcement learning can be used to train robots to perform complex tasks and navigate in dynamic environments. For example, Matarić [1995] studied reinforcement learning in multi-robot domains and showed how learning can give rise to social behaviors.\n",
       "\n",
       "2. **Epidemiology**: Reinforcement learning can be applied to model and predict the spread of diseases, such as pandemic influenza. It can be used to learn prevention strategies and optimize policies for limiting the damage caused by infectious diseases [2].\n",
       "\n",
       "3. **Multi-Agent Systems**: Reinforcement learning is useful in studying the behavior of multiple learning agents in complex environments. It can be applied to develop agent coordination and learn optimal system-wide behaviors [27, 28].\n",
       "\n",
       "4. **Healthcare**: Reinforcement learning can be used in personalized recommendation systems for healthcare. For example, it can learn users' preferences and recommend personalized music playlists based on their feedback and interaction patterns [32].\n",
       "\n",
       "These are just a few examples of the wide range of applications for reinforcement learning. It can be applied to various domains where decision-making and learning from interactions are important. \n",
       "\n",
       "If you would like to explore any of these topics further, please let me know.\n",
       "\n",
       "References:\n",
       "- [2]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[2]</a></sup>: \"Deep Reinforcement Learning for Prevention Strategies in Pandemic Influenza\"\n",
       "- [27]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[27]</a></sup>: \"Learning Agents in Multi-Agent Systems\"\n",
       "- [32]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[32]</a></sup>: \"Personalized Hybrid Recommendation Algorithm for Music Based on Reinforcement Learning\"\n",
       "- [28]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[28]</a></sup>: \"Reinforcement Learning in Multi-Agent Systems\"\n",
       "\n",
       "Is there anything else I can assist you with?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\")\n",
    "\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type,\n",
    "                        memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b5d4e63-534b-4a0e-8791-7e543a2a0bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me some use cases for reinforcement learning?\\nAI: Reinforcement learning has several use cases across different domains. Here are some examples:\\n\\n1. **Robotics**: Reinforcement learning can be used to train robots to perform complex tasks and navigate in dynamic environments. For example, Matarić [1995] studied reinforcement learning in multi-robot domains and showed how learning can give rise to social behaviors.\\n\\n2. **Epidemiology**: Reinforcement learning can be applied to model and predict the spread of diseases, such as pandemic influenza. It can be used to learn prevention strategies and optimize policies for limiting the damage caused by infectious diseases [2].\\n\\n3. **Multi-Agent Systems**: Reinforcement learning is useful in studying the behavior of multiple learning agents in complex environments. It can be applied to develop agent coordination and learn optimal system-wide behaviors [27, 28].\\n\\n4. **Healthcare**: Reinforcement learning can be used in personalized recommendation systems for healthcare. For example, it can learn users\\' preferences and recommend personalized music playlists based on their feedback and interaction patterns [32].\\n\\nThese are just a few examples of the wide range of applications for reinforcement learning. It can be applied to various domains where decision-making and learning from interactions are important. \\n\\nIf you would like to explore any of these topics further, please let me know.\\n\\nReferences:\\n- [2]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[2]</a></sup>: \"Deep Reinforcement Learning for Prevention Strategies in Pandemic Influenza\"\\n- [27]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[27]</a></sup>: \"Learning Agents in Multi-Agent Systems\"\\n- [32]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[32]</a></sup>: \"Personalized Hybrid Recommendation Algorithm for Music Based on Reinforcement Learning\"\\n- [28]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[28]</a></sup>: \"Reinforcement Learning in Multi-Agent Systems\"\\n\\nIs there anything else I can assist you with?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf28927b-d9ee-4412-bb07-13e055e832a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the main points of our conversation:\n",
       "\n",
       "1. Reinforcement learning has several use cases across different domains.\n",
       "2. Some examples include robotics, epidemiology, multi-agent systems, and healthcare.\n",
       "3. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate in dynamic environments.\n",
       "4. In epidemiology, reinforcement learning can be applied to model and predict the spread of diseases, such as pandemic influenza, and learn prevention strategies.\n",
       "5. In multi-agent systems, reinforcement learning is useful for studying the behavior of multiple learning agents in complex environments and developing agent coordination.\n",
       "6. In healthcare, reinforcement learning can be used in personalized recommendation systems, such as personalized music playlists based on user feedback and interaction patterns.\n",
       "7. These are just a few examples, and reinforcement learning can be applied to various domains where decision-making and learning from interactions are important.\n",
       "\n",
       "If you would like more information or have any other questions, feel free to let me know!\n",
       "\n",
       "References:\n",
       "- [2]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[2]</a></sup>: \"Deep Reinforcement Learning for Prevention Strategies in Pandemic Influenza\"\n",
       "- [27]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[27]</a></sup>: \"Learning Agents in Multi-Agent Systems\"\n",
       "- [32]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[32]</a></sup>: \"Personalized Hybrid Recommendation Algorithm for Music Based on Reinforcement Learning\"\n",
       "- [28]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[28]</a></sup>: \"Reinforcement Learning in Multi-Agent Systems\"\n",
       "\n",
       "Let me know if there's anything else I can assist you with!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3830b0b8-0ca2-4d0a-9747-f6273368002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning has several use cases across different domains.\n",
       "2. Some examples include robotics, epidemiology, multi-agent systems, and healthcare.\n",
       "3. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate in dynamic environments.\n",
       "4. In epidemiology, reinforcement learning can be applied to model and predict the spread of diseases, such as pandemic influenza, and learn prevention strategies [2].\n",
       "5. In multi-agent systems, reinforcement learning is useful for studying the behavior of multiple learning agents in complex environments and developing agent coordination [27, 28].\n",
       "6. In healthcare, reinforcement learning can be used in personalized recommendation systems, such as personalized music playlists based on user feedback and interaction patterns [32].\n",
       "\n",
       "These are just a few examples, and reinforcement learning can be applied to various domains where decision-making and learning from interactions are important.\n",
       "\n",
       "References:\n",
       "- [2]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[2]</a></sup>: \"Deep Reinforcement Learning for Prevention Strategies in Pandemic Influenza\"\n",
       "- [27]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[27]</a></sup>: \"Learning Agents in Multi-Agent Systems\"\n",
       "- [32]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[32]</a></sup>: \"Personalized Hybrid Recommendation Algorithm for Music Based on Reinforcement Learning\"\n",
       "- [28]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[28]</a></sup>: \"Reinforcement Learning in Multi-Agent Systems\"\n",
       "\n",
       "Let me know if there's anything else I can assist you with!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e732b-3c8c-4df3-8fcb-c3d01e7bec74",
   "metadata": {},
   "source": [
    "You might get a different answer on the above cell, and it is ok, this bot is not yet well configured to answer any question that is not related to its knowledge base, including salutations.\n",
    "\n",
    "Let's check our memory to see that it's keeping the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1279692c-7eb0-4300-8a66-c7025f02c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me some use cases for reinforcement learning?\\nAI: Reinforcement learning has several use cases across different domains. Here are some examples:\\n\\n1. **Robotics**: Reinforcement learning can be used to train robots to perform complex tasks and navigate in dynamic environments. For example, Matarić [1995] studied reinforcement learning in multi-robot domains and showed how learning can give rise to social behaviors.\\n\\n2. **Epidemiology**: Reinforcement learning can be applied to model and predict the spread of diseases, such as pandemic influenza. It can be used to learn prevention strategies and optimize policies for limiting the damage caused by infectious diseases [2].\\n\\n3. **Multi-Agent Systems**: Reinforcement learning is useful in studying the behavior of multiple learning agents in complex environments. It can be applied to develop agent coordination and learn optimal system-wide behaviors [27, 28].\\n\\n4. **Healthcare**: Reinforcement learning can be used in personalized recommendation systems for healthcare. For example, it can learn users\\' preferences and recommend personalized music playlists based on their feedback and interaction patterns [32].\\n\\nThese are just a few examples of the wide range of applications for reinforcement learning. It can be applied to various domains where decision-making and learning from interactions are important. \\n\\nIf you would like to explore any of these topics further, please let me know.\\n\\nReferences:\\n- [2]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[2]</a></sup>: \"Deep Reinforcement Learning for Prevention Strategies in Pandemic Influenza\"\\n- [27]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[27]</a></sup>: \"Learning Agents in Multi-Agent Systems\"\\n- [32]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[32]</a></sup>: \"Personalized Hybrid Recommendation Algorithm for Music Based on Reinforcement Learning\"\\n- [28]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[28]</a></sup>: \"Reinforcement Learning in Multi-Agent Systems\"\\n\\nIs there anything else I can assist you with?\\nHuman: Give me the main points of our conversation\\nAI: Here are the main points of our conversation:\\n\\n1. Reinforcement learning has several use cases across different domains.\\n2. Some examples include robotics, epidemiology, multi-agent systems, and healthcare.\\n3. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate in dynamic environments.\\n4. In epidemiology, reinforcement learning can be applied to model and predict the spread of diseases, such as pandemic influenza, and learn prevention strategies.\\n5. In multi-agent systems, reinforcement learning is useful for studying the behavior of multiple learning agents in complex environments and developing agent coordination.\\n6. In healthcare, reinforcement learning can be used in personalized recommendation systems, such as personalized music playlists based on user feedback and interaction patterns.\\n7. These are just a few examples, and reinforcement learning can be applied to various domains where decision-making and learning from interactions are important.\\n\\nIf you would like more information or have any other questions, feel free to let me know!\\n\\nReferences:\\n- [2]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[2]</a></sup>: \"Deep Reinforcement Learning for Prevention Strategies in Pandemic Influenza\"\\n- [27]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[27]</a></sup>: \"Learning Agents in Multi-Agent Systems\"\\n- [32]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[32]</a></sup>: \"Personalized Hybrid Recommendation Algorithm for Music Based on Reinforcement Learning\"\\n- [28]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[28]</a></sup>: \"Reinforcement Learning in Multi-Agent Systems\"\\n\\nLet me know if there\\'s anything else I can assist you with!\\nHuman: Thank you\\nAI: Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning has several use cases across different domains.\\n2. Some examples include robotics, epidemiology, multi-agent systems, and healthcare.\\n3. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate in dynamic environments.\\n4. In epidemiology, reinforcement learning can be applied to model and predict the spread of diseases, such as pandemic influenza, and learn prevention strategies [2].\\n5. In multi-agent systems, reinforcement learning is useful for studying the behavior of multiple learning agents in complex environments and developing agent coordination [27, 28].\\n6. In healthcare, reinforcement learning can be used in personalized recommendation systems, such as personalized music playlists based on user feedback and interaction patterns [32].\\n\\nThese are just a few examples, and reinforcement learning can be applied to various domains where decision-making and learning from interactions are important.\\n\\nReferences:\\n- [2]<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[2]</a></sup>: \"Deep Reinforcement Learning for Prevention Strategies in Pandemic Influenza\"\\n- [27]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[27]</a></sup>: \"Learning Agents in Multi-Agent Systems\"\\n- [32]<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[32]</a></sup>: \"Personalized Hybrid Recommendation Algorithm for Music Based on Reinforcement Learning\"\\n- [28]<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\" target=\"_blank\">[28]</a></sup>: \"Reinforcement Learning in Multi-Agent Systems\"\\n\\nLet me know if there\\'s anything else I can assist you with!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87405173",
   "metadata": {},
   "source": [
    "## Using CosmosDB as persistent memory\n",
    "\n",
    "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wisg to provide recommendations. \n",
    "\n",
    "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
    "We will use a class in LangChain use CosmosDBChatMessageHistory, see [HERE](https://python.langchain.com/en/latest/_modules/langchain/memory/chat_message_histories/cosmos_db.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7131daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CosmosDB instance from langchain cosmos class.\n",
    "cosmos = CosmosDBChatMessageHistory(\n",
    "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
    "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
    "    )\n",
    "\n",
    "# prepare the cosmosdb instance\n",
    "cosmos.prepare_cosmos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Memory Object\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\",chat_memory=cosmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27ceb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has several use cases in various domains. Here are some examples:\n",
       "\n",
       "1. **Robotics**: Reinforcement learning can be used to train robots to perform complex tasks and navigate their environment. For example, researchers have studied how learning can give rise to social behaviors in multi-robot domains, where robots can be individually programmed to produce certain group behaviors<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\n",
       "\n",
       "2. **Epidemiology**: Reinforcement learning has been applied to develop prevention strategies in the context of pandemic influenza. Researchers have used deep reinforcement learning to automatically learn prevention strategies and control the spread of infectious diseases<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[23]</a></sup>.\n",
       "\n",
       "3. **Multi-Agent Systems**: Reinforcement learning can be used to study the behavior of multi-agent systems (MASs) composed of learning agents. It has been shown that learning agents in MASs can converge to system-wide optimal behavior, and reinforcement learning algorithms have been developed for agent coordination and cooperation<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\n",
       "\n",
       "4. **Public Health**: Reinforcement learning can be used to compute lockdown decisions for individual cities or regions, considering both health and economic considerations. By using reinforcement learning algorithms, policies for controlling the spread of diseases can be learned automatically based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[29]</a></sup>.\n",
       "\n",
       "5. **Recommendation Systems**: Reinforcement learning can be used to personalize recommendation systems, such as music recommendation. By continuously updating the model based on user preferences, reinforcement learning algorithms can recommend song sequences that better match listeners' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[36]</a></sup>.\n",
       "\n",
       "These are just a few examples of the diverse applications of reinforcement learning. The field continues to evolve, and researchers are exploring new domains and problem areas where reinforcement learning can be applied effectively. Let me know if there's anything else I"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing using our Question\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a5ff826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning has several use cases in various domains.\n",
       "2. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate their environment<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\n",
       "3. In epidemiology, reinforcement learning has been applied to develop prevention strategies for infectious diseases like pandemic influenza<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[23]</a></sup>.\n",
       "4. In multi-agent systems, reinforcement learning can be used to study the behavior of learning agents and achieve system-wide optimal behavior<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\n",
       "5. In public health, reinforcement learning can be used to compute lockdown decisions for cities or regions, considering health and economic factors<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[29]</a></sup>.\n",
       "6. In recommendation systems, reinforcement learning can be used to personalize recommendations, such as music recommendations, by continuously updating the model based on user preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[36]</a></sup>.\n",
       "\n",
       "These examples highlight the diverse applications of reinforcement learning in different fields. If you have any more questions, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be1620fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning has several use cases in various domains.\n",
       "2. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate their environment<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\n",
       "3. In epidemiology, reinforcement learning has been applied to develop prevention strategies for infectious diseases like pandemic influenza<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[23]</a></sup>.\n",
       "4. In multi-agent systems, reinforcement learning can be used to study the behavior of learning agents and achieve system-wide optimal behavior<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\n",
       "5. In public health, reinforcement learning can be used to compute lockdown decisions for cities or regions, considering health and economic factors<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[29]</a></sup>.\n",
       "6. In recommendation systems, reinforcement learning can be used to personalize recommendations, such as music recommendations, by continuously updating the model based on user preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[36]</a></sup>.\n",
       "\n",
       "These examples highlight the diverse applications of reinforcement learning in different fields. If you have any more questions, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ac98",
   "metadata": {},
   "source": [
    "Let's check our Azure CosmosDB to see the whole conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1d7688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me some use cases for reinforcement learning?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Reinforcement learning has several use cases in various domains. Here are some examples:\\n\\n1. **Robotics**: Reinforcement learning can be used to train robots to perform complex tasks and navigate their environment. For example, researchers have studied how learning can give rise to social behaviors in multi-robot domains, where robots can be individually programmed to produce certain group behaviors<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\\n\\n2. **Epidemiology**: Reinforcement learning has been applied to develop prevention strategies in the context of pandemic influenza. Researchers have used deep reinforcement learning to automatically learn prevention strategies and control the spread of infectious diseases<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[23]</a></sup>.\\n\\n3. **Multi-Agent Systems**: Reinforcement learning can be used to study the behavior of multi-agent systems (MASs) composed of learning agents. It has been shown that learning agents in MASs can converge to system-wide optimal behavior, and reinforcement learning algorithms have been developed for agent coordination and cooperation<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\\n\\n4. **Public Health**: Reinforcement learning can be used to compute lockdown decisions for individual cities or regions, considering both health and economic considerations. By using reinforcement learning algorithms, policies for controlling the spread of diseases can be learned automatically based on disease parameters and population characteristics<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[29]</a></sup>.\\n\\n5. **Recommendation Systems**: Reinforcement learning can be used to personalize recommendation systems, such as music recommendation. By continuously updating the model based on user preferences, reinforcement learning algorithms can recommend song sequences that better match listeners\\' preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[36]</a></sup>.\\n\\nThese are just a few examples of the diverse applications of reinforcement learning. The field continues to evolve, and researchers are exploring new domains and problem areas where reinforcement learning can be applied effectively. Let me know if there\\'s anything else I', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Give me the main points of our conversation', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning has several use cases in various domains.\\n2. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate their environment<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\\n3. In epidemiology, reinforcement learning has been applied to develop prevention strategies for infectious diseases like pandemic influenza<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[23]</a></sup>.\\n4. In multi-agent systems, reinforcement learning can be used to study the behavior of learning agents and achieve system-wide optimal behavior<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\\n5. In public health, reinforcement learning can be used to compute lockdown decisions for cities or regions, considering health and economic factors<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[29]</a></sup>.\\n6. In recommendation systems, reinforcement learning can be used to personalize recommendations, such as music recommendations, by continuously updating the model based on user preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[36]</a></sup>.\\n\\nThese examples highlight the diverse applications of reinforcement learning in different fields. If you have any more questions, feel free to ask!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Thank you', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning has several use cases in various domains.\\n2. In robotics, reinforcement learning can be used to train robots to perform complex tasks and navigate their environment<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[22]</a></sup>.\\n3. In epidemiology, reinforcement learning has been applied to develop prevention strategies for infectious diseases like pandemic influenza<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[23]</a></sup>.\\n4. In multi-agent systems, reinforcement learning can be used to study the behavior of learning agents and achieve system-wide optimal behavior<sup><a href=\"https://blobstoragelwbasns7ls3ty.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[28]</a></sup>.\\n5. In public health, reinforcement learning can be used to compute lockdown decisions for cities or regions, considering health and economic factors<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[29]</a></sup>.\\n6. In recommendation systems, reinforcement learning can be used to personalize recommendations, such as music recommendations, by continuously updating the model based on user preferences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-10-14T09%3A46%3A05Z&se=2030-12-30T23%3A00%3A00Z&sp=rl&sig=154k5RvEq964JHojm%2BU7iFiYzczAXcaHBZ7wClxSj5I%3D\">[36]</a></sup>.\\n\\nThese examples highlight the diverse applications of reinforcement learning in different fields. If you have any more questions, feel free to ask!', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load message from cosmosdb\n",
    "cosmos.load_messages()\n",
    "cosmos.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e",
   "metadata": {},
   "source": [
    "![CosmosDB Memory](./images/cosmos-chathistory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789cada-23a3-451a-a91a-0906ceb0bd14",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
    "\n",
    "We added persitent memory using CosmosDB.\n",
    "\n",
    "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, regardless of the input and it struggles to respond to prompts like: Hello, Thank you, Bye, What's your name, What's the weather and any other task that is not search in the knowledge base.\n",
    "\n",
    "\n",
    "## <u>Important Note</u>:<br>\n",
    "As we proceed, while all the code will remain compatible with GPT-3.5 models, we highly recommend transitioning to GPT-4. Here's why:\n",
    "\n",
    "**GPT-3.5-Turbo** can be likened to a 7-year-old child. You can provide it with concise instructions, but it frequently struggles to follow them accurately. Additionally, its limited memory can make sustained conversations challenging.\n",
    "\n",
    "**GPT-3.5-Turbo-16k** resembles the same 7-year-old, but with an increased attention span for longer instructions. However, it still faces difficulties accurately executing them about half the time.\n",
    "\n",
    "**GPT-4** exhibits the capabilities of a 10-12-year-old child. It possesses enhanced reasoning skills and more consistently adheres to instructions. While its memory retention for instructions is moderate, it excels at following them.\n",
    "\n",
    "**GPT-4-32k** is akin to the 10-12-year-old child with an extended memory. It comprehends lengthy sets of instructions and engages in meaningful conversations. Thanks to its robust memory, it offers detailed responses.\n",
    "\n",
    "Understanding this analogy above will become clearer as you complete the final notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629ebf4-aced-45b7-a6a2-315810d37d48",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
    "\n",
    "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook explains and solves the tabular problem and the concept of Agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivbd",
   "language": "python",
   "name": "openaivbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
