{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
   "metadata": {},
   "source": [
    "So far, you have your Search Engine loaded **from two different data sources in two diferent text-based indexes**, on this notebook we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results.\n",
    "\n",
    "The idea is that a user can ask a question about Computer Science (first datasource/index) or about Covid (second datasource/index), and the engine will respond accordingly.\n",
    "This **Multi-Index** demo, mimics the scenario where a company loads multiple type of documents of different types and about completly different topics and the search engine must respond with the most relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_PROMPT_TEMPLATE\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    num_tokens_from_string\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials (my).env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## Multi-Index Search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text-based Indexes that we are going to query (from Notebook 01 and 02)\n",
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "indexes = [index1_name, index2_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a",
   "metadata": {},
   "source": [
    "Try questions that you think might be answered or addressed in computer science papers in 2020-2021 or that can be addressed by medical publications about COVID in 2020-2021. Try comparing the results with the open version of ChatGPT.<br>\n",
    "The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
    "\n",
    "**Example Questions you can ask**:\n",
    "- What is CLP?\n",
    "- How Markov chains work?\n",
    "- What are some examples of reinforcement learning?\n",
    "- What are the main risk factors for Covid-19?\n",
    "- What medicine reduces inflamation in the lungs?\n",
    "- Why Covid doesn't affect kids that much compared to adults?\n",
    "- Does chloroquine really works against covid?\n",
    "- Who won the 1994 soccer world cup? # This question should yield no answer if the system is correctly grounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What is CLP?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf",
   "metadata": {},
   "source": [
    "### Search on both indexes individually and aggragate results\n",
    "\n",
    "#### **Note**: \n",
    "In order to standarize the indexes, **there must be 8 mandatory fields present on each text-based index**: `id, title, content, chunks, language, name, location, vectorized`. This is so that each document can be treated the same along the code. Also, **all indexes must have a semantic configuration**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf2e30f-e71f-4533-ab52-27d048b80a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Index: cogsrch-index-files Results Found: 36, Results Returned: 5\n",
      "200\n",
      "Index: cogsrch-index-csv Results Found: 79, Results Returned: 5\n"
     ]
    }
   ],
   "source": [
    "agg_search_results = dict()\n",
    "\n",
    "for index in indexes:\n",
    "    search_payload = {\n",
    "        \"search\": QUESTION,\n",
    "        \"select\": \"id, title, chunks, language, name, location\",\n",
    "        \"queryType\": \"semantic\",\n",
    "        \"semanticConfiguration\": \"my-semantic-config\",\n",
    "        \"count\": \"true\",\n",
    "        \"speller\": \"lexicon\",\n",
    "        \"queryLanguage\": \"en-us\",\n",
    "        \"captions\": \"extractive\",\n",
    "        \"answers\": \"extractive|count-1\",\n",
    "        \"top\": \"5\"\n",
    "    }\n",
    "\n",
    "    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index + \"/docs/search\",\n",
    "                     data=json.dumps(search_payload), headers=headers, params=params)\n",
    "    print(r.status_code)\n",
    "\n",
    "    search_results = r.json()\n",
    "    agg_search_results[index]=search_results\n",
    "    print(\"Index:\", index, \"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Display the top results (from both searches) based on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e938337-602d-4b61-8141-b8c92a5d91da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Answers from <em>normal</em> query</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.99 (cogsrch-index-files)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Constraint Logic Programming (CLP) is an emerging software technology with a growing number of applications. Data flow in constraint programs is not explicit, and for this reason the concepts of slice and the slicing techniques of imperative languages are not directly applicable. This paper formulates declarative notions of slice suitable for CLP."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.93 (cogsrch-index-csv)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Answers from <em>semantic</em> query</h4></h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0701/0701082v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> 0701082v1.pdf </a> - score: 3.51 (cogsrch-index-files)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0012/0012014v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> arXiv:cs/0012014v1  [cs.SE]  18 Dec 2000 </a> - score: 3.12 (cogsrch-index-files)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Constraint Logic Programming (CLP) is an emerging software technology with a growing number of applications. Data flow in constraint programs is not explicit, and for this reason the concepts of slice and the slicing techniques of imperative languages are not directly applicable. This paper formulates declarative notions of slice suitable for CLP."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0011/0011030v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000 </a> - score: 3.06 (cogsrch-index-files)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1 Constraint Logic Programming  Constraint logic programming (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0310/0310042v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> () </a> - score: 2.93 (cogsrch-index-files)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "A CLP(FD) program searches a solution for a set of variables which take values over finite domains and which must verify a set of constraints. The evolution of the domains can be viewed as a sequence of applications of reduction operators attached to the constraints."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/10403670/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> Quantification of recombinant core-like particles of bluetongue virus using immunosorbent electron microscopy. </a> - score: 2.73 (cogsrch-index-csv)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> Length of encapsidated cargo impacts stability and structure of in vitro assembled alphavirus core-like particles </a> - score: 2.49 (cogsrch-index-csv)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0001/0001009v1.pdf?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> 0001009v1.pdf </a> - score: 2.29 (cogsrch-index-files)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Fractal symbolic analysis com- pares a program and its transformed version by repeat- edly simplifying these programs until symbolic analysis becomes tractable, ensuring that equality of simplified programs is sufficient to guarantee equality of the origi- nal programs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7131174/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP) </a> - score: 2.13 (cogsrch-index-csv)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC280685/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> A model of tripeptidyl-peptidase I (CLN2), a ubiquitous and highly conserved member of the sedolisin family of serine-carboxyl peptidases </a> - score: 2.07 (cogsrch-index-csv)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "BACKGROUND: Tripeptidyl-peptidase I, also known as CLN2, is a member of the family of sedolisins (serine-carboxyl peptidases). In humans, defects in expression of this enzyme lead to a fatal neurodegenerative disease, classical late-infantile neuronal ceroid lipofuscinosis."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1084330/?sv=2021-10-04&ss=btqf&srt=sco&st=2023-09-03T12%3A36%3A56Z&se=2030-09-04T10%3A00%3A00Z&sp=rl&sig=OK69n%2FVXw0MGQ%2BPPOXDLO75l5r21vymd40w1pOOu4kk%3D\"> Subversion of Cellular Autophagosomal Machinery by RNA Viruses </a> - score: 2.06 (cogsrch-index-csv)</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Subversion of Cellular Autophagosomal Machinery by RNA Viruses. Infection of human cells with poliovirus induces the proliferation of double-membraned cytoplasmic vesicles whose surfaces are used as the sites of viral RNA replication and whose origin is unknown."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Answers from <em>normal</em> query</h4>'))\n",
    "\n",
    "for index,search_results in agg_search_results.items():\n",
    "    for result in search_results['@search.answers']:\n",
    "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
    "            display(HTML(f\"<h5>Answer - score: {str(round(result['score'],2))} ({index})</h5>\"))\n",
    "            display(HTML(result['text']))\n",
    "            \n",
    "print(\"\\n\")\n",
    "display(HTML('<h4>Answers from <em>semantic</em> query</h4></h4>'))\n",
    "\n",
    "content = dict()\n",
    "ordered_content = OrderedDict()\n",
    "\n",
    "\n",
    "for index,search_results in agg_search_results.items():\n",
    "    for result in search_results['value']:\n",
    "        if result['@search.rerankerScore'] > 1:# Show answers that are at least 25% of the max possible score=4\n",
    "            content[result['id']]={\n",
    "                \"title\": result['title'],\n",
    "                \"chunks\": result['chunks'],\n",
    "                \"language\": result['language'], \n",
    "                \"name\": result['name'], \n",
    "                \"location\": result['location'] ,\n",
    "                \"caption\": result['@search.captions'][0]['text'],\n",
    "                \"score\": result['@search.rerankerScore'],\n",
    "                \"index\": index\n",
    "            }\n",
    "    \n",
    "#After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
    "for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
    "    ordered_content[id] = content[id]\n",
    "    url = str(ordered_content[id]['location']) + os.environ['BLOB_SAS_TOKEN']\n",
    "    title = str(ordered_content[id]['title']) if (ordered_content[id]['title']) else ordered_content[id]['name']\n",
    "    score = str(round(ordered_content[id]['score'],2))\n",
    "    display(HTML(f'<h5><a href=\"{url}\"> {title} </a> - score: {score} ({ordered_content[id][\"index\"]})</h5>'))\n",
    "    #display(HTML('<h5><a href=\"'+ url + '\">' + title + '</a> - score: '+ score + '</h5>'))\n",
    "    display(HTML(ordered_content[id]['caption']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
   "metadata": {},
   "source": [
    "## Comments on Query results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
   "metadata": {},
   "source": [
    "As seen above the semantic search feature of Azure Cognitive Search service is good. It gives us some answers and also the top results with the corresponding file and the paragraph where the answers is possible located.\n",
    "\n",
    "Let's see if we can make this better with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
   "metadata": {},
   "source": [
    "# Using Azure OpenAI\n",
    "\n",
    "To use OpenAI to get a better answer to our question, the thought process is simple: let's **give the answer and the content of the documents from the search result to the GPT model as context and let it provide a better response**.\n",
    "\n",
    "Now, before we do this, we need to understand a few things first:\n",
    "\n",
    "1) Chainning and Prompt Engineering\n",
    "2) Embeddings\n",
    "\n",
    "We will use a library call **LangChain** that wraps a lot of boiler plate code.\n",
    "Langchain is one library that does a lot of the prompt engineering for us under the hood, for more information see [here](https://python.langchain.com/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d9138-2250-4f6b-bc88-50d7957f8d33",
   "metadata": {},
   "source": [
    "**Important Note**: Starting now, we will utilize OpenAI models. Please ensure that you have deployed the following models within the Azure OpenAI portal using these precise deployment names:\n",
    "\n",
    "- text-embedding-ada-002\n",
    "- gpt-35-turbo\n",
    "- gpt-35-turbo-16k\n",
    "- gpt-4\n",
    "- gpt-4-32k\n",
    "\n",
    "Should you have deployed the models under different names, the code provided below will not function as expected. To resolve this, you would need to modify the variable names throughout all the notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb",
   "metadata": {},
   "source": [
    "## A gentle intro to chaining LLMs and prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69",
   "metadata": {},
   "source": [
    "Chains are what you get by connecting one or more large language models (LLMs) in a logical way. (Chains can be built of entities other than LLMs but for now, let’s stick with this definition for simplicity).\n",
    "\n",
    "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
    "\n",
    "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
    "\n",
    "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
    "\n",
    "Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13df9247-e784-4e04-9475-55e672efea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-35-turbo\" # options: gpt-35-turbo, gpt-35-turbo-16k, gpt-4, gpt-4-32k\n",
    "COMPLETION_TOKENS = 1000\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0520b9-83b2-49fd-ad84-624cb0f15ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question: \"What is CLP?\". Give your response in French\n"
     ]
    }
   ],
   "source": [
    "# Now we create a simple prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"language\"],\n",
    "    template='Answer the following question: \"{question}\". Give your response in {language}',\n",
    ")\n",
    "\n",
    "print(prompt.format(question=QUESTION, language=\"French\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc7dae3-6b88-4ea6-be43-b178ebc559dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is CLP?',\n",
       " 'language': 'French',\n",
       " 'text': \"CLP signifie Classification, Étiquetage et Emballage des substances et des mélanges. Il s'agit d'un système de classification et d'étiquetage harmonisé au niveau européen pour les produits chimiques dangereux. Le CLP vise à protéger la santé humaine et l'environnement en fournissant des informations claires et précises sur les dangers des produits chimiques.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally we create our first generic chain\n",
    "chain_chat = LLMChain(llm=llm, prompt=prompt)\n",
    "chain_chat({\"question\": QUESTION, \"language\": \"French\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8539d0-a538-4368-82c3-5f91d8370f1e",
   "metadata": {},
   "source": [
    "**Note**: this is the first time you use OpenAI in this Accelerator, so if you get a Resource not found error, is most likely because the name of your OpenAI model deployment is different than the variable MODEL set above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5",
   "metadata": {},
   "source": [
    "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
    "\n",
    "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c48038-b1af-4228-8ffb-720e554fd3b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**The second type of Chains are Utility:**\n",
    "\n",
    "* Utility — These are specialized chains, comprised of many LLMs to help solve a specific task. For example, LangChain supports some end-to-end chains (such as [QA_WITH_SOURCES](https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html) for QnA Doc retrieval, Summarization, etc) and some specific ones (such as GraphQnAChain for creating, querying, and saving graphs). \n",
    "\n",
    "We will look at one specific chain called **qa_with_sources** in this workshop for digging deeper and solve our use case of enhancing the results of Azure Cognitive Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0454ddb-44d8-4fa9-929a-5e5563dd28f8",
   "metadata": {},
   "source": [
    "\n",
    "But before dealing with the utility chain needed, we need to deal first with this problem: **the content of the search result files is or can be very lengthy, more than the allowed tokens allowed by the GPT Azure OpenAI models**. \n",
    "\n",
    "This is where the concept of embeddings/vectors come into place.\n",
    "\n",
    "## Embeddings and Vector Search\n",
    "\n",
    "From the Azure OpenAI documentation ([HERE](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=python)), An embedding is a special format of data representation that can be easily utilized by machine learning models and algorithms. The embedding is an information dense representation of the semantic meaning of a piece of text. Each embedding is a vector of floating point numbers, such that the distance between two embeddings in the vector space is correlated with semantic similarity between two inputs in the original format. For example, if two texts are similar, then their vector representations should also be similar. \n",
    "\n",
    "To address the challenge of accommodating context within the token limit of a Language Model (LLM), the solution involves the following steps:\n",
    "\n",
    "1. **Segmenting Documents**: Divide the documents into smaller segments or chunks.\n",
    "2. **Vectorization of Chunks**: Transform these chunks into vectors using appropriate techniques.\n",
    "3. **Vector Semantic Search**: Execute a semantic search using vectors to identify the top chunks similar to the given question.\n",
    "4. **Optimal Context Provision**: Provide the LLM with the most relevant and concise context, thereby achieving an optimal balance between comprehensiveness and lengthiness.\n",
    "\n",
    "\n",
    "Notice that **the documents chunks are already done in Azure Search**. *ordered_content* dictionary (created a few cells above) contains the chunks of each document. So we don't really need to chunk them again, but we still need to make sure that we can be as fast as possible and that we are below the max allowed input token limits of our selected OpenAI model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e79235-3d8b-4713-9336-5004cc4a1556",
   "metadata": {},
   "source": [
    "Our ultimate goal is to rely solely on vector indexes. While it is possible to manually code parsers with OCR for various file types and develop a scheduler to synchronize data with the index, there is a more efficient alternative: **Azure Cognitive Search is soon going to release automated chunking strategies and vectorization within the next months**, so we have three options: \n",
    "1. Wait for this functionality while in the meantime manually push chunks and its vectors to the vector-based indexes \n",
    "2. Fill up the vector-based indexes on-demand, as documents are discovered by users\n",
    "3. Use custom skills (for chunking and vectorization) and use knowledge stores in order to create a vector-base index from a text-based-ai-enriched index at ingestion time. See [HERE](https://github.com/Azure/cognitive-search-vector-pr/blob/main/demo-python/code/azure-search-vector-ingestion-python-sample.ipynb) for instructions on how to do this.\n",
    "\n",
    "In this notebook we are going to implement Option 2: **Create vector-based indexes per each text-based indexes and fill them up on-demand as documents are discovered**. Why? because is simpler and quick to implement, while we wait for Option 1 to become a feature of Azure Search Engine (which is the automation of Option 3 inside the search engine).\n",
    "\n",
    "As observed in Notebooks 1 and 2, each text-based index contains a field named `vectorized` that we have not utilized yet. We will now harness this field. The objective is to avoid vectorizing all documents at the time of ingestion (Option 3). Instead, we can vectorize the chunks as users search for or discover documents. This approach ensures that we allocate funds and resources only when the documents are actually required. Typically, in an organization with a vast repository of documents in a data lake, only 20% of the documents are frequently accessed, while the rest remain untouched. This phenomenon mirrors the [Pareto Principle](https://en.wikipedia.org/wiki/Pareto_principle) found in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12682a1b-df92-49ce-a638-7277103f6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "indexes = [index_name, index2_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6d6a7-18ef-45b2-a216-3c1f50006593",
   "metadata": {},
   "source": [
    "In order to not duplicate code, we have put many of the code used above into functions. These functions are in the `common/utils.py` and `common/prompts.py` files. This way we can use these functios in the app that we will build later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bccca45-d1dd-476f-b109-a528b857b6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(ordered_results): <class 'collections.OrderedDict'>, len(ordered_results): 17\n"
     ]
    }
   ],
   "source": [
    "k = 5 # Number of results per each text_index\n",
    "ordered_results = get_search_results(QUESTION, indexes, k=10, reranker_threshold=1)\n",
    "print(f\"type(ordered_results): {type(ordered_results)}, len(ordered_results): {len(ordered_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7714f38a-daaa-4fc5-a95a-dd025d153216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDcwMS8wNzAxMDgydjEucGRm0',\n",
       "              {'title': None,\n",
       "               'name': '0701082v1.pdf',\n",
       "               'location': 'https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0701/0701082v1.pdf',\n",
       "               'caption': 'The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification.',\n",
       "               'index': 'cogsrch-index-files',\n",
       "               'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n07\\n\\n01\\n08\\n\\n2v\\n1 \\n\\n [\\ncs\\n\\n.P\\nL\\n\\n] \\n 1\\n\\n2 \\nJa\\n\\nn \\n20\\n\\n07\\n\\nUnder consideration for publication in Theory and Practice of Logic Programming 1\\n\\nRecurrence with affine level mappings is P-time\\ndecidable for CLP(R)\\n\\nTechnical note\\n\\nFRED MESNARD\\nIREMIA, Université de la Réunion, France\\n\\n(e-mail: Frederic.Mesnard@univ-reunion.fr)\\n\\nALEXANDER SEREBRENIK\\nLaboratory for Quality Software (LaQuSo), T.U. Eindhoven, The Netherlands\\n\\n(e-mail: A.Serebrenik@tue.nl)\\n\\nsubmitted 2 May 2006; revised 13 October 2006; accepted 4 January 2007\\n\\nAbstract\\n\\nIn this paper we introduce a class of constraint logic programs such that their termination can be\\nproved by using affine level mappings. We show that membership to this class is decidable in poly-\\nnomial time.\\n\\nKEYWORDS: constraint logic programming – termination – decidability\\n\\n1 Introduction\\n\\nTermination is well-known to be one of the crucial properties of software verification.\\nLogic programming, and more generally constraint logic programming (CLP), with their\\nstrong theoretical basis lend themselves easily to termination analysis as witnessed by a\\nvery intensive research in the area.\\n\\nIn this paper, which is a revised version of (Serebrenik and Mesnard 2004), we study\\ndecidability of termination for CLP(C) programs for a given constraint domain C. In\\ngeneral, decidability depends on the constraint domain C. On the one hand, Devienne\\net al. (1993) have established undecidability of termination for one-rule binary CLP(H)\\nprograms, where H is the domain of Herbrand terms. On the other hand, Datalog, i.e.,\\nlogic programming with no function symbols, provides an example of a constraint pro-\\ngramming language such that termination is decidable. We note that the decidability of\\nthe related problem of boundedness for Datalog queries has been studied, for instance,\\nin (Afrati et al. 2005; Marcinkowski 1996). For constraint domains with the undecidable\\ntermination property, we are interested in subclasses of programs such that termination is\\ndecidable for these subclasses. A trivial example is the subclass of non-recursive programs.\\n\\nWe organise the paper as follows. After the preliminary remarks of Section 2, in Sec-\\ntion 3 we present our main result. Section 4 reviews related results before our conclusion.\\n\\nhttp://arXiv.org/abs/cs/0701082v1\\n\\n\\n2 Fred Mesnard and Alexander Serebrenik\\n\\n2 Preliminaries\\n\\nFor CLP-related definitions, we follow (Jaffar et al. 1998). Extensive introductions to CLP\\ncan be found in (Jaffar and Maher 1994; Marriott and Stuckey 1998). The key notions of\\nCLP are those of an algebra and an associated constraint solver over a class of constraints,\\nnamely a set of first order formulas including the always satisfiable constraint true, the un-\\nsatisfiable constraint false, and closed under variable renaming, conjunction and existential\\nquantification. If c is a constraint, we write ∃c for its existential closure. We consider ideal\\nCLP(C), i.e., we require the existence of a constraint solver solvC mapping in finite time\\neach constraint to true or false such that if solvC(c) = false then the constraint ∃c is\\nfalse with respect to C and if solvC(c) = true then the constraint ∃c is true with respect to\\nC. The associated domain is denoted DC. Given a constraint c, a solution of c is a mapping\\nθ from the set of variables to DC such that cθ is true with respect to C. The set of predicate\\nsymbols associated with C is denoted ΠC. We are interested in the following domains and\\nlanguages:\\n\\n• N. The predicate symbols are = and ≥, the function symbols are 0, 1, and +.\\n• Q and R. The predicate and function symbols are as above. Q+ and R+ restrict Q\\n\\nand R to non-negative numbers.\\n\\nGiven a CLP(C)-program P, we define ΠP as the set of user-defined predicate symbols\\nappearing in P. We restrict our attention to flat programs, i.e., finite sets of rules in a flat\\nform. So each rule is of form: either q0(ỹ0)← c or q0(ỹ0)← c,q1(ỹ1), . . . ,qn(ỹn) where c\\nis a constraint, q0, . . . ,qn ∈ ΠP, ỹ0, . . . , ỹn denote tuples of distinct variables,\\n\\nTn\\ni=0 ỹi = ∅,\\n\\nand the set of free variables of the constraint c is included in\\nSn\\n\\ni=0 ỹi. Flat queries are de-\\nfined accordingly. A binary program is a flat program such that all rules have no more\\nthan one user-defined body subgoal. The C-base BC\\n\\nP is defined as {p(d1, . . . ,dn) | p ∈\\nΠP,(d1, . . . ,dn) ∈ (DC)n}. For a flat query Q of the form c,A1, . . . ,An, the set of ground\\ninstances of Q, denoted groundC(Q), is the set of conjunctions of the form A1θ, . . . ,Anθ\\nwhere θ is a solution of c. The notion of groundedness is extended to flat rules and pro-\\ngrams.\\n\\nExample 1\\nConsider the following CLP(Q) program P:\\n\\nr1 p(x) ← x = 2.\\n\\nr2 p(x) ← 0 = 1.\\n\\nr3 p(x) ← 72≥ x,y = x + 1, p(y).\\n\\nThis program is a binary program, groundQ(r1) is {p(2)}, groundQ(r2) is ∅, groundQ(r3)\\n\\nis an infinite set that contains, among others, p(72)← p(73) and p(1/2)← p(3/2), and\\ngroundQ(P) = groundQ(r1)∪ groundQ(r2)∪ groundQ(r3). ',\n",
       "                'Note that ground instances do\\nnot contain any constraint.\\n\\nWe now discuss the operational semantics of CLP-programs we consider in this paper.\\nA state of computation is a pair 〈A1, . . . ,An‖c〉. We further assume that one of the atoms in\\nA1, . . . ,An, say Ai, is selected for resolution by a selection rule. The operational semantics\\ncan be expressed by means of the following rewriting rules:\\n\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 3\\n\\n• 〈A1, . . . ,An‖c〉 rewrites to 〈�‖false〉 if there exists a fresh rule A′i← c′,B1, . . . ,Bm in\\nP such that c∧ (Ai = A′i)∧ c′ is unsatisfiable;\\n• 〈A1, . . . ,An‖c〉 rewrites to 〈A1, . . . ,Ai−1,B1, . . . ,Bm,Ai+1, . . . ,An||c∧Ai = A′i ∧ c′〉 if\\n\\nthere exists a fresh rule A′i← c′,B1, . . . ,Bm in P such that c∧ (Ai = A′i)∧c′ is satisfi-\\nable.\\n\\nA derivation from a state S0 is a finite or infinite sequence of states S0,S1, . . . ,Sn, . . . such\\nthat each Si can be rewritten as Si+1. A ground state is a state 〈A1, . . . ,An‖true〉 where each\\nAi belongs to BC\\n\\nP . We say that a CLP(C) program P is terminating if every derivation start-\\ning from any ground state via any selection rule is finite, under the operational semantics\\ndefined above.\\n\\nTo characterize this notion of termination, we use the notion of level mapping. A level\\nmapping for a constraint domain C is a function | · | : BC\\n\\nP → R. We adapt the idea of recur-\\nrence, originally introduced in (Bezem 1993), to CLP:\\n\\nDefinition 1\\nLet P be a flat CLP(C) program, and | · | : C-base→ R be a level mapping. P is called\\nrecurrent with respect to | · | if there exists a real number ε > 0 such that, for every A←\\nB1, . . . ,Bn ∈ groundC(P), |A| ∈ R+, and |Bi| ∈ R+, |A| ≥ |Bi|+ ε for all i, 1 ≤ i ≤ n. We\\nsay that P is recurrent if there exists a level-mapping such that P is recurrent with respect\\nto it.\\n\\nObserve that rules of the form p(x̃)← c are not taken into account by the definition\\nabove. Moreover, without loss of generality, we may fix ε to 1: if P is recurrent in this\\nnarrow sense, P is trivially recurrent with respect to Definition 1. Conversely, since ε > 0,\\nwe can safely multiply the values of the level mapping by 1/ε.\\n\\nTheorem 1\\n(Bezem 1993) P is recurrent if and only if P is terminating.\\n\\n3 Alm-recurrent programs\\n\\nLet us consider programs that can be analyzed by means of affine level mappings.\\n\\nDefinition 2\\nA level mapping | · | is called affine if for any n-ary predicate symbol p ∈ ΠP, there exist\\nreal numbers µp,i, 0≤ i≤ n, such that for any atom p(e1, . . . ,en) ∈ BC\\n\\nP :\\n\\n|p(e1, . . . ,en)|= µp,0 +\\nn\\n\\n∑\\ni=1\\n\\nµp,iei\\n\\nSo for a given atom p(ẽ), its affine level mapping is a linear combination of ẽ shifted by\\na constant. We can define the class of programs we are interested in:\\n\\nDefinition 3\\nLet P be a flat CLP(C) program. We say that P is alm-recurrent if there exists an affine\\nlevel mapping | · | such that P is recurrent with respect to it.\\n\\n\\n\\n4 Fred Mesnard and Alexander Serebrenik\\n\\nExample 2\\nThe CLP(Q) program P from Example 1 is alm-recurrent with respect to |p(x)|= 73− x.\\n\\nClearly, if P is alm-recurrent, then P is recurrent thus terminating. Let us show that alm-\\nrecurrence can be efficiently decided. We start with proving this result for binary programs.\\n\\nTheorem 2\\nAlm-recurrence of a binary constraint logic program P over Q,Q+,R and R+ is decidable\\nin polynomial time with respect to the size of P.\\n\\nProof\\nThe proof is constructive: we provide a decision procedure for alm-recurrence of binary\\nconstraint logic programs over Q,Q+,R and R+. The decision procedure extends the al-\\ngorithm proposed in (Sohn and Van Gelder 1991) for termination of Prolog programs (ab-\\nstracted as CLP(N) programs) to binary CLP(C) where C is Q,Q+,R or R+. The algo-\\nrithm tries to find an affine level mapping showing that P is alm-recurrent by examining\\neach user-defined predicate symbol p of a binary CLP program P in turn (the precise order\\ndoes not matter). For every rule r, say p(x̃p)← c,q(x̃q), we test the satisfiability of c. For\\nthe domains we consider, it can be done in polynomial time (Khachiyan 1979). If c is not\\nsatisfiable, we disregard this rule. Otherwise, let np and nq be the arities of p and q. For the\\nrule r, recurrence is equivalent to:\\n\\nC |= c→ [|p(x̃p)| ≥ 1 + |q(x̃q)| ∧ |q(x̃q)| ≥ 0] (1)\\n\\nNote that the condition c→ |p(x̃p)| ≥ 0 can be omitted as it is implied by (1). Formula (1)\\nis logically equivalent to C |= c→ |p(x̃p)| ≥ 1+ |q(x̃q)| and C |= c→ |q(x̃q)| ≥ 0. Let x̃p be\\n(xp,1, . . . ,xp,np), x̃q be (xq,1, . . . ,xq,nq) and let µp,0, . . . ,µp,np ,µq,0, . . . ,µq,nq ∈R be such that\\nfor any atom p(e1, . . . ,enp)∈ BC\\n\\nP and any atom q(e1, . . . ,enq)∈BC\\nP : |p(e1, . . . ,enp)|= µp,0 +\\n\\n∑np\\ni=1 µp,iei and |q(e1, . . . ,enq)| = µq,0 + ∑\\n\\nnq\\ni=1 µq,iei. Hence, c should imply (µp,0− µq,0)+\\n\\n∑np\\ni=1 µp,ixp,i + ∑\\n\\nnq\\ni=1(−µq,i)xq,i ≥ 1 and µq,0 + ∑\\n\\nnq\\ni=1 µq,ixq,i ≥ 0. For the sake of uniformity,\\n\\nwe rewrite the second inequality as µq,0 + ∑np\\ni=1 0xp,i + ∑\\n\\nnq\\ni=1 µq,ixq,i ≥ 0. ',\n",
       "                'Both inequalities\\n\\ncan be presented using the scalar product notation as µ̃x̃≥ 1 and µ̃′x̃≥ 0, where:\\n\\nx̃ = (x0,xp,1, . . . ,xp,np ,xq,1, . . . ,xq,nq)\\n\\nx0 is a new variable fixed to 1 and used to obtain the free coefficient in the product\\nµ̃ = (µp,0−µq,0,µp,1, . . . ,µp,np ,−µq,1, . . . ,−µq,nq)\\n\\nµ̃′ = (µq,0,0, . . . ,0,µq,1, . . . ,µq,nq).\\n\\nHence, the binary rule r gives rise to the following two pseudo linear programming\\nproblems. The problems are pseudo linear rather than linear because symbolic parameters\\nappear in the objective functions.\\n\\nminimise θ = µ̃x̃ subject to c∧ x0 = 1 (2)\\n\\nminimise δ = µ̃′x̃ subject to c∧ x0 = 1 (3)\\n\\nWe note that c∧ x0 = 1 is satisfiable as c is satisfiable and x0 is a new variable, and we\\nrewrite c∧x0 = 1 as Ax̃≥ b in the standard way (Schrijver 1986). An affine level mapping\\n| · | ensuring recurrence exists at least for this rule if and only if θ∗ ≥ 1 and δ∗ ≥ 0, where\\nθ∗ and δ∗ denote the minima of the corresponding objective functions. Because of the\\n\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 5\\n\\nsymbolic constants µp,i and µq,i, neither (2) nor (3) is a linear programming problem. Now,\\nthe idea is to consider the dual form:\\n\\nmaximise η = bT ỹ subject to AT ỹ = µ̃T ∧ ỹ≥ 0 (4)\\n\\nmaximise γ = bT z̃ subject to AT z̃ = µ̃′T ∧ z̃≥ 0 (5)\\n\\nwhere ỹ and z̃ are tuples of adequate length of new variables. By the duality theorem of\\nlinear programming which holds in C (see (Schrijver 1986) for instance), we have θ∗ = η∗\\n\\nand δ∗ = γ∗. Furthermore, we observe that µ̃ appears linearly in the dual problem (4).\\nHence the constraints of (4) can be rewritten, by adding η≥ 1 as a set of linear inequations\\ndenoted Sp≥1+q\\n\\nr . Similarly, the constraints of (5) can be rewritten, by adding γ ≥ 0 as a\\nset of linear inequations, denoted Sq≥0\\n\\nr . Let us define defnP(p) as the set of binary rules\\ndefining p in P, Sp as the conjunction\\n\\nV\\n\\nr∈defnP(p)[S\\np≥1+q\\nr ∧Sq≥0\\n\\nr ], and SP as the conjunction\\nV\\n\\np∈ΠP\\nSp. We have by construction SP is satisfiable if and only if there exists a affine level\\n\\nmapping ensuring recurrence of P.\\nMoreover, as P is a finite set of binary rules, computing SP can be done in polynomial\\n\\ntime with respect to the size of P and results in a constraint the size of which is also\\npolynomial with respect to the size of P. Finally, testing satisfiability of SP in Q, Q+, R,\\nand R+ can be done in polynomial time (Khachiyan 1979).\\n\\nExample 3\\nApplying the algorithm to the example 1, we obtain the following two pseudo linear pro-\\ngramming problems corresponding to (2) and (3), respectively:\\n\\nminimise θ = µp,1x1−µp,1x2 subject to 72≥ x1∧ x2 = x1 + 1∧ x0 = 1\\n\\nminimise δ = µp,0 + µp,1x2 subject to 72≥ x1∧ x2 = x1 + 1∧ x0 = 1\\n\\nRewriting the system of constraints as Ax̃ ≥ b and switching to the dual form, we get the\\nsystem SP:\\n\\n\\uf8f1\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f2\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f3\\n\\nη = y1− y2−72 ∗ y3 + y4− y5,\\n\\nη≥ 1,\\n\\ny1− y2 = 0,−y3− y4 + y5 = µp,1,\\n\\ny4− y5 =−µp,1,\\n\\ny1 ≥ 0,\\n\\ny2 ≥ 0,\\n\\ny3 ≥ 0,\\n\\ny4 ≥ 0,\\n\\ny5 ≥ 0\\n\\n\\uf8fc\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fd\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fe\\n\\n∪\\n\\n\\uf8f1\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f2\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f3\\n\\nγ = z1− z2−72 ∗ z3 + z4− z5,\\n\\nγ≥ 0,\\n\\nz1− z2 = µp,0,\\n\\n−z3− z4 + z5 = 0,\\n\\nz4− z5 = µp,1,\\n\\nz1 ≥ 0,\\n\\nz2 ≥ 0,\\n\\nz3 ≥ 0,\\n\\nz4 ≥ 0,\\n\\nz5 ≥ 0\\n\\n\\uf8fc\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fd\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fe\\n\\nSince SP is satisfiable, P is alm-recurrent. Note that projecting SP onto the µp,i’s gives\\n{µp,0 + 73 ∗µp,1 ≥ 0,µp,1 ≤ −1}. Any solution to this last constraint is a level mapping\\nensuring alm-recurrence of P.\\n\\nAn immediate consequence of the result above is that recurrence with affine level map-\\npings is also P-time decidable for non-binary CLP(R) program with rules which contain\\nmore than one atom in their bodies. Formally, the following theorem holds.\\n\\n\\n\\n6 Fred Mesnard and Alexander Serebrenik\\n\\nTheorem 3\\nAlm-recurrence of a constraint logic program P over Q,Q+,R and R+ is decidable in\\npolynomial time with respect to the size of P.\\n\\nProof\\nLet P be a constraint logic program. Let P′ be the binary constraint logic program such\\nthat for every rule q0(ỹ0)← c,q1(ỹ1), . . . ,qn(ỹn) with n≥ 1 in P, P′ contains the following\\nrules:\\n\\nq0(ỹ0)← c,q1(ỹ1).\\n\\n. . .\\n\\nq0(ỹ0)← c,qn(ỹn).\\n\\nand nothing else. From Definition 1, we note that P is recurrent if and only if P′ is re-\\ncurrent. Moreover, the size of P′ is polynomial in the size of P. Hence, by Theorems 2,\\nalm-recurrence of P′ is P-time decidable.\\n\\nAlthough the technique above is not complete for programs over N, it is a sound way to\\nprove recurrence of programs over this domain: if a program is recurrent over Q, it is also\\nrecurrent over N. For binary programs, as we allow negative coefficients in the level map-\\nping, we get a more powerful criterion than the one proposed in (Sohn and Van Gelder 1991).\\n',\n",
       "                'For instance, termination of Example 1 (considered as a CLP(N) program) cannot be\\nproved by (Sohn and Van Gelder 1991).\\n\\nFor binary CLP(Q) programs, the decision procedure described above has been pro-\\ntotyped in SICStus Prolog (SICS 2005) using the Simplex algorithm (Dantzig 1951) and\\na Fourier-based projection operator (Holzbaur 1995) to ease manual verification. There-\\nfore, the complexity of the prototype is not polynomial. The implementation is available at\\nhttp://www.univ-reunion.fr/∼gcc/soft/binterm4q.tgz\\n\\n4 Related Works\\n\\nThe basic idea of identifying decidable and undecidable subsets of logic programs goes\\nback to (Devienne et al. 1993).\\n\\nRecently, decidability of classes of imperative programs has been studied in (Cousot 2005;\\nPodelski and Rybalchenko 2004; Tiwari 2004). Tiwari considers real-valued programs with\\nno nested loops and no branching inside a loop (Tiwari 2004). Such programs correspond\\nto one-binary-rule CLP(R). The author provides decidability results for subclasses of these\\nprograms. Our approach does not restrict nesting of loops and it allows internal branching.\\nWhile in general termination of such programs is undecidable (Tiwari 2004), we identified\\na subclass of programs with decidable termination property. Termination of the following\\nCLP(R) program and its imperative equivalent can be shown by our method but not by the\\none proposed in (Tiwari 2004).\\n\\nExample 4\\n\\nq(x) ← −20≤ x,x≤ 20,y + 5 = x,q(y).\\nq(x) ← 0≤ x,x≤ 100,y + 1 = x,q(y).\\n\\nhttp://www.univ-reunion.fr/~gcc/soft/binterm4q.tgz\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 7\\n\\nwhile ((−20≤ x≤ 20) or (0 ≤ x≤ 100)) do\\nif (−20≤ x≤ 20) x = x−5 fi\\nif (0≤ x≤ 100) x = x−1 fi\\n\\nod\\n\\nSimilarly to (Tiwari 2004), Podelski and Rybalchenko (2004) have considered programs\\nwith no nested loops and no branching inside a loop. However, they focused on integer\\nprograms and provide a polynomial time decidability technique for a subclass of such\\nprograms. In case of general programs their technique can be applied to provide a sufficient\\ncondition for liveness.\\n\\nIn a recent paper, Cousot (2005) applied abstraction techniques and langrangian relax-\\nation to prove termination. Extension of the basic technique should be able to analyse\\nloops with disjunctions in their condition such as Example 4. However, complexity of the\\napproach is not discussed and it is not clear whether the technique is complete for some\\nclass of programs.\\n\\nOne might like to investigate a more expressive language of constraints including poly-\\nnomials. Recall that we require the constraints domain to be ideal, i.e., one needs a decision\\nprocedure for existentially closed conjunctions. Such a decision procedure exists, for in-\\nstance, for real-closed fields such as R (Tarski 1931; Renegar 1992). For some domains\\nsuch as Q, existence of a decision procedure is still an open problem, although it seems\\nto be unlikely (Pheidas 2000). If one restricts attention to real-closed fields, one might\\neven consider polynomial level-mappings of a certain power rather than the affine ones.\\nOne can show that in this case proving recurrence is equivalent to determining satisfia-\\nbility of the equivalent quantifier-free formula (Tarski 1931; Tarski 1951). Hence, recur-\\nrence is still decidable in this case. Although the known complexity bound of determining\\nthe equivalent quantifier-free formula given an existential formula is a double exponen-\\ntial (Basu et al. 1996; Collins 1975), to the best of our knowledge the complexity of the\\nsubclass of formulas which we obtain is an open question.\\n\\n5 Conclusion\\n\\nIn this paper we have considered constraints solving over the rationals and the reals. For\\nthese domains we have identified a class of CLP programs such that an affine level map-\\nping is sufficient to prove their recurrence. We have seen that membership to this class\\nis decidable and presented a polynomial-time decision procedure. The decision procedure\\ncan also be used as a sound termination proof technique for binary CLP(N) and has been\\nprototyped in SICStus Prolog for binary CLP(Q).\\n\\nAcknowledgements\\n\\nWe thank the referees for useful suggestions.\\n\\nReferences\\n\\nAFRATI, F. N., COSMADAKIS, S. S., AND FOUSTOUCOS, E. 2005. Datalog programs and their\\npersistency numbers. ACM Transactions on Computational Logic (TOCL), 6, 3, 481–518.\\n\\n\\n\\n8 Fred Mesnard and Alexander Serebrenik\\n\\nBASU, S., POLLACK, R., AND ROY, M.-F. 1996. On the combinatorial and algebraic complexity of\\nquantifier elimination. Journal of the ACM 43, 6, 1002–1045.\\n\\nBEZEM, M. 1993. Strong termination of logic programs. Journal of Logic Programming 15, 1&2,\\n79–97.\\n\\nCOLLINS, G. E. 1975. Quantifier elimination for real closed fields by cylindrical algebraic decom-\\nposition. In Second GI conference on Automata Theory and Formal Languages. Lecture Notes in\\nComputer Science, vol. 33. Springer, 134–183.\\n\\nCOUSOT, P. 2005. Proving program invariance and termination by parametric abstraction, lagrangian\\n',\n",
       "                'relaxation and semidefinite programming. In Verification, Model Checking, and Abstract Interpre-\\ntation, 6th International Conference, VMCAI, Paris, France, January 17-19, 2005, Proceedings,\\nR. Cousot, Ed. Lecture Notes in Computer Science, vol. 3385. Springer, 1–24.\\n\\nDANTZIG, G. B. 1951. Maximization of a linear function of variables subject to linear inequalities.\\nIn Activity Analysis of Production and Allocation - Proceedings of a Conference, T. Koopmans,\\nEd. Cowles Commission Monograph, vol. 13. Wiley, New York, 339–347.\\n\\nDEVIENNE, P., LEBÈGUE, P., AND ROUTIER, J.-C. P. 1993. Halting problem of one binary horn\\nclause is undecidable. In STACS 93, 10th Annual Symposium on Theoretical Aspects of Computer\\nScience, Würzburg, Germany, February 25-27, 1993, Proceedings., P. Enjalbert, A. Finkel, and\\nK. W. Wagner, Eds. Lecture Notes in Computer Science, vol. 665. Springer, 48–57.\\n\\nHOLZBAUR, C. 1995. OFAI clp(Q,R) Manual. Tech. Rep. TR-95-09, Austrian Research Institute\\nfor Artificial Intelligence (ÖFAI), Schottengasse 3, A-1010 Vienna, Austria.\\n\\nJAFFAR, J. AND MAHER, M. J. 1994. Constraint logic programming: A survey. Journal of Logic\\nProgramming 19/20, 503–582.\\n\\nJAFFAR, J., MAHER, M. J., MARRIOTT, K., AND STUCKEY, P. J. 1998. The semantics of constraint\\nlogic programs. Journal of Logic Programming 37, 1-3, 1–46.\\n\\nKHACHIYAN, L. 1979. A polynomial algorithm in linear programming. Soviet Mathematics—\\nDoklady 20, 191–194.\\n\\nMARCINKOWSKI, J. 1996. DATALOG SIRUPs uniform boundedness is undecidable. In Proceed-\\nings of the 11th Annual IEEE Symposium on Logic in Computer Science. 13–24.\\n\\nMARRIOTT, K. AND STUCKEY, P. J. 1998. Programming with Constraints: An Introduction. The\\nMIT Press.\\n\\nPHEIDAS, T. 2000. An effort to prove that the existential theory of is undecidable.\\nContemporary Mathematics 270, 237–252. Available at http://www.ams.org/mathscinet-\\ngetitem?mr=2001m:03085.\\n\\nPODELSKI, A. AND RYBALCHENKO, A. 2004. A complete method for the synthesis of linear\\nranking functions. In Verification, Model Checking, and Abstract Interpretation, 5th International\\nConference, Venice, January 11-13, 2004, Proceedings, B. Steffen and G. Levi, Eds. Lecture Notes\\nin Computer Science, vol. 2937. Springer, 239–251.\\n\\nRENEGAR, J. 1992. On the computational complexity and geometry of the first-order theory of the\\nreals. Journal of Symbolic Computation 13, 3, 255–352.\\n\\nSCHRIJVER, A. 1986. Theory of Linear and Integer Programming. Wiley.\\n\\nSEREBRENIK, A. AND MESNARD, F. 2004. On termination of binary CLP programs. In Logic\\nBased Program Synthesis and Transformation, 14th International Symposium, LOPSTR, Verona,\\nItaly, August 26-28, 2004, Revised Selected Papers, S. Etalle, Ed. Lecture Notes in Computer\\nScience, vol. 3573. Springer, 231–244.\\n\\nSICS. 2005. SICStus User Manual. Version 3.12.3. Swedish Institute of Computer Science.\\n\\nSOHN, K. AND VAN GELDER, A. 1991. Termination detection in logic programs using argument\\nsizes. In Proceedings of the Tenth ACM SIGACT-SIGART-SIGMOD Symposium on Principles of\\nDatabase Systems. ACM Press, 216–226.\\n\\nTARSKI, A. 1931. Sur les ensembles définissables de nombres réels. Fundamenta Mathematicae 17,\\n210–239.\\n\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 9\\n\\nTARSKI, A. 1951. A Decision Method for Elementary Algebra and Geometry, 2nd ed. University of\\nCalifornia Press.\\n\\nTIWARI, A. 2004. Termination of linear programs. In Computer-Aided Verification, CAV, R. Alur\\nand D. Peled, Eds. Lecture Notes on Computer Science, vol. 3114. Springer, 70–82.\\n\\n\\n\\tIntroduction\\n\\tPreliminaries\\n\\tAlm-recurrent programs\\n\\tRelated Works\\n\\tConclusion\\n\\tReferences\\n\\n'],\n",
       "               'language': 'en',\n",
       "               'score': 3.506740093231201,\n",
       "               'vectorized': True}),\n",
       "             ('aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMi8wMDEyMDE0djEucGRm0',\n",
       "              {'title': 'arXiv:cs/0012014v1  [cs.SE]  18 Dec 2000',\n",
       "               'name': '0012014v1.pdf',\n",
       "               'location': 'https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0012/0012014v1.pdf',\n",
       "               'caption': 'Constraint Logic Programming (CLP) is an emerging software technology with a growing number of applications. Data flow in constraint programs is not explicit, and for this reason the concepts of slice and the slicing techniques of imperative languages are not directly applicable. This paper formulates declarative notions of slice suitable for CLP.',\n",
       "               'index': 'cogsrch-index-files',\n",
       "               'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n00\\n\\n12\\n01\\n\\n4v\\n1 \\n\\n [\\ncs\\n\\n.S\\nE\\n\\n] \\n 1\\n\\n8 \\nD\\n\\nec\\n 2\\n\\n00\\n0\\n\\nSlicing of Constraint Logic Programs 1\\n\\n1\\n\\n1In M. Ducassé (ed), proceedings of the Fourth International Workshop on Automated Debugging (AADEBUG\\n2000), August 2000, Munich. COmputer Research Repository (http://www.acm.org/corr/), cs.SE/0012014; whole pro-\\nceedings: cs.SE/0010035.\\n\\nhttp://arxiv.org/abs/cs/0012014v1\\nhttp://www.acm.org/corr/\\nhttp://arxiv.org/abs/cs/0012014\\nhttp://arxiv.org/abs/cs/0010035\\n\\n\\nSlicing of Constraint Logic Programs\\n\\nGyöngyi Szilágyi1, Tibor Gyimóthy1 and Jan Małuszyński 2\\n\\n1 Research Group on Artificial Intelligence Hungarian Academy of Sciences\\n2 Dept. of Computer and Information Sci., Linköping University, Sweden\\n\\nE-mail:{szilagyi,gyimi}@inf.u-szeged.hu, janma@ida.liu.se\\n\\nAbstract\\n\\nAbstract. Slicing is a program analysis technique originally developed for imperative\\nlanguages. It facilitates understanding of data flow and debugging.\\n\\nThis paper discusses slicing of Constraint Logic Programs. Constraint Logic Programming\\n(CLP) is an emerging software technology with a growing number of applications. Data flow\\nin constraint programs is not explicit, and for this reason the concepts of slice and the slicing\\ntechniques of imperative languages are not directly applicable.\\n\\nThis paper formulates declarative notions of slice suitable for CLP. They provide a basis for\\ndefining slicing techniques (both dynamic and static) based on variable sharing. The techniques\\nare further extended by using groundness information.\\n\\nA prototype dynamic slicer of CLP programs implementing the presented ideas is briefly\\ndescribed together with the results of some slicing experiments.\\n\\n1 Introduction\\n\\nThis paper discusses slicing of Constraint Logic Programs. Constraint Logic Programming (CLP)\\n(see e.g. [13]) is an emerging software technology with growing number of applications. Data\\nflow in constraint programs is not explicit, and for this reason the concept of a slice and the slicing\\ntechniques of imperative languages are not directly applicable. Also, implicit data flow makes the\\nunderstanding of program behaviour rather difficult. Thus program analysis tools explaining data\\nflow to the user could be of great practical importance. This paper presents a prototype tool based on\\nthe slice concept applied to CLP.\\n\\nIntuitively a program slice with respect to a specific variable at some program point contains\\nall those parts of the program that may affect the value of the variable (backward slice) or may be\\naffected by the value of the variable (forward slice). Slicing algorithms can be classified according\\nto whether they only use statically available information (static slicing), or compute those statements\\nwhich influence the value of a variable occurrence for a specific program input (dynamic slice). The\\nslice provides a focus for analysis of the origin of the computed values of the variable in question. In\\nthe context of CLP the intuition remains the same, but the concept of slice requires precise definition\\nsince the nature of CLP computations is different from the nature of imperative computing.\\n\\nSlicing techniques for logic programs have been discussed in [5, 14, 19]. CLP extends logic\\nprogramming with constraints. This is a substantial extension and the slicing of CLP program has, to\\nour knowledge, not yet been addressed by other authors. Novel contributions presented in this paper\\nare:\\n\\n• A precise formulation of the slicing problem for CLP programs. We first define a concept of\\nslice for a set of constraints, which is then used to define slices of derivation trees, representing\\nstates of CLP computations. Then we define slices of a program in terms of the slices of its\\nderivation trees.\\n\\n\\n\\nSlicing of Constraint Logic Programs 3\\n\\n• Slicing techniques for CLP. We present slicing techniques that make it possible to construct\\nslices according to the definitions. The techniques are based on a simple analysis of variable\\nsharing and groundness.\\n\\n• A prototype dynamic slicer. A tool implementing the proposed techniques and some experi-\\nments with its use are briefly described.\\n\\nThe precisely defined concepts of slice gives a solid foundation for development of slicing tech-\\nniques. The prototype tool, including some visualisation facilities, helps the user in better under-\\nstanding of the program and in (manual) search for errors. Integration of this tool with more advanced\\ndebuggers is a topic of future work.\\n\\nThe paper is organized as follows. Section 2 outlines some basic concepts which are then used\\nin Section 3 to formulate the problem of slicing. Section 4 presents and justifies a declarative for-\\nmalization of CLP slicing, based on a notion of dependency relation. Section 5 discusses a dynamic\\nbackward slicing technique, and the use of directionality information for reducing the size of slices.\\nOur prototype tool is described in Section 6, together with results of some experiments. Section 7\\n',\n",
       "                'then discusses relations to other work. Finally in Section 8 we present our conclusions and sugges-\\ntions for future work.\\n\\n2 Constraint Logic Programs\\n\\nThe cornerstone of Constraint Logic Programming (CLP) [9, 13] is the notion of constraint. Con-\\nstraints are formulae constructed with some constraint predicates with a predefined interpreta-\\ntion. A typical example of a constraint is a linear arithmetic equation or inequality with rational\\ncoefficients where the constraint predicate used is equality interpreted over rational numbers, e.g.\\nX − Y = 1. The variables of a constraint range over the domain of interpretation. A valuation of\\na set S of variables is a mapping θ from S to the interpretation domain. A set of constraints C is\\nsatisfiable if there exists a valuation θ for the set of variables occurring in C, such that θ(C) holds\\nin the constraint domain.\\n\\nA constraint logic program is a set of clauses of the form h : −b1, ..., bn, n ≥ 0 , where\\nh, b1, ..., bn are atomic formulae. The predicates used to construct b1, ..., bn are either constraint\\npredicates or other predicates (sometimes called defined predicates). The predicate of h is a defined\\npredicate. A goal is a clause without h. This syntax extends logic programs with the possibility of\\nincluding constraints into the clauses.\\n\\nExample 1 In the following constraint program the equality constraint and symbols of arithmetic\\noperations are interpreted over the domain of rational numbers. This simple example is chosen to\\nsimplify the forthcoming illustration of slicing concepts and techniques. The constraints are distin-\\nguished by the curly brackets {}.\\n\\np(X,Y,Z):- {X-Y=1}, q(X,Y), r(Z).\\nq(U,V):- {U+V=3}.\\nr(42).\\n\\nSlicing refers to computations. Abstractly, a computation can be seen as construction of a tree,\\nfrom renamed instances of clauses. We explain briefly the idea discussed formally in [3].\\n\\nIntuitively, a clause c can be seen as a tree with root h head and leaves b1, ..., bn body atoms. If\\nthe predicate of bi appears in the head of a clause c′ then a renamed copy c′′ of c′ can be composed\\nwith c by attaching the head of c′′ to bi. This implicitly adds equality constraints for the corresponding\\narguments of the atoms. This process can be repeated for the leaves of the resulting tree. More\\nformally this is captured by the following notion. A skeleton for a program P is a labeled ordered\\ntree with the root labeled by a goal clause and with the nodes labeled by (renamed) clauses of the\\nprogram; some leaves may instead be labeled ”?” in which case they are called incomplete nodes.\\n\\n\\n\\n4 AADEBUG 2000\\n\\nEach non-leaf node has as many children as the non-constraint atoms of its body. The head predicate\\nof the i-th child of a node is the same as the predicate of the i-th non-constraint body atom of the\\nclause labeling the node.\\n\\nFor a given skeleton S the set C(S) of constraints, which will be called the set of constraints of\\nS, consists of :\\n\\n• the constraints of all clauses labeling the nodes of S\\n\\n• all equations ~x = ~y where ~x are the arguments of the i-th body atom of the clause labeling a\\nnode n of S, and ~y are the arguments of the head atom of the clause labeling the i-th child of\\nn. (No equation is created if the i-th child of n is an incomplete node).\\n\\nA derivation tree for a program P is a skeleton for P whose set of constraints is satisfiable. If the\\nskeleton is complete (i.e. it has no incomplete node) the derivation tree is called a proof tree. Figure\\n1 shows a complete skeleton tree for the program in Example 1.\\n\\nq(U,V) :- {U + V = 3}\\n\\np(X,Y,Z) :- {X - Y = 1}, q(X,Y), r(Z)\\n\\nr(42)\\n\\nFigure 1: A skeleton for the CLP program of Example 1.\\n\\nThe set of constraints of this skeleton is: C(S) = {X − Y = 1, X = U, Y = V, U + V = 3, Z =\\n42} and it is satisfiable. Thus the skeleton is a proof tree.\\n\\nFor the presentation of the slicing techniques we need to refer to program positions and to\\nderivation tree positions. A slice is defined with respect to some particular occurrence of a variable\\n(in a program or derivation tree), and positions are used to identify these ocurrences. Positions also\\nidentify arguments of the atomic formulae and their subterms.\\n\\nTo define the notion of position we assume that some standard way of enumeration of the nodes\\nof any given tree T is adopted. The indices of the nodes of T are called positions of T and the set of\\nall positions is denoted Pos(T ). Each position determines a unique subtree of T . On the other hand,\\nT may have several identical subtrees T0 at different positions.\\n\\nThis notation extends also for atomic formulae and terms, where the positions determine unique\\nsubterms. A position of a term such that the corresponding subterm is a variable will be called a\\nvariable position. We extend the adopted way of enumeration to clauses and programs; a program\\nposition is an index in this enumeration that identifies an atomic formula or a term in a clause of the\\nprogram.\\n\\n',\n",
       "                'A single clause may be treated as a one-clause program. As discussed above, a derivation tree\\nhas its nodes labeled by renamed variants of program clauses. By a derivation tree position of a\\nderivation tree T we mean a pair (i1, i2), where i1 is a position of the skeleton of T and i2 is a\\nposition of the clause labeling node i1 in T . The set of all tree positions of a derivation tree T will be\\ndenoted by Pos(T ).\\n\\nRecall that each label of a derivation tree T is a variant of a program clause, or of a goal. There-\\nfore the positions of T can be mapped in a natural way into the corresponding program positions.\\n\\nSimilary, each occurrence of a variable X in C(T ) (the constraint set of T ) originates from a\\nvariable position of X in T . Thus variable positions of T can be linked to the related constraints of\\nC(T ).\\n\\nLet P be a set of positions of T , and ΨT (P) the set of all variables that appear in the terms on\\npositions in P . In this way P identifies the subset CP of C(T ) consisting of all constraints including\\nvariables in ΨT (P).\\n\\nExample 2 Consider the derivation tree of Figure 1.\\nLet (P) = { derivation tree positions of the atom q(X, Y )} ⊆ Pos(T ).\\nThen ΨT (P) = {X, Y } and CP = {X − Y = 1, X = U, Y = V }.\\n\\n\\n\\nSlicing of Constraint Logic Programs 5\\n\\n3 The Slicing Problem\\nGiven a variable X in a CLP program we would like to find a fragment of the program that may\\naffect the value of X . This is rather imprecise, hence our objective is to formalize this intuition. We\\nfirst define the notion of a slice of a satisfiable set of constraints. A variable X in a derivation tree T\\nhas its valuations [9, 13] restricted by the set of constraints of T (which is satisfiable), so our second\\ntask will be to define a slice of a derivation tree, and finally a slice of a program (see Figure 2).\\n\\nX\\nslice slice slice\\n\\nφ\\n\\nProof Tree ProgramConstraint store\\n\\nposition\\nproof tree program \\n\\nposition\\nvariable\\ninstance\\n\\nFigure 2: A slice of a constraint set, a proof tree and a program.\\n\\nLet C be a set of constraints. Intuitively we would like to remove all constraints of the set that do\\nnot restrict the valuation of a given variable. The binding of a variable X to a value v is said to be a\\nsolution of C with respect to X iff there exists a valuation ν such that ν(X) = v and ν satisfies C.\\nThe set of all solutions of C with respect to X will be denoted by Sol(X, C).\\n\\nDefinition 1 A slice of a satisfiable constraint set C with respect to X is a subset S ⊆ C such that\\nSol(X, S) = Sol(X, C).\\n\\nIn other words the set of all solutions of a slice S of C with respect to X is equal to the set of all\\nsolutions of C with respect to X . Definition 1 gives implicitly a notion of minimal slice: it is a slice\\nS of C such that if we further reduce S to S ′, then Sol(X, S ′) is different from Sol(X, C). Notice\\nthat the whole set C is a slice of itself, and that the definition does not provide any hint about how\\nto find a minimal slice. The problem of finding minimal slices may be undecidable in general, since\\nsatisfiability may be undecidable. So reasoning about minimality of the constructed slices seems only\\nbe possible in very restricted cases, and for some specific constraint domains. Our general technique\\nis domain independent but we show in Section 5 how the groundness information ( which may be\\nprovided by a specific constraint solver) can be used to reduce the size of the slices constructed by\\nthe general technique.\\n\\nWe now formulate the slicing problem for derivation trees. A derivation tree T is a skeleton with\\na set of constraints C(T ). The variables of C(T ) originate from positions of T . Let P be a set of\\npositions of T , i.e. P ⊆ Pos(T ). Then Ψ(P) identifies the variables of C(T ) with occurrences\\noriginating from positions in P . We denote by CP the set of all constraints of C(T ) that include\\nthese variables.\\n\\nDefinition 2 A slice of a derivation tree T with respect to a variable position of X is any subset P\\nof the positions of T such that CP is a slice of C(T ) with respect to X .\\n\\nThe intuition reflected by this definition is that the constraints connected with the positions of the\\ntree not included in a slice do not influence restrictions on the valuation of X imposed by the tree.\\nWe formalize this by referring to the formal notion of the slice of a set of constraints. Notice that any\\nsuperset of a slice is also a slice.\\n\\nFinally we define the notion of a CLP program slice with respect to a variable position. We\\nnotice that every position of a derivation tree T is a (renamed) copy of a program position or of a\\ngoal position. This provides a natural map ΦT of the positions of T into program positions and goal\\npositions. Corresponding to this definition of ΦT , for a program position q the set Φ−1\\n\\nT (q) contains\\nthose proof tree positions such that if r ∈ Φ−1\\n\\nT (q) then ΦT (r) = q.\\n\\n\\n\\n6 AADEBUG 2000\\n\\nDefinition 3 A slice of a CLP program P with respect to a program position q is any set S of\\n',\n",
       "                'positions of P such that for every derivation tree T whenever its position r is in Φ−1\\n\\nT (q), there exists\\na slice Q of T with respect to r such that ΦT (Q) ⊆ S.\\n\\nThis means that for any derivation tree position r, such that ΦT (r) = q, and program slice S with\\nrespect to q, the value of the variable in r can only be influenced by variants of the program positions\\nin S.\\n\\n4 Dependency-based slicing\\n\\nThe formal definitions of the previous section make it possible to state precisely our objective, which\\nis automatic construction of slices.\\n\\nOur formulation defines slicing of a CLP program in terms of the slicing of sets of constraints.\\nGenerally it is undecidable whether a subset of a set of constraints is a slice. This section presents a\\nrather straightforward sufficient condition for this. We provide here a “syntactic” approach to slicing\\nconstraint stores, proof trees and programs. The propositions follow easily from the definitions and\\nwill be stated without proof. More details can be found in the technical report [16].\\n\\n4.1 Slicing sets of constraints\\nWe use variable sharing between constraints as a basis for slicing sets of constraints. Let C be a\\nset of constraints, and vars(C) the set of all variables occurring in the constraints in C. Let X, Y\\nbe variables in vars(C). X is said to depend explicitly on Y iff both occur in a constraint c in C.\\nNotice that the explicit dependency relation is symmetric and reflexive but need not be transitive.\\n\\nDefinition 4 A dependency relation on vars(C) is the transitive closure of the explicit dependency\\nrelation.\\n\\nThe dependency relation on C will be denoted by depC . Notice that depC is an equivalence relation\\non vars(C). We map any equivalence class [X]depC\\n\\nto the subset CX of C that consists of all\\nconstraints that include variables in [X]dep. Then CX is a slice of C (see [16]).\\n\\nExample 3 For the set of constraints of Example 1 the dependency relation has two equivalence\\nclasses: {X, Y, U, V } and {Z} and gives the following slice of C with respect to X:\\n\\nCX = {X − Y = 1, X = U, Y = V, U + V = 3}\\n\\n4.2 Slicing of derivation trees\\nWe defined the concept of slice for a derivation tree by referring to the notion of slice of a set\\nof constraints. To construct slices of derivation trees we introduce a dependency relation on the\\npositions of a derivation tree. We now define a direct dependency relation ∼T on Pos(T ). It can be\\nrelated to the dependency relation on vars(C(T )) [16] and hence can be used for slicing T .\\n\\nDefinition 5 Let T be a derivation tree. The direct dependency relation ∼T on Pos(T ) is defined as\\nfollows:\\nα ∼T β iff one of the following conditions holds:\\n\\n1. α and β are positions in an occurrence of a clause constraint (constraint edge).\\n\\n2. α and β are positions in a node equation (transition edge).\\n\\n3. α and β are positions in an occurrence of a term (functor edge).\\n\\n\\n\\nSlicing of Constraint Logic Programs 7\\n\\n4. α and β share a variable (local edge).\\n\\nObserve that the relation is both reflexive and symmetric. The transitive closure ∼∗\\n\\nT of the direct\\ndependency relation will be called the dependency relation on Pos(T ). So ∼∗\\n\\nT is an equivalence\\nrelation.\\n\\nProposition 1 Let T be a proof tree and let α be a variable position of T . Then [α]∼∗\\n\\nT\\nis a slice of T\\n\\nwith respect to α.\\n\\n4.3 Slicing of CLP programs\\nThis section defines a dependency relation on the positions of the program and then makes use of it\\nin constructing program slices. Recall that each position of a derivation tree T “originates” from a\\nposition of the selected program P . This is formally captured by the map Φ : Pos(T ) → Pos(P ).\\nThe dependency relation ∼P on Pos(P ) we are going to define should reflect dependency relations\\nin all proof trees of P . More precisely, whenever α ∼T β in some tree T we would also like to have\\nΦ(α) ∼P Φ(β).\\n\\nDefinition 6 Let P be a CLP program. The direct dependency relation ∼P on Pos(P ) is defined as\\nfollows: α ∼P β iff at least one of the following conditions holds:\\n\\n1. α and β are positions of the same constraint (constraint edge).\\n\\n2. α is a position of the head atom of a clause c and β is a position of a body atom of a clause d\\nand both atoms have the same predicate symbol (transition edge).\\n\\n3. α and β belong to the same argument of a function (functor edge).\\n\\n4. α and β are in the same clause and have a common variable (local edge).\\n\\nThe dependency relation of a program can be represented as a graph.\\n\\n \\n\\nlocal edge\\n\\ntransition edge\\n\\nconstraint edge\\n\\n    q( U, V )\\n\\np( X, Y, Z )  :-      { X - Y = 1 }       q( X, Y )         r( Z )\\n\\n:-      { U + V = 3 }                                     r( 42 )\\n\\nFigure 3: Program dependence represented in graphical form and the backward slice with respect to\\nZ in p(X,Y,Z))\\n\\nComparing the definitions of ∼T and ∼P one can check that whenever α ∼T β in some tree T\\nof P then Φ(α) ∼P Φ(β) as well. Consequently, for any proof tree T (α ∼∗\\n\\nT β) ⇒ Φ(α) ∼∗\\n\\nP Φ(β).\\nThe transitive closure ∼∗\\n\\n',\n",
       "                'P is an equivalence relation on Pos(P ). The following result shows how ∼∗\\n\\nP\\n\\ncan be used for the slicing of P .\\n\\n\\n\\n8 AADEBUG 2000\\n\\nProposition 2 Let P be a CLP program and let β be a position of P . Then [β]∼∗\\n\\nP\\nis a slice of P with\\n\\nrespect to β.\\n\\nFigure 3 shows the program dependences and a backward slice of the program in Example 1 with\\nrespect to Z in p(X, Y, Z). For the program in Example 1 ∼∗\\n\\nP has two equivalence classes. One of\\nthem includes all occurrences of Z and the occurrence of the constant 42. The other consists of the\\nremaining positions.\\n\\nDefinition 6 with Proposition 2 give a method for constructing program slices without referring\\nto proof trees. Thus, we obtain a static slicing technique for CLP. The mapping Φ was introduced\\nto argue about correctness of this technique. These results also confirm the correctness of the slicing\\nalgorithm in [5] since a logic program can be viewed as a constraint logic program.\\nThe proposition shows that the concept of dependency relation on program positions provides a\\nsufficient condition for slicing a CLP program. However, the slice obtained may be quite large,\\nsometimes it may even include the whole constraint store.\\n\\nWe propose two ways for addressing this problem. On one hand, improvement is possible if we\\nhandle the so called “calling context problem”[7] which appears when the same predicate is called\\nfrom two different clauses. As we explained in [16] it is possible to adapt to CLP the solution\\nproposed by Horwitz et. al [7] for procedural languages. Another way of reducing the size of slices\\nis to infer and to take into account information about proliferation of ground instantiations during the\\nexecution of the program. A directional dynamic slicing technique based on this idea is presented in\\nthe next section.\\n\\n5 Dynamic directional slicing\\n\\nAll the dependency relations discussed so far were symmetric. Intuitively, for a constraint c(X, Y )\\na restriction imposed on valuations of X usually influences admissible valuations of Y and vice\\nversa. However if c(X, Y ) belongs to a satisfiable constraint set C and some other constraints of C\\nmake X ground then the slice of C with respect to X need not include c(X, Y ). For example, if\\nC = {X + 1 = 0, Y > X} is interpreted on the integer domain then {X + 1 = 0} is a slice of C\\nwith respect to X . This slice can be constructed by using information about groundness of variables\\noccurring in the dependency graph.\\n\\nThis section shows how to use groundness information in derivation tree slicing, that is in dy-\\nnamic slicing of CLP programs. It extends to CLP the ideas of dynamic slicing for logic programs\\npresented in [5]. In our approach groundness is captured by adding directionality information to\\ndependency graphs. The directed graphs show the propagation of ground data during the execution\\nof CLP programs, and these graphs can then be used to produce more precise slices. The groundness\\ninformation will be collected during the computation that constructs the derivation tree to be sliced.\\nThe proposed concepts are also applicable to the case of static slicing, where the groundness infor-\\nmation has to be inferred by static analysis of the program. This is however not discussed in this\\npaper.\\n\\n5.1 Groundness Annotations\\n\\nGroundness information associated with a derivation tree will be expressed as an annotation of its\\npositions. The annotation classifies the positions of a derivation tree or the positions of the CLP\\nprogram. The positions are classified as inherited (marked with ↓), synthesized (↑) and dual (l). An\\nannotation is partial if some positions are dual. Formally speaking, an annotation is a mapping µ\\nfrom the positions into the set {↓, ↑, l} [3].\\n\\nThe intended meaning of the annotation is as follows. An inherited position is a position which is\\nground at time of calling, that is when the equation involving this position is first created during the\\nconstruction of the derivation tree. A synthesized positions is a position which is ground at success,\\nthat is when the subtree having the position in its root label is completed in the computation process.\\n\\n\\n\\nSlicing of Constraint Logic Programs 9\\n\\nThe dual positions of a proof tree are those for which no groundness information is given, including\\nthose which are ground neither at call nor at success.\\n\\nThe annotations will be collected during the execution of the program. Alternatively, they may\\nbe inferred with some straightforward inference rules discussed in [16].\\n\\nWe now introduce the following auxiliary terminology relevant to the annotated positions of a\\nCLP program. The inherited positions of the head atoms and the synthesized positions of the body\\natoms are called input positions. Similarly, the synthesized positions of the head atoms and inherited\\npositions of the body atoms are called output positions. Note that dual positions are not strictly\\nclassified as input or output ones. ',\n",
       "                'Alternatively, if we say that a position is annotated as an output\\nwe mean that it is annotated as inherited provided it is a position in a body atom, or annotated as\\nsynthesized if it is a position of the head of a clause.\\n\\nExample 4 Consider the following CLP program:\\n\\n1. p(X,Y) :- r(X), q(X,Y).\\n2. r(3).\\n3. q(U,V) :- {U+V = 5}.\\n\\nThe corresponding annotated proof tree for the goal p(X, Y ) is presented in Figure 4, where the\\nactual positions have been replaced by I (the input positions) and by O (the output positions):\\n\\n) :- r(I 1. p(O  ,O ) , q(O  , I  ).\\n\\n3. q(I  , O ) : - {O , I  = O }.r(O 2. . )\\n\\nFigure 4: The annotated proof tree for Example 5\\n\\nThe annotation reflects groundness propagation during the computation, as discussed below. The\\nvariables X and Y of p(X, Y ) are annotated as output, since they are ground at success of p, and\\np(X, Y ) is a head atom. For the same reason the argument of the fact r(3) in node 2 is annotated as\\noutput. The variable U in the first argument of the predicate q(U, V ) in node 3 is ground at call, so it\\nis annotated as input, while V is ground at success of q so it is annotated as output.\\n\\nIn a CLP program groundness of a position depends generally on the used constraint solver.\\nMonitoring the execution, also in this case, we are able to annotate certain positions as inputs or\\noutputs. For example the indomain(X) constraint of CHIP instantiates X to a value in its domain,\\nso that X is an input position. Rational solvers can usually solve linear equations. For example in\\nthe rational constraint Y = 2 ∗ X + Z, X can be annotated input if Y an Z are output.\\n\\n5.2 Directional slicing of derivation trees\\nHaving input/output information for positions of a derivation tree, we then add directions to its de-\\npendence graph. The following definition describes how it can be achieved.\\n\\nDefinition 7 Directed Dependency Graph of a Proof Tree\\nLet T be a proof tree, TG = (TreePos(T ),∼T ) its proof tree dependence graph, then the directed\\ndependence graph of T (P ) can be defined as:\\nTDG = (TreePos(T ),→T ), where:\\n\\n• α →T (G) β if α ∼T (G) β is a transition edge, α is an output position and β is an input position\\n\\n• α →T (G) β if α ∼T (G) β is a local edge, α is an input position and β is an output position\\n\\n• α →T (G) β and β →T (G) α in every other case when α ∼T (G) β\\n\\n\\n\\n10 AADEBUG 2000\\n\\nFrom the definition of →T (G) assuming correctness of the annotation we find that if α is a position\\nof X in T and it is annotated as input or as output then C(T ) binds X to a single value. This value\\nis determined by the constraints connected with those positions that are in the set {β|β →∗\\n\\nT (G) α}.\\nThus we have:\\n\\nProposition 3 {β|β →∗\\n\\nT (G) α} is a slice of T with respect to α.\\n\\nThese slices are usually more precise than in the case when the groundness information is not\\nused.\\n\\nThe concept of directed dependency graph can be extended to programs and used for static slic-\\ning. This requires good methods for static groundness analysis to infer annotations for program\\npositions. Some suggestions for that can be found in [16].\\n\\n6 A Prototype Implementation\\n\\nWe developed a prototype in SICStus Prolog for dynamic backward slicing of constraint logic pro-\\ngrams written in SICStus. The tool handles a realistic subset of Prolog, including constructs such\\nas cut, if-then and or. The inputs of the slicing system are: the source code, a test case (a goal)\\nand (after the execution) the execution traces given by the Prolog interpreter. From this information\\nthe Directed Proof Tree Dependence Graph (Definition 7) may be constructed. The following three\\ntypes of slice algorithms were implemented (see Figure 5):\\n\\n1. Proof tree slice\\nIn this case the user chooses an argument position of the created Proof Tree, and the slice is\\nconstructed with respect to this proof tree position using the Directed Proof Tree Dependency\\nGraph (see Definition 7). This kind of slice is useful when the user is interested in the data\\ndependences of the Proof Tree.\\n\\n2. Dynamic slice\\nThis case is very similar to 1, but the constructed slice of the Proof Tree is mapped back to\\nthe program. This is the classic dynamic slice approach [12], as in the case of procedural\\nlanguages. So this slice provides a slice of the program.\\n\\n3. Program position slice\\nIn this case the user selects a program position. The system provides all instances of this\\nprogram position in the Proof Tree, creates the proof tree slice for every instance, then the\\nunion of these slices are constructed and mapped back to the program. So this algorithm also\\nprovides a slice of the program, which shows all dependences of a program position for a given\\ntest case.\\n\\nA graphical interface draws the proof tree (see Figure 7), marked with different colored nodes that are\\nin the Proof tree slice, and in the case of a dynamic slice and program position slice the corresponding\\nslice of the program is highlighted. The label of the nodes identify the nodes of the proof tree\\n',\n",
       "                'including the name of the predicate and the annotation of its arguments.\\n\\nIn the implementation we applied a very simple annotation technique: the inherited positions\\nwere those which were ground at the time of calling, while synthesized positions were those which\\nwere ground at success. This method provides precise annotation, because we continuously extract\\ninformation from the actual state of the constraint store. However, in the current implementation\\nslicing can only be done on argument positions. If an argument includes several variables it is not\\npossible to distinguish between them, which makes the constructed slice ”less precise” (compared\\nto the minimal slice). So, our aim is to improve the existing implementation, extend it to variable\\npositions.\\n\\nIn the present version of the tool the sliced proof tree corresponds to the first success branch of\\nthe SLD tree. As the proof tree slice definition is quite general, there is no real difficulty in applying\\n\\n\\n\\nSlicing of Constraint Logic Programs 11\\n\\nProof Tree\\n\\nslice\\n\\nproof tree position\\n\\nslice\\n\\nProof Tree\\n\\nproof tree position\\n\\nProgram\\n\\nsliceφT\\n\\nProof Tree Slice Dynamic Slice\\n\\nφ-1\\n\\nT\\n (p)\\n\\nφ  (p)\\nT\\n\\n-1\\n\\nsliceφ-1\\nT (p)\\n\\nφ-1\\n\\nT\\n\\nslice\\n\\np\\n\\nφT\\n\\nunion of\\n\\nthe slices\\n\\nProof TreeProgram\\nProgram\\n\\nProgram Position slice\\n\\nFigure 5: Proof Tree, Dynamic and Program Position Slice.\\n\\nthe technique to all success branches of SLD tree. The extension to failure branches is discussed in\\n[6]. Currently we are working on an implementation of these extensions.\\n\\nSystematic slicing experiments were performed on a number of constraint logic programs (writ-\\nten in SICSTus Prolog). Each of them was executed with a number of test inputs to collect data\\nabout the relative size of a slice with respect to the proof tree, depending on the choice of the po-\\nsition. The selected application programs [9, 13] had different language structures (use of cut, or,\\nif-then, databases, compound constraint), and were of different size.\\n\\nThe summarized data of the test results on proof tree slicing is listed in Table 1. The comparison\\nof the three kind of slices with respect to the number of nodes are shown in Figure 6.\\n\\nPROGRAM NUMBER OF NUMBER OF NUM. OF COMP- AVERAGE SIZE OF AVERAGE SIZE OF\\nCLAUSES TEST CASES UTED SLICES THE PROOF TREE SLICES\\n\\nNODE ARG. POS. NODE ARG.POS.\\n1 LIGHTMEAL 11 1 17 9 15 44.64 % 41.17 %\\n2 CIRC 5 2 139 33.35 54.09 35.14 % 54.44 %\\n3 SUM 6 4 626 80.26 120.77 30.46 % 49.34 %\\n4 FIB 4 6 1349 399.57 533.51 7.56 % 8.53 %\\n5 SCHEDULING 20 1 575 134 390 51.21 % 71.66 %\\n6 PUZZLE 30 2 1363 227.57 607.82 19.05 % 14.93 %\\n\\nTable 1: Proof Tree Slice\\n\\nIt should be mentioned that the average slice size (in percent) in these experiments had no corre-\\nlation with the size of the program. The average slice size was 32% of the number of executed nodes\\nand 40% of the executed argument positions.\\n\\nThe intended application of our slicing method is to support debugging of constraint programs.\\nA bug in a program shows up as a symptom during the execution of the program on some input. This\\nmeans that in some computation step (i.e. in some derivation tree) a variable of the program is bound\\nin a way that does not conform to user expectations. A slice of the derivation tree with respect to\\nthis occurrence of the variable can be mapped into the text of the program and will identify a part of\\nthe program where the undesired binding was produced. This would provide a focus for debugging,\\nwhatever is the debugging technique used. Intersection of the slices produced for different runs of\\nthe buggy program may further narrow the focus.\\n\\nIn particular, our slicing technique can be combined with Shapiro’s algorithmic debugging [15],\\ndesigned originally for logic programs. As shown in [11] the slice of a derivation tree of a logic\\nprogram may reduce the number of queries of algorithmic debugger. This technique can also be\\napplied to the case of algorithmic debugging of CLP programs discussed in [19].\\n\\n\\n\\n12 AADEBUG 2000\\n\\nFigure 6: Comparison of the Proof Tree Slice, Dynamic Slice and the Program Position Slice.\\n\\n7 Related Work\\n\\nProgram slicing has been widely studied for imperative programs [4, 10, 8, 12, 7]. To our knowledge\\nonly a few papers have dealt with the problem of slicing logic programs, and slicing of constraint\\nlogic programs has not been investigated till now.\\n\\nWe provided a theoretical basis for the slicing of proof trees and programs starting from a se-\\nmantic definition of the constraint set dependence. This applies as well to the special case of logic\\nprograms (the Herbrand domain). In particular it justifies the slicing technique of Gyimóthy and\\nPaakki [5] developed to reduce the number of queries for algorithmic debugger and makes it possible\\nto extend the latter to the general case of CLP. The directional slicing of Section 5 is an extension of\\nthis technique to the general case of CLP.\\n\\nSchoening and Ducassé [14] proposed a backward slicing algorithm for Prolog which produces\\n',\n",
       "                'executable slices. For a target Prolog program they defined a slicing criterion which consists of a goal\\nof P and a set of argument positions Pa, along with a slice S as a reduced and executable program\\nderived from P . An executable slice is usually less precise but it may be used for additional test\\nruns. Hence the objectives of their work are somewhat different from ours, and their algorithm is\\napplicable to a limited subset of Prolog programs.\\n\\nIn [19] Zhao et al defined some static and dynamic slices of concurrent logic programs called\\nliteral dependence nets. They presented a new program representation called the argument depen-\\ndence net for concurrent logic programs to produce static slices at the argument level. There are\\nsome similarities between our slicing techniques and Zhao’s methods, since we also rely on some\\ndependency relations. However, the focus of our work has been on CLP not on concurrent logic\\nprograms, and our main aim has been a declarative formulation of the slicing problem whic provides\\na clear reference basis for proving the correctness of the proposed slicing methods.\\n\\nThe results of the ESPRIT Project DiSCiPl [2] show the importance of visualisation in the de-\\nbugging of constraint programs. Our tool provides a rudimentary visualisation of the sliced proof\\ntree. It was pointed out by Deransart and Aillaud [1] that abstraction techniques are needed in the\\nvisualisation of the search space. Program position slicing, if applied to all branches of the SLD-tree,\\nprovides yet another abstraction of the search space.\\n\\n 60 50 40 Proof tree slice 30 - IDynamic slice Program position slice 20 SLICE SIZE (%) 10 0 - 1 2 3 4 5 6 PROGRAMS \\n\\n\\n\\nSlicing of Constraint Logic Programs 13\\n\\nFigure 7: Displayed program and proof tree slices.\\n\\n8 Conclusions\\n\\nThe paper offers a precise declarative formulation of the slicing problem for CLP. It also gives a\\nsolid reference basis for deriving various techniques of slicing CLP programs in general and for\\nlogic programs treated as a special case. This technique was illustrated by deriving the directional\\ndata flow slicing technique for CLP, which is an extension of [5] applied to CLP. As a side effect, the\\nlatter, which was presented in somewhat pragmatic setting, obtains a theoretical justification.\\n\\nThe paper presents also a prototype slicing tool using this technique. The experiments with\\nthe tool show that the obtained slices were quite precise in some cases, and on average provided a\\nsubstantial reduction of the program.\\n\\nThe future work will focus on the application of slicing techniques to constraint programs de-\\nbugging. Two aspects being considered. Firstly, in the manual debugging of CLP programs it is\\nnecessary to support user with a tool that facilitates the understanding of the program. We believe\\nthat a future version of our slicer equipped with suitable visualisation features could be very suitable\\nfor this purpose. Secondly, the slicing of a derivation tree can often reduce the number of queries\\nin algorithmic debugging of logic programs [15]. (The algorithmic debugging technique has been\\nextended to CLP [17]).\\n\\nAs a first step in this direction we are going to integrate our CLP slicing tool with the IDTS\\n\\n DOTTY node(1,0,0,2,[i,o,i,0]) goal(prg,4) node(2,1,1,1,[i,o]} node(8,1,1,2, [1 ,- ]) goal(p,2) goal(q,2) f node(3,2,2,1,[i,o] node(6,2,2,2,[i]] \"node(9,8,2,1,[1,0]) node(14,8,2,2,[d]) goal( sum,2) goal(control,1) goal( sum,2) goal( {},1) node(4,3,3,1,[i,o]; node(5,3,3,2,[d]) goal( {},1) node(7,6,3,1,[i]) node( 10,9,3,1,[i,o]} node(13,9,3,2,[d]) goal(sum,2) goal({},1) goal( sum,2) goal( {},1) node(11,10,4,1,[1,0]) node(12,10,4,2,[d]) goal(sum,2) goal({},1) prec File Edit View Help ? : - use _module ( library (clpr) ) . prg (L1, Sum, L2 , DSum) : - p ( Ll, Sum) , q (L2, DSum) . p (Ll, Sum) : - sum (Ll, Sum) , control ( Sum) . control ( Sum) : - {Sum =< 100.0}, q (L2, DSum) : - sum ( L2, Sum2) , {DSum=2. 0*Sum2} . sum ( [], 0. 0) sum ( [X] Rem , Sum) : - sum (Rem, Suml ) {Sun =X+Sum1} Ready. \\n\\n\\n\\n14 AADEBUG 2000\\n\\nalgorithmic debugger [11], originally developed for pure logic programs.\\n\\nAcknowledgments\\n\\nThe work of the first and second authors was supported by the grants OTKA T52721 and IKTA\\n8/99.\\n\\nReferences\\n[1] P. Deransart and C. Aillaud: Towards a Language for CLP Choice-tree Visualisation, In: P. De-\\n\\nransart, M. Hermenegildo, and J. Małuszyński, (editors), Analysis and Visualization Tools for\\nConstraint Programming, LNCS. Springer Verlag, 2000 (to appear).\\n\\n[2] P. Deransart, M. Hermenegildo, and J. Małuszyński, (editors), Analysis and Visualization Tools\\nfor Constraint Programming, LNCS. Springer Verlag, 2000 (to appear).\\n\\n[3] P. Deransart and J. Małuszyński: A grammatical view of logic programming. The MIT Press\\n1993.\\n\\n[4] T. Gyimóthy, Á. Beszédes and I. Forgács: An Efficient Relevant Slicing Method for Debugging.\\nIn Proceedings of 7th European Software Engineering Conference (ESEC’99), LNCS 1687\\n',\n",
       "                'Springer Verlag, pages 303-322, Toulouse, France, September 1999.\\n\\n[5] T. Gyimóthy and J. Paakki: Static Slicing of Logic Programs. In Proceedings of Second Inter-\\nnational Workshop on Automated and Algorithmic Debugging (AADEBUG’95), pages 85-105,\\nSaint Malo, France, May 1995.\\n\\n[6] Harmath L., Szilágyi Gy., Gyimóthy, T., Csirik J.: Dynamic Slicing of Logic Programs. Pro-\\ngram Analysis and verification, Fenno-Ugric Symposium (FUSST’99), pages 101-113, Tallin,\\nEstonia 1999.\\n\\n[7] S. Horwitz, T. Reps and D. Binkley: Interprocedural Slicing Using Dependence Graphs. In\\nProceedings of ACM Transactions on Programming Languages and Systems 12, pages 26-61,\\n1990.\\n\\n[8] S. Horwitz and T. Reps: The Use of Program Dependence Graphs in Software Engineering.\\nIn Proceedings of the Fourteenth International Conference on Software Engineering , pages\\n392-411, Melbourne, Australia, May 1992.\\n\\n[9] J.Jaffar and M.J.Maher: Constraint logic programming: A survey. The Journal of Logic Pro-\\ngramming 19/20:503-582, 1994.\\n\\n[10] M. Kamkar and P. Fritzson: Evaluation of Program Slicing tools. In 2nd International Workshop\\non Automated and Algorithmic Debugging (AADEBUG’95) , pages 51-69, Saint Malo, France,\\nMay 1995.\\n\\n[11] G. Kókai, L Harmath, T. Gyimóthy: Algorithmic Debugging and Testing of Prolog Programs,\\nIn Proceedings of the Fourteenth International Conference on Logic Programming, Eighth\\nWorkshop on Logic Programming Environments (ICLP’97), pages 14-21, Leuven, Belgium,\\nSeptember 1997.\\n\\n[12] B. Korel and J. Rilling: Application of Dynamic Slicing in Program Debugging. In Proceedings\\nof the Third International Workshop on Automatic Debugging (AADEBUG ’97), Linköping,\\npages 43-59, Sweden, May 1997.\\n\\n\\n\\nSlicing of Constraint Logic Programs 15\\n\\n[13] K. Marriott and P.J. Stuckey: Programming with Constraints. An Introduction. The MIT Press,\\n1998\\n\\n[14] S. Schoening and M. Ducassé: A Backward Slicing Algorithm for Prolog. In Proceedings of\\nThird International Static Analysis Symposium SAS’96, LNCS 1145, 317-331, Springer-Verlag\\n1996.\\n\\n[15] E. Shapiro: Algorithmic Debugging. The MIT Press, 1983.\\n\\n[16] Gy. Szilágyi, T. Gyimóthy, J. Maluszyński: Slicing of Constraint Logic Programs. Technical\\nReport, Linköping University Electronic Press 1998/020, www.ep.liu.se/ea/cis/1998/002.\\n\\n[17] A. Tessier and G. Fèrrand. Declarative Diagnosis in the CLP Scheme, In: P. Deransart, M.\\nHermenegildo, and J. Małuszyński, (editors), Analysis and Visualization Tools for Constraint\\nProgramming, LNCS. Springer Verlag, 2000 (to appear).\\n\\n[18] F. Tip: A survey of Program Slicing Techniques. Journal of Programming Languauges, Vol.3.,\\nNo.3, pages 121-189, September, 1995.\\n\\n[19] J. Zhao, J. Cheng and K. Ushijima: Slicing Concurrent Logic Programs. In Proceedings of\\nSecond Fuji International Workshop on Functional and Logic Programming, pages 143-162,\\n1997.\\n\\n\\n'],\n",
       "               'language': 'en',\n",
       "               'score': 3.1176469326019287,\n",
       "               'vectorized': True}),\n",
       "             ('aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMS8wMDExMDMwdjEucGRm0',\n",
       "              {'title': 'arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000',\n",
       "               'name': '0011030v1.pdf',\n",
       "               'location': 'https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0011/0011030v1.pdf',\n",
       "               'caption': 'A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1 Constraint Logic Programming  Constraint logic programming (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers).',\n",
       "               'index': 'cogsrch-index-files',\n",
       "               'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n00\\n\\n11\\n03\\n\\n0v\\n1 \\n\\n [\\ncs\\n\\n.A\\nI]\\n\\n  2\\n1 \\n\\nN\\nov\\n\\n 2\\n00\\n\\n0\\n\\nLogic Programming Approaches for\\n\\nRepresenting and Solving Constraint\\n\\nSatisfaction Problems: A Comparison\\n\\nNikolay Pelov, Emmanuel De Mot, and Marc Denecker\\n\\nDepartment of Computer Science, K.U.Leuven\\nCelestijnenlaan 200A, B-3001 Heverlee, Belgium\\n\\nE-mail: {pelov,emmanuel,marcd}@cs.kuleuven.ac.be\\n\\nAbstract. Many logic programming based approaches can be used to\\ndescribe and solve combinatorial search problems. On the one hand there\\nis constraint logic programming which computes a solution as an answer\\nsubstitution to a query containing the variables of the constraint satis-\\nfaction problem. On the other hand there are systems based on stable\\nmodel semantics, abductive systems, and first order logic model gen-\\nerators which compute solutions as models of some theory. This paper\\ncompares these different approaches from the point of view of knowledge\\nrepresentation (how declarative are the programs) and from the point of\\nview of performance (how good are they at solving typical problems).\\n\\n1 Introduction\\n\\nConsistency techniques are widely used for solving finite domain constraint sat-\\nisfaction problems (CSP) [19]. These techniques have been integrated in logic\\nprogramming, resulting in finite domain constraint logic programming (CLP)\\n[20]. In this paradigm, a program typically creates a data structure holding the\\nvariables of the CSP to be solved, sets up the constraints and uses a labelling\\ntechnique to assign values to the variables. The constraint solver uses consistency\\ntechniques to prune the search. This leads to a rather procedural programming\\nstyle. Moreover, the problem description is not very declarative because the map-\\nping between domain variables and their value has an indirect representation in\\na term structure.\\n\\nIn this paper, we compare CLP and three computational paradigms allowing\\nproblem solving based on more declarative representations. A common feature of\\nthese approaches is that the relation between the CSP variables and their values\\nis encoded as a predicate or function relating identifiers of the CSP variables\\nwith their value. E.g. in the graph coloring problem, the predicate relates node\\nnumbers with colors. This representation allows for a more natural declarative\\nrepresentation of the problem.\\n\\nOne approach is specification in first order logic. As pointed out in [12], one\\ncan represent a CSP as a first order logic theory such that (part of) its models\\n\\nhttp://arXiv.org/abs/cs/0011030v1\\n\\n\\ncorrespond to the solutions of the CSP. Hence first order model generators such\\nas SEM [24] can be used to solve such problems.\\n\\nThe two other approaches use extensions of logic programming. Recently, a\\nlogic programming paradigm based on stable model semantics [6] has emerged.\\nNiemelä [14] proposes it as a constraint programming paradigm, Marek and\\nTruszczyński [13] introduce Stable Logic Programming and Lifschitz [11] pro-\\nposes Answer Set Programming. As described in [13], the methodology of these\\napproaches is to encode a computational problem by a logic program such that\\nits stable models represent the solutions. A number of efficient systems for com-\\nputing stable models have been developed. Of these, Niemelä’s smodels [15, 14]\\nis considered one of the most performant systems.\\n\\nAbduction [8] uses a similar predicate representation for the relation between\\nthe identifiers of CSP variables and their value. This predicate is declared to be\\nopen or abducible. Constraining this relation to be a solution, an abductive\\nsystem will return models of the abducible which are solutions of the CSP.\\n\\nWe use some typical CSP problems to compare the merits of the various\\napproaches. One experiment is in graph coloring. We have compared the rep-\\nresentation and the performance of CLP with the three other approaches in a\\nsequence of experiments where the size of the graph increases and the number\\nof colors remains constant. Another experiment is the n-queens problem where\\nboth the domain size and the number of constraints increases with increasing\\nproblem size. We also report on experiments using CLP, stable logic program-\\nming and abduction for solving a complex real world scheduling problem. For\\neach different system, we have tried to use any special features provided by it.\\n\\nIn Section 2 we review in more detail the various approaches and systems,\\nfocusing mainly on the knowledge representation aspects. Section 3 reports on\\nthe experiments and we conclude in Section 4.\\n\\nWe are not aware of any previous work which compares this wide range of\\nlogic based systems for their suitability in solving CSP problems. Mackworth [12]\\nexplores the space of possible CSP formalizations but assesses neither the quality\\nfrom point of view of knowledge representation nor the performance of actual\\nsystems. Also, approaches based on stable model semantics and abduction are\\nnot included in his work. ',\n",
       "                'This paper is an extension and revision of [17] which\\nfocuses more on the formal relations between the declarative specifications of\\nthe problems on the different systems.\\n\\nOne more problem which uses aggregate functions is included in the present\\npaper. So is an additional experiment for finding all solutions of the n-queens\\nproblem. Finally, some comments from the authors of the different systems were\\ntaken into account.\\n\\n2 Formalisms and Systems\\n\\nA constraint satisfaction problem (CSP) is usually defined as a finite set of con-\\n\\nstraint variables X = {X1, . . . , Xn} (the variables of the CSP), a finite domain\\nDi of possible values for each variable Xi, and a finite set of constraint relations\\n\\n\\n\\nR where each r ∈ R is a constraint between a subset of the set X of variables. A\\nsolution is an instantiation of the variables of X which satisfies all the constraints\\nin R.\\n\\n2.1 Constraint Logic Programming\\n\\nConstraint logic programming (CLP) [7] is an extension of logic programming\\nwhere some of the predicate and function symbols have a fixed interpretation over\\nsome subdomain (e.g. finite trees or real numbers). Special purpose constraint\\nsolvers are integrated with a logic programming system for efficient reasoning on\\nthese symbols. This results in a very expressive language which can efficiently\\nsolve problems in many domains.\\n\\nVan Hentenryck [20] pioneered the work on finite domain constraint logic\\nprogramming, CLP(FD), by introducing domain declarations for the logic vari-\\nables and integrating consistency techniques as part of the SLD proof procedure.\\nA CLP(FD) system supports standard arithmetic relations (=, 6=, <) and func-\\ntions (+,−, ∗) on the natural numbers. A typical formulation of the n-queens\\nproblem is as follows:\\n\\nqueens(N, L)←\\nlength(L, N),\\ndomain(L, 1, N),\\nconstrain all(L),\\nlabeling(L).\\n\\nconstrain all([]).\\nconstrain all([X |Xs])←\\n\\nconstrain between(X, Xs, 1)\\nconstrain all(Xs).\\n\\nconstrain between(X, [], N).\\nconstrain between(X, [Y |Y s], N)←\\n\\nsafe(X, Y, N),\\nN1 is N + 1,\\nconstrain between(X, Y s, N1).\\n\\nsafe(X1, X2, D)←\\nX1 6= X2, abs(X1 −X2) 6= D.\\n\\nExecuting the query queens(n, L) first creates a list L with n variables where\\nthe ith variable gives the column position of the queen on row i. Then the\\nconstraints expressed with the safe/3 predicate are added by using two nested\\nrecursive predicates. Such procedural code for setting up constraints and the\\nencoding of the solution in a large data structure results in a rather procedural\\nstyle which is typical for the CLP approach.\\n\\n2.2 First Order Logic: Model Generation\\n\\nThe most elegant solution for the n-queens problem is using many sorted first\\norder logic and first order model generation. Systems like FINDER and SEM\\n\\n\\n\\n[24] are examples. One can introduce functions (with the sorts of their domain\\nand range) and predicates (with the sorts of their domains and the sort bool as\\nrange). In addition, functions can be restricted to be injective, bijective, . . . This\\nallows to express the n-queens problem very concisely as:\\n\\nD = {1..n}\\n\\npos : D → D (bijection)\\n\\nabs(pos(X1)− pos(X2)) 6= X2 −X1 ← X1 < X2.\\n\\nThe first line declares D as a sort with interpretation consisting of the set of\\nintegers 1 to n. The following line introduces the function pos/1 as a bijection\\nfrom D to D. Hence, the range of the function is a permutation of its domain.\\nThis function represents the column positions of the queens. The only remaining\\nconstraint is that queens have to be on different diagonals. This is expressed by\\nthe formula on the third line using the predefined functions abs/1 and −/2. Due\\nto symmetry, one need only to verify the constraint for pairs of queens X1, X2\\n\\nsuch that X1 < X2.\\n\\nSolutions are given by the interpretation of the pos/1 function in the models\\nof this theory. In principle, this approach is applicable on any CSP problem by\\nrepresenting the CSP variables by logical constants. However, in most cases, CSP\\nvariables are just an encoding of some attribute of a set of first order objects,\\nsuch as the position of a queen or the color of a node in a graph. In such cases,\\nthere is no need to introduce the CSP variable. The attribute can be represented\\ndirectly as a function or predicate on these objects (e.g. pos).\\n\\nAs the domains of all sorts are finite, SEM first computes the grounding\\nof the theory and then uses backtracking combined with various inference and\\nsimplification rules to guide the search for models [24].\\n\\n2.3 Stable Logic Programming\\n\\nIn [14], Niemelä proposes logic programming with the stable model semantics [6]\\nas a constraint logic programming paradigm. The underlying idea is to represent\\na problem as a set of rules, each rule being the declarative expression of a piece\\nof knowledge about the problem domain and such that the stable models of the\\nwhole program are constrained to be solutions of the problem.\\n\\nThe smodels system [15] is an efficient implementation of the stable model\\nsemantics. ',\n",
       "                'It works with propositional rules and a special pre-processing program\\nis used for grounding strongly range restricted logic programs. The implementa-\\ntion combines bottom-up inference with backtracking search and employs pow-\\nerful pruning methods. A recent extension of the system [16] introduces choice\\nrules:\\n\\nl {l1, l2, . . . ln} u← B.\\n\\n\\n\\nwhere l1, l2, . . . ln are literals. The semantics of such a rule is that if the body B\\nis true then at least l and at most u literals among li should be true in a stable\\nmodel of the program.\\n\\nFollowing [14] and [16], the program for the n-queens problems can be for-\\nmulated as:\\n\\nd(1..n).\\n\\n1 {pos(X, Y ) : d(Y )} 1← d(X).\\n1 {pos(X, Y ) : d(X)} 1← d(Y ).\\n\\n← d(X1), d(Y1), d(X2), d(Y2), pos(X1, Y1), pos(X2, Y2),\\nX1 < X2, X2 −X1 = abs(Y1 − Y2).\\n\\nSolutions are given by the pos(i, j) atoms in the stable models of the program.\\nThe first line defines that d/1 is a domain with elements 1..n with n the size of\\nthe board. The first choice rule is used to define the solution space of the problem\\nby stating that for each X in the domain d(X), there exists exactly one Y such\\nthat pos(X, Y ) is true. The colon notation denotes an expansion of pos(X, Y )\\nfor every value of Y . Similarly, the second choice rule expresses that there is\\nexactly one queen on each column. The last rule defines the final constraint of\\nthe problem: no two queens on the same diagonal. Again, the “<” constraints in\\nthese rules eliminate instances which are redundant due to symmetry. The main\\ndifference with the first order logic specification is that the mapping between\\nqueens and their position is now represented by a predicate. Declaring that this\\npredicate represents a bijective function is succinctly expressed by the two choice\\nrules.\\n\\n2.4 Abduction\\n\\nAbductive logic programming [8] extends the logic programming paradigm with\\nabductive reasoning. An abductive logic program has three components: (1) a\\nlogic program P , (2) a set of predicates A called abducibles or open predicates,\\nand (3) a set of integrity constraints I. The abducibles are predicates not defined\\nin the program. The task of an abductive system is to find a set ∆ of ground\\nabducible atoms such that the integrity constraints are true in the logic program\\nconsisting of P ∪∆; formally: P ∪∆ |= I.\\n\\nKakas and Michael proposed an integration of CLP and an abductive logic\\nprogramming system [9]. Originally, it was defined only for definite programs\\nand integrity constraints and in [10] it was extended to deal with negation as\\nfailure through abduction in a similar way as in [5]. One restriction of ACLP\\nis that integrity constraints need to be of the form ← a(X̄), B, where a is an\\nabducible. As we will see, this forces sometimes to reformulate some constraints\\nby an additional recursion. Such restrictions are not present in SLDNFAC [3], a\\nmore recent integration of an abductive system with CLP that is based on the\\nmore general abductive procedure SLDNFA [2].\\n\\n\\n\\nThe SLDNFAC system uses ID-Logic [1] as specification language which is\\ntransformed into an abductive logic program by using a Lloyd-Topor transfor-\\nmation. The specification of the n-queens problem is:\\n\\nd(1..n).\\n\\nopen function(pos(d, d)).\\n\\nY1 6= Y2 ∧X2 −X1 6= Y2 − Y1 ∧X2 −X1 6= Y1 − Y2\\n\\n⇐ pos(X1, Y1) ∧ pos(X2, Y2) ∧X1 < X2.\\n\\nThe first line of the program defines d/1 as a domain predicate with the integers\\n1..n as elements (defining rows and columns). The next line states that the\\npredicate pos/2 represents an open function in the defined domain. It is used to\\nrepresent the column position of a queen in a row. Finally there is a constraint\\nsaying that two queens can not be on the same column and diagonal. This\\nrepresentation is almost identical to the FOL specification of section 2.2. The\\nmain difference is that the open function is represented by a predicate.\\n\\nAs mentioned, ACLP does not allow function declarations. Consequently, the\\nfact that pos predicate represents a function must be expressed by explicit con-\\nstraints. A standard way to axiomatize that the abductive predicate pos(X, Y )\\nshould be true for each X in the domain d(X) is by using the following rule and\\nintegrity constraints:\\n\\nhas pos(X)← d(Y ), pos(X, Y ).\\n← d(X), not has pos(X).\\n\\nUnfortunately, the integrity constraint does not satisfy the ACLP’s restriction\\nthat at least one positive abductive atom should occur in it. Hence, these axioms\\nhave to be reformulated using a recursive program which generates a position\\nfor each queen. The specification for the ACLP system is:\\n\\nA = {pos/2}\\n\\nproblem(N)← nqueens(N, N).\\nnqueens(0, N).\\nnqueens(X, N)← X > 0, Y in 1..N, pos(X, Y ),\\n\\nXnext is X − 1, nqueens(Xnext, N).\\n\\nattack(X1, Y1, X2, Y2)← Y1 = Y2.\\nattack(X1, Y1, X2, Y2)← Y1 + X1 = Y2 + X2.\\nattack(X1, Y1, X2, Y2)← Y1 −X1 = Y2 −X2.\\n\\n← pos(X1, Y1), pos(X2, Y2), X1 < X2, attack(X1, Y1, X2, Y2).\\n\\nThe n-queens problem is solved by solutions of the abductive query← problem(n).\\n',\n",
       "                'The ACLP representation is in the middle of the declarative FOL representation\\nand the more procedural CLP representation.\\n\\n\\n\\n3 Experiments\\n\\n3.1 The Systems\\n\\nThe finite domain CLP package is the one provided with ECLiPSe version 4.2.\\nBoth abductive systems, ACLP [10] and SLDNFAC, [3] are meta interpreters\\n\\nwritten in Prolog, running on ECLiPSe version 4.2 and making use of its fi-\\nnite domain library. For all these systems, a search strategy which first selects\\nvariables with the smallest domain which participate in the largest number of\\nconstraints was used.\\n\\nThe model generator SEM version 1.7 is a fine tuned package written in C.\\nsmodels version 2.25, the system for computing stable models, is implemented in\\nC++ and the associated program used for grounding is lparse version 0.99.54.\\nAll experiments have been done on the same hardware, namely Pentium II.\\n\\n3.2 Graph Coloring\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n10000\\n\\n10 100 1000\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nNodes\\n\\nGraph Coloring\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 1. Graph coloring\\n\\nOur first experiment is done with 4-colorable graphs. We used a graph gen-\\nerator1 program which is available from address http://web.cs.ualberta.ca/\\n1 The graphs have been generated with the following parameters: 0, 13, 6, n, 4, 0.2, 1,\\n\\n0 where n is the number of vertices. Graph-coloring problems generated with these\\nparameters are difficult.\\n\\n\\n\\n~joe/Coloring/Generators/generate.html. We applied the systems in a se-\\nquence of experiments with graphs of increasing size and constant number of\\ncolors. We have modified only one parameter of the problem namely the number\\nof vertices. Figure 1 gives the results of solving the problem with the different\\nsystems. Both axes are plotted in a logarithmic scale. On the x-axis we have put\\nthe number of vertices. Not surprisingly, CLP is the fastest system. The times\\nfor smodels is second best on this problem. We assume it is in part because of\\nthe very concise formulation. Using the so called technique of rules with excep-\\ntions [14], the two rules needed to describe the space of candidate solutions also\\nencode the constraint that the color is a function of the vertex. Hence there is\\nonly one other rule, namely the constraint that two adjacent vertices must have\\na different color. The difference with CLP is almost two orders of magnitude\\nfor the largest problems. The times reported for smodels do not include the\\ntime for grounding the problem, these times only consist of a small part of the\\ntotal time. Grounding the problem for 650 nodes takes only 10 seconds, whereas\\nsolving the problem takes over 100 seconds. SLDNFAC is slightly worse than\\nsmodels. Although meta-interpretation overhead tends to increase with prob-\\nlems size, the difference with smodels grows very slowly. The model generator\\nSEM deteriorates much faster and runs out of memory for the larger problems.\\nThe fact that it grounds the whole theory is a likely explanation. The differ-\\nence with smodels supports the claim that smodels has better techniques for\\ngrounding. ACLP performs substantially worse than SLDNFAC and also dete-\\nriorates faster. The difference is likely due to the function-specification available\\nin SLDNFAC. Contrary to ACLP, SLDNFAC exploits the knowledge that the\\nabducible encodes a function to reduce the number of explicitly stored integrity\\nconstraints.\\n\\n3.3 N-Queens\\n\\nFigure 2 gives the running times for the different systems for finding a first\\nsolution. Both axes are plotted on a linear scale. The time consumed while\\ngrounding is again not included in the graph (for 18 queens, half a second).\\nAgain, CLP gives the best results. SLDNFAC is second best and, although meta-\\ninterpretation overhead increases with problem size, deteriorates very slowly.\\nACLP is third2, with a small difference, probably due to the lack of the function-\\nspecification mentioned in the section above. The next one is SEM. It runs out\\nof memory for large problems (it needs about 120MB for 27 queens). smodels\\n\\nperforms very poorly on this problem, in particular when compared with its\\nperformance on the graph coloring problem. It is well-known that to obtain good\\nresults for computing the first solution for the n-queens problem, a good search\\nheuristic is needed, like the first fail principle used by the systems based on CLP.\\nWe believe that the bad performance of smodels is explained by the absence of\\n\\n2 The results with ACLP are substantially better than those in the previous paper [17].\\nThis is due to the removal of a redundant and time consuming complete consistency\\ncheck after the processing of each new CLP constraint.\\n\\n\\n\\n0\\n\\n2\\n\\n4\\n\\n6\\n\\n8\\n\\n10\\n\\n10 15 20 25 30\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 2. N-queens: one solution\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n4 5 6 7 8 9 10 11 12 13\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens (all solutions)\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 3. N-queens: all solutions\\n\\n\\n\\nappropriate heuristics. ',\n",
       "                'This is confirmed by the much better performance of the\\nsystem in computing all solutions.\\n\\nFigure 3 gives the running times for finding all solutions. The y-axis is plot-\\nted on a logarithmic scale. The CLP, ACLP and SLDNFAC systems are based\\non the same finite domain constraint solver, so their convergence is not unex-\\npected. Indeed, the abductive system generates a constraint problem which is\\nequivalent to the problem generated by the CLP program and no backtracking\\noccurs in the abductive system. Hence, its overhead becomes ignorable. Also\\nthe SEM system converges to the same performance as CLP (but runs out of\\nmemory for big problems). In this experiment, the smodels system performs\\nmuch better but is still the slowest system. A likely reason for this is that the\\nnumber of propositional variables in the n-queens problem grows quadratically\\nwith the problem size, in contrast with the graph coloring problem where the\\nnumber of variables grows only linearly (because of a constant number of colors).\\nConsequently, the grounding grows faster for this problem. The CLP consistency\\ntechniques seem to be much less sensitive to the domain size, and this carries\\nover to the abductive systems which reduce the problem to a CLP problem and\\nthen use the CLP solver to search for the solution.\\n\\n3.4 A Real World Problem\\n\\nA Belgian electricity company has a number of power plants divided in geo-\\ngraphic areas. Each power plant has a number of power generating units, each of\\nwhich must receive a given number (usually 1 or 2) of preventive maintenances\\nwith a fixed duration in the course of one year. The computational problem is to\\nschedule these maintenances according to some constraints and optimality crite-\\nria. Some of the constraints are: some time slots are prohibited for maintenance\\nfor some units; for each power plant, there is an upper limit on the total number\\nof units in maintenance per week for reasons of availability of personnel; some\\nof the maintenances are fixed in advance, . . . The objective of the problem is to\\nfind a schedule that maximizes the minimal weekly reserve, which is the sum\\nof the capacity of all units not in maintenance minus the expected weekly peak\\nload.\\n\\nThis is a rather difficult problem in several aspects. Firstly, the specification\\nuses aggregate expressions like cardinality and sum (e.g. for each area, there is\\nan upper limit to the total capacity for units in maintenance per week). Only\\nCLP, smodels and SLDNFAC support some form of aggregates and only these\\nsystems were used in our experiment. Also, the search space is very large, as\\nthere are 56 maintenances to be scheduled in 52 weeks which makes about 5652\\n\\ncombinations3. The company provided a set of constraints for which the optimal\\nsolution was known to have a minimal week reserve of 2100 (100%). The three\\nsystems found correct schedules but none was able to find this optimal solution.\\n\\n3 The maintenances with duration of more than one week cannot be scheduled in week\\n52, hence this number is only an upper approximation.\\n\\n\\n\\nThis application was first considered in a context of a master’s thesis [18] and\\nthen reported in [4], where a first attempt was done for integrating the SLDNFA\\nproof procedure with the CLP system ROPE [23, 22]. This early system needed\\n24 hours to reduce the problem to a constraint store. Later on, in [22] several\\ndifferent direct encodings in CLP of the problem were presented and compared.\\nRecently, [21] discussed an extension of the SLDNFAC system with aggregate\\nfunctions and this problem was used as a benchmark.\\n\\nThe first version of the smodels system did not support aggregate expres-\\nsions. A more recent version of the system added a limited support for rules\\nwith a body consisting of a single cardinality or sum constraint [16] and allowed\\nus to specify the problem. However, these aggregate constraints cannot be used\\nfor computing the sum or the cardinality of a set of atoms and we were not\\nable to express the optimization function. By setting increasing lower bounds on\\nthe reserve capacity, branch and bound can be simulated manually. It should be\\nnoted that, because of the very large size of the problem, the specification of the\\nproblem in the smodels system had to be redesigned with special care in order\\nto produce a ground program not exceeding the limits of the system.\\n\\nTable 1 summarizes the results of executing the problem with the different\\nsystems. The first row “Setup” gives the time used for pre-processing the problem\\nspecification. For the abductive systems, this is the time for reducing the high-\\nlevel specification to a set of constraints. For the smodels system this is the\\ntime for grounding the program. The rest of the rows give the times used by the\\nconstraint solver to find a solution with the given quality. The results for CLP\\nare taken from [22] for a standard encoding of the problem4 and the program\\nwas run under SICStus Prolog.\\n\\nReserve CLP SLDNFACsmodels\\n\\nSetup 45 36.4\\n\\n',\n",
       "                '1900 63.2 8.07\\n2000 7.71 62.9 >8h\\n2010 25.85 63.8\\n2020 43.73 62.9\\n2030 57.28 63.0\\n2040 71.63 261.1\\n2050 26843.50 871.3\\n\\nTable 1. Power plant scheduling\\n\\nIn the case of SLDNFAC, it can be seen in Table 1 that substantial progress\\nwas made. Rather than the 24h needed in the earlier version [4], the current\\nSLDNFAC procedure only needs 45 seconds for reducing the problem and about\\n15 minutes for finding a solution of level 2050 (97.6%). A solution with reserve\\ncapacity of 2030 (96.5%) was found in less than two minutes. Note that the\\n\\n4 Without using global constraints, like cumulative.\\n\\n\\n\\ntimings for a solution with a reserve capacity of 1900 up to 2030 are similar.\\nThis is explained by the fact that in the five cases the same solution with reserve\\ncapacity of 2030 was computed. The small differences in timings are due to\\nnoise in the measurements. Strange enough, CLP deteriorates when it reaches\\na solution for a reserve capacity of 2050 whereas the SLDNFAC solution does\\nnot. This must be due to the fact that the constraint store built by the CLP\\nsolution differs from the one built by the SLDNFAC solution. This is accidental:\\nin general, constraint stores constructed by a hand made CLP program are more\\nefficient than the ones computed by SLDNFAC. The smodels system needed\\n40 seconds for grounding and the best solution we were able to find was 1900\\n(90.5%) in 8 seconds. We did not find better solutions in reasonable time.\\n\\n4 Conclusion\\n\\nFinite domain CLP is widely accepted as an excellent tool for CSP solving.\\nHowever CLP programs have drawbacks from the point of view of knowledge\\nrepresentation. As explained in Section 2.1, the variables of the CSP have to be\\norganized in a data structure and “procedural” code is required to create this\\ndata structure and to set up the constraints. This level of indirection increases\\nthe conceptual distance between the program and the problem and makes pro-\\ngrams less declarative. Recently, several attempts have been made to introduce\\nformalisms allowing more declarative formalizations. They are based on stable\\nmodel semantics [11, 13, 14] and on abduction [9, 10, 3]. Although these systems\\nhave an expressivity beyond what is needed to describe a CSP (they address\\nnon-monotonic reasoning while CSP solving requires only negation of primitive\\nconstraints), it is worthwhile to compare these systems with CLP which is state\\nof the art for CSP solving. Because both stable models and abduction express\\nsolutions to problems as models of their theory, we have also included first or-\\nder model generators in our study [24]. As argued in Section 2, these three\\napproaches are better than CLP from knowledge representation point of view,\\nthe formalizations are more natural, more readable, conceptually closer to the\\nproblem, in short they are more declarative than CLP programs. Which one of\\nthe three discussed mechanisms is the most declarative is likely a matter of taste\\nand familiarity.\\n\\nInevitably there is a price to be paid for these higher level descriptions. None\\nof the “declarative” systems experimented with comes close to the performance\\nlevel of CLP. This result holds although the CLP system is not favored by\\nthe problem choice. Indeed, in both graph coloring and n-queens problem, all\\nconstraints are disequality constraints which are known to give little propagation.\\n\\nOur experiments show that first order model generators do not scale well\\nand run out of memory for large problem instances even though the size of the\\nground program is smaller compared to smodels. We think that this is not\\nan inherent limitation of the approach but rather that such systems were writ-\\nten with the goal of fast performance and this is visible in our experiemnts. In\\ncontrast, smodels runs in linear space wrt the size of the grounding [15] and\\n\\n\\n\\nwas able to solve all problem sizes. Of the two abductive systems, SLDNFAC\\nsupports a substantially richer formalism and is performing slightly better than\\nACLP. As the two systems follow more or less the same strategy of top-down\\nreduction of integrity constraints and of forwarding the reduced ones to the CLP\\nsolver and as both are implemented as a Prolog meta-interpreter, the difference\\nseems to be mainly due to the support of function specifications. The fact that\\nthe SLDNFAC meta-interpreter outperforms SEM (a fine tuned C implementa-\\ntion) on both problems and compares very well with the C++ implementation of\\nsmodels (it is much better on the n-queens problem while it reaches almost the\\nsame performance on the graph coloring problem) suggest that its overall strat-\\negy is the best one of the three systems for CSP solving. Also the experiments\\nwith the large scheduling problem suggest this: the setup time is acceptable and\\ndifferences in search time seem to be due to differences in the order of traversing\\nthe search space. While the difference with CLP is substantial, a low level imple-\\n',\n",
       "                'mentation or compilation should be able to come close to the performance levels\\nof CLP, offering the best of both worlds: declarative problem formulations and\\nefficient execution. However, SLDNFA, the procedure underlying SLDNFAC, is\\ncomplex, hence building a direct implementation is a hard task. We believe the\\ndevelopment of such a system is a worthwhile topic for future research.\\n\\nAcknowledgements\\n\\nNikolay Pelov, Emmanuel De Mot and Marc Denecker are supported by the\\nGOA project LP+. We want to thank Maurice Bruynooghe for his contribution\\non the topic and anonymous referees for their useful comments.\\n\\nReferences\\n\\n[1] M. Denecker. Extending classical logic with inductive definitions. In J. Lloyd\\net al., editors, First International Conference on Computational Logic, volume\\n1861 of Lecture Notes in Artificial Intelligence, pages 703–717, London, U.K.,\\nJuly 2000. Springer.\\n\\n[2] M. Denecker and D. De Schreye. SLDNFA: an abductive procedure for abductive\\nlogic programs. Journal of Logic Programming, 34(2):201–226, Feb. 1998.\\n\\n[3] M. Denecker and B. Van Nuffelen. Experiments for integration CLP and ab-\\nduction. In K. Apt, A. Kakas, E. Monfroy, and F. Rossi, editors, Proceedings of\\nthe 1999 ERCIM/COMPULOG Workshop on Constraints, Paphos, Cyprus, Oct.\\n1999. University of Cyprus.\\n\\n[4] M. Denecker, H. Vandecasteele, D. De Schreye, G. Seghers, and T. Bayens.\\nScheduling by “abductive execution” of a classical logic specification. In\\nERCIM/COMPULOG Workshop on Constraints, Schloss Hagenberg, Austria,\\nOct.27–28 1997.\\n\\n[5] K. Eshghi and R. Kowalski. Abduction compared with negation by failure. In\\nG. Levi and M. Martelli, editors, Proceedings of the Sixth International Conference\\non Logic Programming, pages 234–254. Lisbon, Portugal, MIT Press, June 1989.\\n\\n\\n\\n[6] M. Gelfond and V. Lifschitz. The stable model semantics for logic programming.\\nIn R. A. Kowalski and K. A. Bowen, editors, Logic Programming, Proceedings\\nof the Fifth International Conference and Symposium, pages 1070–1080, Seattle,\\nWashington, Aug. 1988. MIT Press.\\n\\n[7] J. Jaffar and M. Maher. Constraint logic programming: A survey. Journal of\\nLogic Programming, 19/20:503–581, 1994.\\n\\n[8] A. C. Kakas, R. Kowalski, and F. Toni. Abductive logic programming. Journal\\nof Logic and Computation, 2(6):719–770, Dec. 1992.\\n\\n[9] A. C. Kakas and A. Michael. Integrating abductive and constraint logic program-\\nming. In L. Sterling, editor, Proceedings of the 12th International Conference on\\nLogic Programming, pages 399–413. Tokyo, Japan, MIT Press, 1995.\\n\\n[10] A. C. Kakas, A. Michael, and C. Mourlas. ACLP: Abductive constraint logic\\nprogramming. Journal of Logic Programming, 44(1–3):129–177, 2000.\\n\\n[11] V. Lifschitz. Answer set planning. In D. De Schreye, editor, Proceedings of the\\n16th International Conference on Logic Programming, pages 23–37. MIT Press,\\nDec. 1999.\\n\\n[12] A. K. Mackworth. The logic of constraint satisfaction. Journal of Artificial Intel-\\nligence, 58(1–3):3–20, Dec. 1992.\\n\\n[13] V. W. Marek and M. Truszczyński. Stable models and an alternative logic pro-\\ngramming paradigm. In K. R. Apt, V. W. Marek, M. Truszczyński, and D. S.\\nWarren, editors, The Logic Programming Paradigm: A 25-Year Perespective, pages\\n375–398. Springer, 1999.\\n\\n[14] I. Niemelä. Logic programs with stable model semantics as a constraint program-\\nming paradigm. Annals of Mathematics and Artificial Intelligence, 25(3,4):241–\\n273, 1999.\\n\\n[15] I. Niemelä and P. Simons. Efficient implementation of the well-founded and sta-\\nble model semantics. In M. Maher, editor, Logic Programming, Proceedings of the\\n1996 Joint International Conference and Syposium, pages 289–303, Bonn, Ger-\\nmany, Sept. 1996. MIT Press.\\n\\n[16] I. Niemelä, P. Simons, and T. Soininen. Stable model semantics of weight con-\\nstraint rules. In M. Gelfond, N. Leone, and G. Pfeifer, editors, Proceedings of the\\nFifth International Conference on Logic Programming and Nonmonotonic Rea-\\nsoning, volume 1730 of Lecture Nortes in Computer Science, pages 317–331, El\\nPaso, Texas, USA, Dec. 1999. Springer-Verlag.\\n\\n[17] N. Pelov, E. De Mot, and M. Bruynooghe. A comparison of logic programming\\napproaches for representation and solving of constraint satisfaction problems. In\\nM. Denecker, A. Kakas, and F. Toni, editors, 8th International Workshop on\\nNon-Monotonic Reasoning, Special Session on Abduction, Breckenridge, Colorado,\\nUSA, Apr. 2000.\\n\\n[18] G. Seghers and T. Bayens. Solving a combinatorial maintenance problem for elec-\\ntrical power plants, developed in OLP-FOL and CLP. Master’s thesis, Department\\nof Computer Science, K.U.Leuven, 1996.\\n\\n[19] E. Tsang. Foundations of Constraint Satisfaction. Computation in Cognitive\\nScience. Academic Press, 1993.\\n\\n[20] P. Van Hentenryck. Constraint Satisfaction in Logic Programming. MIT Press,\\n1989.\\n\\n[21] B. Van Nuffelen and M. Denecker. Problem solving in ID-logic with aggregates.\\nIn A. K. Mark Denecker, editor, Eight International Workshop on Nonmonotonic\\n',\n",
       "                'Reasoning, special track on Abductive Reasoning, Breckenridge, Colorado, USA,\\n2000. Workshop associated with KR’2000.\\n\\n\\n\\n[22] H. Vandecasteele. Constraint Logic Programming: Applications and Implementa-\\ntion. PhD thesis, K.U.Leuven, 1999.\\n\\n[23] H. Vandecasteele and D. De Schreye. Implementing a finite-domain CLP-language\\non top of Prolog: a transformational approach. In F. Pfenning, editor, Proceedings\\nof Logic Programming and Automated Reasoning, volume 822 of Lecture Notes in\\nArtificial Intelligence, pages 84–98, Kiev, Ukraine, 1994. Springer-Verlag.\\n\\n[24] J. Zhang and H. Zhang. Constraint propagation in model generation. In U. Mon-\\ntanari and F. Rossi, editors, Proc. of 1st International Conference on Principles\\nand Practice of Constraint Programming, volume 976 of Lecture Notes in Com-\\nputer Science, pages 398–414, France, Sept. 1995. Springer.\\n\\n\\n'],\n",
       "               'language': 'en',\n",
       "               'score': 3.05637264251709,\n",
       "               'vectorized': True}),\n",
       "             ('aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDMxMC8wMzEwMDQydjEucGRm0',\n",
       "              {'title': '()',\n",
       "               'name': '0310042v1.pdf',\n",
       "               'location': 'https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0310/0310042v1.pdf',\n",
       "               'caption': 'A CLP(FD) program searches a solution for a set of variables which take values over finite domains and which must verify a set of constraints. The evolution of the domains can be viewed as a sequence of applications of reduction operators attached to the constraints.',\n",
       "               'index': 'cogsrch-index-files',\n",
       "               'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n03\\n\\n10\\n04\\n\\n2v\\n1 \\n\\n [\\ncs\\n\\n.S\\nE\\n\\n] \\n 2\\n\\n2 \\nO\\n\\nct\\n 2\\n\\n00\\n3\\n\\nAADEBUG2003 171\\n\\nRigorous design of tracers:\\nan experiment for constraint\\nlogic programming\\n\\nMireille Ducassé∗, Ludovic Langevine†, Pierre Deransart†\\n\\n∗ IRISA/INSA de Rennes, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France\\n† INRIA Rocquencourt, BP 105, 78153 Le Chesnay Cedex, France\\n\\nABSTRACT\\n\\nIn order to design and implement tracers, one must decide what exactly to trace and how to produce this\\ntrace. On the one hand, trace designs are too often guided by implementation concerns and are not as useful\\nas they should be. On the other hand, an interesting trace which cannot be produced efficiently, is not very\\nuseful either. In this article we propose a methodology which helps to efficiently produce accurate traces.\\nFirstly, design a formal specification of the trace model. Secondly, derive a prototype tracer from this spec-\\nification. Thirdly, analyze the produced traces. Fourthly, implement an efficient tracer. Lastly, compare the\\ntraces of the two tracers. At each step, problems can be found. In that case one has to iterate the process. We\\nhave successfully applied the proposed methodology to the design and implementation of a real tracer for\\nconstraint logic programming which is able to efficiently generate information required to build interesting\\ngraphical views of executions.\\n\\nKEYWORDS: AADEBUG2003; tracer design methodology, tracer formal specification, tracer efficient imple-\\n\\nmentation\\n\\n1 Introduction\\n\\nDesigning and implementing tracers is a difficult task. One must decide what exactly to trace and\\nhow to produce this trace. On the one hand, trace designs are too often guided by implementation\\nconcerns and are not as useful as they should be. On the other hand, an interesting trace which cannot\\nbe produced efficiently, is not very useful either.\\n\\nSome sort of instrumentation is required to produce the trace information. This instrumentation\\ncan be done at different levels, for example the user programs can be transformed at source or com-\\npiled levels. Another possibility is to plant trace hooks in the language interpreter or emulator. All\\nthese possibilities have their advantages and drawbacks, deciding for one is not straightforward. For\\nexample, source level transformation does not require to open the compiler sources and can be effi-\\ncient enough [DN00]. Instrumenting an interpreter is in general easier than working directly in the\\ncompiler and the loss in performance might be acceptable.\\n\\nIn M. Ronsse, K. De Bosschere (eds), proceedings of the Fifth International Workshop on Automated Debugging (AADE-\\nBUG 2003), September 2003, Ghent. COmputer Research Repository (http://www.acm.org/corr/), cs.SE/yymmnnn; whole\\nproceedings: cs.SE/0309027.\\n1E-mail: Mireille.Ducasse@irisa.fr, {Ludovic.Langevine, Pierre.Deransart}@inria.fr\\n2This work is partially supported by the French RNTL project OADymPPaC, Tools for dynamic analysis of constraint logic\\nprograms, http://contraintes.inria.fr/OADymPPaC/\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\nhttp://arxiv.org/abs/cs/0310042v1\\nhttp://www.elis.UGent.be/aadebug2003/\\nhttp://contraintes.inria.fr/OADymPPaC/\\n\\n\\n172 M. DUCASSÉ ET AL.\\n\\nHowever, in order to have at the same time a faithful and efficient enough tracer, people often\\ndecide to instrument the language emulator or the user compiled code. In both cases, they have to\\ndive deeply into non-obvious code. This is a tricky task, especially if the tracer developers have not\\nbeen involved in the development of the compiler. At this stage, it is necessary that the trace model is\\nstable. Instrumenting at low level requires a lot of tedious work, it is essential to know exactly what\\nis expected before starting.\\n\\nThe first stage of the design, namely deciding what to trace, is, therefore, critical. However, de-\\nciding what to trace out of the blue is not obvious. It is often when people see the output of a tracer\\nthat they can tell whether the information is relevant and helpful.\\n\\nTo solve this apparent contradiction, we have conceived a methodology that we have successfully\\napplied to the design and implementation of a real tracer:\\n\\n1. Design a formal specification of the trace model based on an abstraction of the operational\\nsemantics of the language.\\n\\n2. Derive a prototype tracer from this specification.\\n\\n3. Analyze the produced traces to update or validate the trace model. This analysis can be par-\\ntially automated.\\n\\n4. Implement an efficient tracer.\\n\\n5. Validate the efficient implementation using the prototype.\\n\\nAt each step, problems in the model or in implementations can be found. In that case one has to\\niterate the process.\\n\\nThe advantages of the approach are as follows. Firstly, the formal specification helps to produce a\\ntrace model which gives an accurate picture of the executions. When examining existing tracers, one\\n',\n",
       "                'too often has the feeling that they produce whatever information is easily available, hoping that the\\nusers will manage with the holes and the noise. While users often manage, mostly because they have\\nno other choice, we claim that tracers with clean semantics are much more helpful. Secondly, in our\\napproach the prototype is systematically derived from the trace model. It is therefore easy to produce\\nand the resulting traces are faithful to the model. The prototype can easily produce trace samples.\\nThirdly, analyzing the trace samples enables people to tune the trace model. When an automated\\ntrace analyzer is used, this analysis can be systematic and thorough. Fourthly, when the tracer devel-\\nopers reach the stage where they have to implement a low-level tracer, they know which information\\nis crucial and which one can be escaped. If implementation compromises have to be made, people\\nhave rational arguments to take their decisions. Lastly, comparing the actual output of the low-level\\nimplementation against the expected trace produced by the prototype is a good way to validate the\\nquality of the implementation.\\n\\nNote that the execution of the prototype tracer can afford to be slow. Indeed, it is used only at\\ndevelopment time for qualitative reasoning, firstly to tune the trace model, then to test the imple-\\nmentation. Furthermore it is meant to be used on small programs only. The only requirement of\\nthese programs is that they altogether exhibit all the characteristics of the traced language. In order\\nto test the performance of the final tracer, big programs have, of course, to be traced but with the\\nlow-level implementation not with the prototype.\\n\\nThe first three steps of this methodology had been applied to the retrospective design of a Prolog\\ntracer [JDR01]. The formal specification step enabled to specify a variety of existing trace models for\\nProlog which were shown to be minor variants of each others. The result was a unified view of nu-\\nmerous models which were initially proposed without much rationale to support them. Furthermore\\na number of implementation issues regarding variable identifiers were detected.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 173\\n\\nMore interestingly, we have used all the steps of the methodology to design from scratch a tracer\\nfor constraint logic programming over finite domains(CLP(FD) in the following). A detailed descrip-\\ntion of this tracer can be found in [LDD03]. The low-level tracer has been implemented inside the\\ncompiler of Gnu-Prolog [GP01] by somebody who did not previously know the implementation of\\nthe compiler. This experiment has been done within a project on visualization of constraint program\\nexecutions, with academic and industrial partners working on different platforms. Both the formal\\nspecification of the trace model and the prototyping capabilities have enabled us to discuss with all\\nthe partners of the project and to make sure that the designed trace is indeed matching the needs\\nof everybody. Some partners build graphical views [SA00], other provide explanations of failure\\nfor over-constrained problems [JB00]. They all work with parts of the specified trace. As the de-\\nsign of the trace model was not connected to a particular implementation we could design a model\\nwhich is generic enough to be specialized at low cost for two different styles of constraint satisfaction\\n(CSP [Lrg01] and CLP [Apt99]). Furthermore, some parts of the designed information, for example\\nthe list of variables and the constraint identifiers, have been proved essential for the quality of the\\nviews but they are not obvious to gather from the implementation in the emulator. Starting from the\\nformal specification and knowing that they were absolutely needed, made them not too difficult to\\nimplement. One can conjecture that, had we started to implement straightaway the low-level imple-\\nmentation, these kinds of information would probably have never been provided by the tracer. Not\\nsurprisingly, in the tracers of the CLP systems, Sicstus Prolog [ASBC02] and Ilog Solver [Ilo01], in\\norder to get the list of variables, one has to traverse a huge part of the trace. This is especially tedious\\nto do for users.\\n\\nThe contribution of this article is to propose a methodology to rigorously design and validate\\ntracer implementations. To our best knowledge, this had not been done before. This methodology\\nhas been successfully tested against the design and implementation of a real tracer.\\n\\nThe next sections present the methodology in more details and illustrate it with samples of the ex-\\nperiment done with the design, implementation and validation of a tracer for Gnu-Prolog. The expla-\\nnations are meant for readers with no previous knowledge of constraint solving. Section 2 presents\\nthe trace model formalization step. Section 3 describes how to systematically derive an instrumented\\nmeta-interpreter from the formal specification. ',\n",
       "                'Section 4 outlines the trace analysis step. In particular,\\nit briefly presents the connection to a trace analyzer and lists some interesting graphical views for\\nCLP(FD). Section 5 discusses the low-level implementation of tracers. Section 6 sketches the valida-\\ntion of the efficient tracer against the prototype implementation.\\n\\n2 Formal specification of a trace model\\n\\nThe first step of our methodology is to specify a trace model, namely what information about pro-\\ngram executions should be given. In our sequential language context, a trace is a sequence of events.\\nAn event represents an interesting execution step, it can be seen as an execution breakpoint to which\\ninformation is attached.\\n\\nMost specifications of trace models are informal, when they exist at all. However, an informal\\nspecification is prone to misinterpretation by both developers and users. Indeed, in order to denote\\nthe events of interest, one has first to be able to denote events, and this is not easy in an informal way.\\n\\nIn the following, we describe two ways that have been tried to provide a formal specification of\\ntrace model, firstly an existing operational semantics has been instrumented and secondly an abstract\\noperational semantics has been specified. We then give some details of the second experiment.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n174 M. DUCASSÉ ET AL.\\n\\nx y z x y z x y z x y zx y z x y z\\n\\n1\\n\\n3\\n2\\n\\nred\\nx red\\n\\ny\\nred\\n\\ny\\ny > z red\\n\\nz\\ny > z red\\n\\nx\\nx > yx > yx > y\\n\\nFigure 1: Application of reductions to the system {x > y; y > z}.\\n\\n2.1 Instrumenting an existing operational semantics\\n\\nSome programming languages have precise operational semantics which rigorously specify the com-\\nputation steps. Hence the computation events are clearly denoted. In such a case, it is relatively easy\\nto formally specify a trace model as shown by Jahier et al. with the Prolog tracer retro-specifica-\\ntion [JDR01]. There were already numerous operational semantics available for Prolog. The contin-\\nuation passing semantics of Nicholson and Foo [NF89] was used. Then instrumentations inside the\\noperational semantics were specified. Only 2 rules of one line each had to be instrumented in order\\nto get the “standard” trace of Prolog. The instrumentation itself is slightly tricky but it can be under-\\nstood without ambiguity when examining a formal specification of 10 lines. The detailed description\\nof this experiment is out of the scope of this article. Indeed, the explanations of operational semantics\\nrequires a couple of pages, understanding them requires a good knowledge of Prolog and this article\\nis not aiming at Prolog specialists.\\n\\n2.2 Specifying an abstract operational semantics\\n\\nAn operational semantics is not always available, for example we are not aware of any for the C lan-\\nguage. In such a case, starting the design of the tracer by designing a complete operational semantics\\nis certainly an overkill. An operational semantics specifies in detail the execution of a program. From\\nan operational semantics one can derive an implementation of a compiler. In order to design a tracer,\\nless information is usually needed than to implement a compiler. In that case, an abstract operational\\nsemantics is sufficient. The information given in an abstract operational semantics is correct but not\\ncomplete. It tells tracer developers what information should be provided to users and it tells users\\nhow to interpret this trace information. In the case of CLP(FD) there was no operational semantics\\nthat we could use to specify a tracer and we designed an abstract operational semantics as a set of\\nstate transition rules. .\\n\\n2.3 Informal presentation of domain reduction\\n\\nBefore we give examples of a formal specification of events we have to informally explain how vari-\\nable domains are reduced. This is an essential mechanism of constraint propagation in the case of\\nfinite domains. A CLP(FD) program searches a solution for a set of variables which take values\\nover finite domains and which must verify a set of constraints. The evolution of the domains can\\nbe viewed as a sequence of applications of reduction operators attached to the constraints. Each op-\\nerator can be applied several times until the computation reaches a fix-point [FLT00]. This fix-point\\nis the set of final domain states. An example of computation with reduction operators is shown in\\nFigure 1. There are three variables x, y and z and two constraints, x > y and y > z. A set of possi-\\nble values is associated to each variable. This set is called the domain of the variable. The domain\\nreduction consists in elementary steps that remove inconsistent values from those domains. At the\\nbeginning, the domain of x, Dx, the domain of y, Dy , and the domain of z, Dz , are all equal to {1, 2, 3}.\\nThis is represented by three columns of white squares. Considering the first constraint, it appears that\\nx cannot take the value “1”, because otherwise there would be no value for y such that x > y; ',\n",
       "                'this in-\\nconsistent value is withdrawn from Dx. This withdrawal is marked with a black square. In the same\\nway, the value 3 is withdrawn from the domain of y. Then, considering the constraint y > z, the sets\\n{1} and {2, 3} are respectively withdrawn from Dy and Dz . Finally, using again the first constraint to\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 175\\n\\nnewVariable\\nx 6∈ V\\n\\nV ← V ∪ {x}, D ← D ∪ {(x, Dx)}\\n{Dx : initial domain of x}\\n\\nnewConstraint\\nc 6∈ C ∧ var(c) ⊂ V\\n\\nC ← C ∪ {c}\\n\\nreject\\nA = {c} ∧ unsatisfiable(c,D) ∧ R = ∅\\n\\nA← ∅, R← {c}\\n\\nsuspend\\nA = {c} ∧ no_reduction(c,D) ∧ R = ∅\\n\\nA← ∅, S ← S ∪ {c}\\n\\nawake\\nA = ∅ ∧ wake_condition(c) ∧ R = ∅\\n\\nA← {c}\\n\\nreduce\\nA = {c} ∧ x ∈ var(c) ∧ W c\\n\\nx(D) 6= ∅ ∧ R = ∅\\n\\nDx ← Dx −W c\\nx(D)\\n\\n{\\n\\nW c\\nx(D) : inconsistent values\\n\\nof x for c wrt D\\n\\n}\\n\\nFigure 2: Six rules of the abstract operational semantics defining six event types\\n\\npropagate the previous reduction of Dy , Dx is reduced to the singleton {3}. The fix-point is reached.\\nThe final solution is {x = 3, y = 2, z = 1}.\\n\\n2.4 Samples of formal event rules for CLP(FD)\\n\\nOur abstract operational semantics is defined by a set of transition rules between observed states. An\\nobserved state is a tuple containing in particular: C, the set of constraints declared until this state;\\nV , the set of finite-domain variables declared until this state; D, the set of domains of the variables\\ndeclared until this state; A, the set of active constraints ; S, the set of sleeping constraints; and R,\\nthe set of rejected constraints which contains unsatisfiable constraints.\\n\\nFigure 2 gives six examples of transition rules specifying types of events of interest. The complete\\ntrace model contains thirteen event types. Rule newVariable specifies that a new variable x is intro-\\nduced in V and that its initial domain is Dx. Rule newConstraint specifies that the solver introduces\\na new constraint c in C, all variables involved in c are already defined. Rule reject specifies that if\\nthe active constraint (A = {c}) is unsatisfiable in the current state of the domains, it is put in the\\nset of rejected constraints, R. A constraint is unsatisfiable for example when one of its variables has\\nan empty domain. Rule suspend specifies that when an active constraint cannot reduce any domain\\nat the moment, it is suspended in S. Rule awake specifies that when the set of active constraints is\\nempty and some specific condition is fulfilled a suspended constraint can be awoken and become ac-\\ntive 3. Rule reduce specifies that if the active constraint, c, has a variable, x, with inconsistent values\\nin its domain, W c\\n\\nx(D), these values are withdrawn from its domain Dx.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n176 M. DUCASSÉ ET AL.\\n\\n1 newVariable v1 =[0-268435455]\\n2 newVariable v2 =[0-268435455]\\n3 newConstraint c1 fd_element([v1,[2,5,7],v2])\\n4 reduce c1 v1 =[1,2,3] W=[0,4-268435455]\\n5 reduce c1 v2 =[2,5,7] W=[0-1,3-4,6,8-268435455]\\n6 suspend c1\\n7 newConstraint c4 x_eq_y([v2,v1])\\n8 reduce c4 v2 =[2] W=[5,7]\\n9 reduce c4 v1 =[2] W=[1,3]\\n\\n10 suspend c4\\n11 awake c1\\n12 reject c1\\n...\\n\\nFigure 3: A portion of Trace for fd_element(I,[2,5,7],A), (A#=I ; A#=2). a-b means\\nfrom a to b and a,b means a and b\\n\\n2.5 A Trace Example\\n\\nFigure 3 presents the beginning of a trace of a toy program in order to illustrate the event types\\ndescribed above. This program, fd_element(I, [2,5,7],A), (A#=I ; A#=2), specifies that\\nA is a finite domain variable which is in {2, 5, 7} and I is the index of the value of A in this list;\\nmoreover A is either equal to I or equal to 2. The first option is infeasible; the trace shows the events\\nrelated to the failing attempt to satisfy it.\\n\\nThe trace can be read as follows. The first two events are related to the introduction of two vari-\\nables v1 and v2, corresponding respectively toI and A. In Gnu-Prolog variables are always created\\nwith the maximum domain (from 0 to 268.435.455). Then the first constraint is created: fd_element\\n(event #3). This constraint makes two domain reductions (events #4 and #5): the domain of the first\\nvariable (I) becomes {1, 2, 3} and the domain of A becomes {2, 5, 7}. After these reductions, the con-\\nstraint is suspended (event #6). The next constraint, A#=I, is added (event #7). Two reductions are\\ndone on variables A and I, the only possible value for A and I to be equal is 2 (events #8 and #9).\\nAfter these reductions, the constraint is suspended (event #10). The first constraint is awoken (event\\n#11). If A and I are both equal to 2, I cannot be the rank of A. Indeed, the rank of 2 is 1 and the value\\nat rank 2 is 5. The constraint is therefore rejected (event #12). The execution continues and find the\\nsolution A=2 and I=1. This requires 20 other events not shown here\\n\\n2.6 Discussion\\n\\nOur semantics does not specify how the rules are applied but what events are of interest and what\\ninformation is available at each event. ',\n",
       "                'As already mentioned, it helps tracer developers to design the\\ntracer and it helps tracer users to interpret the produced traces.\\n\\nFor example, rule reject tells the implementor that whenever the solver finds an unsatisfiable\\nconstraint, the tracer should be called with this constraint. The same rule tells users that when they\\nsee a reject event in a trace, the corresponding constraint has become unsatisfiable and there was\\npreviously no rejected constraint.\\n\\nSimilarly, rule reduce tells the implementor that, when the solver processes a reduction, the tracer\\nshould be called with information about the related constraint, the related variable and the new\\ndomain Dx. The same rule tells users that when they see a reduce event in a trace, the reduction\\nhas been achieved on one of the variables of the specified constraint, that there were inconsistent\\n\\n3Awakening conditions are solver dependent, and usually contain the “added value” of each solver. Some are therefore rather\\nreluctant to show this condition in the trace.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 177\\n\\n1 reject(St0, St) :-\\n2 St0 = ([C], S, Q, T, [], D),\\n3 get_varC(C, VarC),\\n4 member(X, VarC),\\n5 get_domain(X, D, []),\\n6 St = ( [], S, Q, T, [C], D),\\n7 trace(reject, C, St0, _, _, _).\\n8\\n\\n9 reduce(St0, St, ModOut) :-\\n10 St0 = ([C], S, Q, T, [], D0),\\n11 get_varC(C, VarC),\\n12 member(X, VarC),\\n13 reduction(C, D0, X, Wx),\\n14 update_domain(X, Wx, D0, D, ModOut),\\n15 St = ([C], S, Q, T, [], D),\\n16 trace(reduce, C, St0, X, Wx, ModOut).\\n\\nFigure 4: Translation into Prolog of the reject and reduce rules of Figure 2\\n\\nvalues to remove from this variable and that there was previously no rejected constraint. The trace\\nalso gives the inconsistent values that have been withdrawn. Incidentally, the rule also specifies that\\nthe constraint that prompted the reduction is still the active one (A is not modified).\\n\\nNote that the upper part of the rules are not shown in actual traces, this is implicit information. In\\nmost tracers, users have to guess it. In our system, it is explicit, at least in the formal specification.\\n\\n3 Implementation of a prototype tracer\\n\\nA formal specification of trace model is helpful to formally reason about a trace. However, it actually\\nspecifies many traces for many kinds of solvers. It is sometime too arid to decide whether possible\\ntraces can be of any help to users. With that respect, it is better to have samples of execution traces\\nchecked by “guinea pig users”. Producing samples by hand is very tedious. It becomes quickly un-\\ntractable since the trace model evolves according to the remarks of the guinea pigs! New samples\\nhave therefore to be produced until a trace model is validated by users. It is, thus, welcome to have\\na tracer as quickly as possible. However, a low-level implementation is not suited before the trace\\nmodel has been validated by users. As already mentioned in the introduction, we propose to use a\\nprototype tracer in order to break this deadlock.\\n\\n3.1 Derivation of a prototype tracer from the CLP(FD) trace model\\n\\nIn our CLP(FD) experiment, we derive a CLP(FD) interpreter coded in Prolog that we instrument\\nwith trace hooks. Figure 4 contains the translation of reject and reduce rules of Figure 2. Each rule is\\nencoded by a predicate with the same name as the rule.\\n\\nBefore paraphrasing the code for one rule, we give the meaning of all the (simple) predicates\\nthat are used and not defined: get_varC(C, V) takes as input a constraint C and outputs a list\\nof the constraint variables that appear in C; member(X, L) is a standard Prolog predicate which\\nchecks whether X is an element of the list L; get_domain(X, D, Dx) takes a constraint vari-\\nable X and a domain state D, and outputs the domain of X (Dx); note that in Prolog = denotes a\\nunification; trace(Port, C, St0, Att1, Att2, Att3) takes as input the different event at-\\ntributes; it calls the trace analysis system which can, for example, print a trace line; reduction(C,\\nD, X, Wx) takes as input a constraint C, a domain state D, a constraint variable X, and outputs the\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n178 M. DUCASSÉ ET AL.\\n\\nvalues to withdraw from the domain of X; it fails if Wx = ∅ (no reduction can be done);\\nupdate_domain(X, Wx, D0, D, Mod) takes as input a constraint variable X, a value set Wx (to\\nwithdraw), and a domain state D0; it outputs the state domain D such that Dx=D0 - Wx, and the\\nlist of modification types Xmod1\\n\\n, ..., Xmodn\\n, where modi ∈ {min, max, ground, any, empty}. These\\n\\nmodifications characterize the Wx value withdrawal.\\nAll the predicates implementing transition rules take as input a solver state St0 and output a new\\n\\nsolver state St. St0 and St respectively denote the state of the solver before and after the application\\nof a rule. Predicate reject(St0, St) implements the reject rule. That rule needs to fulfill 3 condi-\\n',\n",
       "                'tions to be allowed to be applied: firstly, there is a constraint C in the active constraint set, secondly\\nthe set of rejected constraints is empty, and thirdly there exists a variable attached to the C constraint\\nwhose domain is empty. This last condition implies the unsatisfiable(c,D) predicate of Figure 2.\\nThe first two conditions are checked line 2. The third condition is checked lines 3 to 5 using Prolog\\nbacktracking. The execution of this predicate will backtrack to member(X, VarC) until either there\\nis no more variables in VarC or one of them has an empty domain. After the application of the rule\\nthe set of active constraints is empty and the set of rejected constraints contains C (line 6). The tracer\\nis called with the relevant information (line 7). Note the use of Prolog anonymous variables for ar-\\nguments 3 to 6. This means that the values are meaningless. The other rules are implemented in the\\nsame way.\\n\\nThe rules are integrated into the underlying Prolog system in the usual meta-interpretation way\\nof Prolog. This is not detailed in this article. An introduction to meta-interpreters in Prolog can be\\nfound in [SS94].\\n\\n3.2 Discussion\\n\\nWe have been able to systematically deduce the Prolog code from the specification. Even if the pro-\\nduction of the prototype tracer was not automatic, it has been sufficiently systematic so that the\\nmodifications of the trace model could be immediately integrated. Furthermore, it has always been\\neasy to convince ourselves that the produced prototypes indeed implemented the expected trace\\nmodel.\\n\\nThe produced prototype tracer was rather slow, but as already mentioned in the introduction,\\nefficiency is not an issue at this stage. The idea is to validate the trace model, the tracer designers use\\nthe prototype on well chosen and small programs.\\n\\nThe formal specification is very useful, but if time and resources are short, and if the prototype\\ntracer is very simple and easy to implement, it can be considered to start the design of the tracer with\\nthe prototype. One will miss the formal support for verification but at least there will be some means\\nto think about the trace design.\\n\\nIn our experiments, we have used the meta-interpretation capabilities of logic programming to\\nbuild prototype tracers. Even in languages with no meta-programming capabilities, there are always\\nsome means to easily produce prototypes. For example a source-level instrumentation of a subset\\nof the language is generally possible. Not all the features and libraries of a language need to be\\ninstrumented in the prototype. If the syntax of the language is specified by a grammar, then the in-\\nstrumentation can be implemented inside this grammar, for example with an attributed grammar\\nlanguage such as Yacc.\\n\\n4 Trace analysis\\n\\nOnce a first trace model is designed and a prototype tracer exists, it is important to play with actual\\ntraces. As soon as the traces are longer than what can be printed on a page it becomes very tedious to\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 179\\n\\n    \\n\\n?− fd_element(I,[2,5,7],A),(A#=I;A#=2).\\n\\nGives control to\\n\\nRetrieves current attribute values\\n\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n\\n<Execution>\\n\\n<Execution>\\n\\n<no trace info about next event>\\n\\nfirst event\\n\\n<Execution>\\n\\n...\\n\\nsecond event\\n\\n[LSD]:\\n\\nnth  event\\n\\n<retrieve current event attributes>\\n\\n<print current event attributes>\\n\\n[LSD]: fget(chrono = 4), print.\\n\\nf_get(chrono = 4)\\n\\n<current chrono is not equal to 4>\\n\\n<current chrono is equal to 4>\\n\\n[4] Reduce  c1   v1=[1,2,3]\\n\\nFigure 5: Illustration of the processing of a filtering query\\n\\nanalyze them by hand. Even toy programs can produce traces of thousands of events whose system-\\natic display would be inefficient and irrelevant. Therefore, we believe that the validation can be much\\nmore rigorous and powerful if it is automated. In our approach we connect the prototype tracer with\\nan automated trace analyzer à la Opium [Duc99b]. The first advantage is that many long traces can be\\nsystematically tested. A second advantage is that abstract and graphical views can be automatically\\nbuilt [Duc99a, Jah00]. In the case of CLP we have built a number of graphical views which helped\\nus select from the potential interesting trace information the ones that were really important and the\\nones that were not so crucial. It should be noted that, applying the methodology, the trace model that\\nwe designed varied quite a lot between the first design [LDDJ01] and the current one [LDD03].\\n\\nIn the remaining of this section we first present the generic trace querying facility. We then sketch\\none example of interesting graphical view of CLP(FD) executions which has been built with the trace\\nanalyzer.\\n\\n4.1 Analysis of the produced trace\\n\\n',\n",
       "                'In our trace analysis scheme, users can formulate queries in order to investigate an execution trace.\\nThe queries are formulated in the Prolog language extended by two primitives: fget/1 and\\nget_attr/2. fget/1 searches for a specific event forward in the execution trace, get_attr/2\\nretrieves data about the current event.\\n\\nEvents are searched for as the traced program is executed. There are two execution processes,\\none for the traced execution, and one for the trace analysis (called LSD in the following4). Figure 5\\nillustrates how the fget/1 primitive works. Let us assume that the programmer wants to query the\\nexecution trace of the program given in Figure 3. When the execution reaches the first event, it notifies\\nLSD which prompts the programmer for a trace query. The programmer enters a goal in order to\\n\\n4LSD stands for a “Long Story Debugger”. It is a prototype of generator of trace analyzers currently under development.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n180 M. DUCASSÉ ET AL.\\n\\n1 :- fget([port = reduce, chrono>3]),\\n2 get_attr([var, withdrawn], [X, Wx]).\\n3\\n\\n4 :- setval(nb_reject, 0),\\n5 fget(in(port, [reject, solution])),\\n6 ( get_attr(port, reject)\\n7 -> incval(nb_reject),\\n8 fail\\n9 ; true %else this is a solution, stop counting\\n\\n10 ),\\n11 getval(nb_reject, NbFailures),\\n12 writeln(NbFailures).\\n\\nFigure 6: Two examples of trace queries\\n\\nsearch forward until an event with chronological number equal to 4 is found (fget([chrono=4])).\\nThis event should then be displayed (print). At that moment, LSD can only get information about\\nthe current event. It therefore returns control to the traced execution. When the traced execution\\nreaches the next event, it locally checks whether the current chrono is equal to 4. As the current\\nchrono is not the requested one, the traced execution is resumed until the next event is reached.\\nThe chrono is again locally checked. Forward moves and checking are done in turn until the first\\nevent whose chrono is 4. LSD is notified and proceeds. The current event attributes are retrieved\\nby the print command which displays the related information. The execution of the trace query is\\ncompleted. The programmer is then prompted for another one.\\n\\nThe scheme previously described is a good compromise between efficiency and expressive power.\\nOn the one hand, the search for events is done in the traced process, and can be very efficient. On the\\nother hand, as the whole power of Prolog is available in the analyzer process, sophisticated debug-\\nging programs can be written.\\n\\nTwo examples of composed queries are given in Figure 6. The first query asks to go to the\\nfirst event whose port 5 is reduce with a chronological number (chrono) greater than 3. The re-\\nduced variable and the withdrawn domain are then retrieved and stored in the variables X and\\nWx On the trace given in Figure 3, the query would find the fourth event and return X=v1 and\\nWx=[0,4-268435455].\\n\\nThe second query of Figure 6 is an example of sophisticated query which could be integrated into\\nan analysis program. It counts the number of failures encountered before the first solution and prints\\nit. First, the counter is initialized (line 4). The fget primitive is used to find the next event whose\\nport is either reject or solution (line 5). Then the actual port is retrieved with get_attr (line 6). If it\\nis reject, then the counter is incremented (line 7) and a failure is forced (line 8). If it is not a reject, it\\nmeans that it is a solution; in that case the loop is stopped by simply executing true (line 9). In the\\ncase where the execution is made to fail, it will backtrack to the fget which will find the next event\\nwhose port is either reject or solution (line 5). If the execution does no longer contain such events,\\nthe overall query will simply fail. In the case where the loop terminates on a solution the value of the\\ncounter is retrieved (line 11) and printed (line 12).\\n\\n4.2 A CLP(FD) visualization of variable updates\\n\\nOne of our experiments is the generation of a 3D variable update view. The evolution of the do-\\nmains of the variables during the computation is displayed in three dimensions. It gives a tool à\\nla TRIFID [CH00]. The trace analyzer computes domain size each time a constraint is added to the\\n\\n5following the Prolog tradition the type of events is called “port”.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 181\\n\\nFigure 7: Comparing two search procedures for the 40-queens problem with VRML views computed\\nby trace analysis.\\n\\nstore or rejected, as well as when a solution is found. The details of reduce events allow us to assign\\ncolor to each kind of domain update (for example minimum or maximum value removed or domain\\nemptied) as made by Simonis and Aggoun in the Cosytec Search-Tree Visualizer [SA00]. The trace\\nanalysis is implemented in about 125 lines of Prolog and generates an intermediate file. A program\\n',\n",
       "                'implemented in 240 lines of C converts this file into the VRML format.\\n\\nFigure 7 shows the resolution of the 40-queens problem with two different enumeration strategies.\\nThere are three axes: variables, domain size and time. The first strategy is a first-fail selection of the\\nenumerated variable and the first value tried is the minimum of its domain. The second strategy is\\nalso a first-fail strategy but variable list is sorted with the middle variable first and the middle of\\ndomain is preferred to its minimum. The two graphical views allow users to compare the efficiency\\nof these two strategies by manipulating the 3D-model. With the first strategy, domain sizes on one\\nside of the chess-board quickly decrease, and the domain size on the other side oscillate at length.\\nWith the second strategy, domain sizes decrease more regularly and more symmetrically, the solution\\nis found faster. In fact, the second strategy, which consists in positioning the queens starting from the\\ncenter of the chess-board, benefits more from the symmetrical nature of the problem.\\n\\n4.3 Discussion\\n\\nThe list of all the variables attached to the problem is a relevant information because graphical views\\nsuch as the 3D-model display all the domains at a glance whereas the solver handles only a small\\nsubset of variables at a time. The above experiments made clear that the tracer must be able, if re-\\nquested, to provide the whole state at each event, namely the domains and the constraints of the\\nproblem. Furthermore, the list of variables involved in a given constraint is not straightforward to\\nget from the implementation. However, this kind of information is also crucial to build some graph-\\nical views which are helpful to users. Even if producing these types of information requires some\\nimplementation efforts and may have a cost in terms of performance, it is worth producing them.\\nThis was not possible to decide by just looking at the formal semantics.\\n\\n5 Efficient implementation\\n\\nWhen the trace designer knows what in the expected trace model is important for which debugging\\nfunctions. The actual implementation can start. The events of interest have to be located in the com-\\npiler or compiled code. It is also necessary to specify how to get the information related to each event.\\nAt this stage, the tracer implementors can decide that a piece of information is too tricky or too costly\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n Domains Variables Time \\n\\n Domains Variables Time \\n\\n\\n\\n182 M. DUCASSÉ ET AL.\\n\\nto produce. This happens all the time in tracers produced without this methodology. The essential\\ndifference here is that the tracer implementors know what is kept or not and why. This is important\\nfor users. For example, if a particular graphical view requires some information which cannot be\\ngenerated in a particular implementation, users will know straightforwardly and will not discover it\\nthe hard way.\\n\\n5.1 The Gnu-Prolog tracer implementation\\n\\nEncoding a trace model that is not derived from the actual implementation of the solver is a delicate\\ntask. The correspondence between a formalized event and the code of the solver is not obvious: some\\nevents can be almost simultaneous, or a single event can be performed in several points of the code.\\nFor example, the trace model provides a unified view of the domain reduction with the reduce rule\\nwhereas there are several places to instrument in the code. Domain reduction is a crucial point in\\na constraint solver and the corresponding code is highly optimized. In Gnu-Prolog, there are four\\ndifferent cases for the domain reduction, depending on the way the values to withdraw have been\\ncomputed. The tracer handles each case with its peculiarities in order to get a single reduction event.\\nWhatever domain reduction routine is used, the trace event will be a reduce with standard attributes.\\n\\nAnother issue is the ability to proceed through the whole sets of constraints and variables, as well\\nas to allocate them unique identifiers. The solver only handles pointers on data structures. During\\nthe execution, a given pointer can be used for several constraints and variables. Moreover, at a given\\nmoment, the solver focuses on a small subset of entities. Therefore the tracer has to maintain its own\\ndata structures to reference all the pointers the solver handles. When the solver creates a new variable\\nor a new constraint, the tracer references the pointer on this new entity in a specific table. This table\\nassociates to this pointer a new integer identifier and some debugging data that can be useful in\\nthe sequel. When the solver deletes some constraints and variables, the corresponding entries are\\nremoved from the tracer table. This table can be used to search for an identifier knowing the pointer\\non an entity or to search for a pointer knowing the identifier of an entity. Both of these uses are made\\nin logarithmic time. ',\n",
       "                'Another possible use is retrieving the list of all the variables or the list of all the\\nconstraints.\\n\\nThe methodology has led to a trace model that is far from the implementation of Gnu-Prolog.\\nThe trace has needed the instrumentation of critical points in the solver. Nevertheless, the imple-\\nmentation has been possible and the final model has a clear semantics that is easy to understand\\nfor a constraint programmer. Moreover, the resulting tracer is efficient: the time overhead while ex-\\necuting a program without any trace output is between 5 and 30 percents (less than 10% in most of\\nour benchmarks). While producing a very detailed trace (with almost all the attributes the model\\nprovides), the time ratio against an untraced execution is between 3 and 7.4. These performances\\nare comparable to other debuggers known to be efficient enough, for example the Mercury tracer of\\nSomogyi and Henderson [SH99] or the ML tracer of Tolmach and Appel [TA95].\\n\\nIt is worth noticing that the tracer has been implemented in such a way that only the part of the\\ntrace which is required by a specific analysis is constructed: users pay only for what they need.\\n\\n5.2 Discussion\\n\\nTwo other tracers exist for constraint programming. The first one is the trace mechanism of the Ilog\\nSolver platform. Ilog Solver is a C++ library for constraint solving. Some virtual trace functions are\\ncalled at some specific points of the solver. By default, those functions do nothing. The developer can\\nredefine them to produce his own trace. The parameters of the trace functions are the attributes of\\nthe corresponding trace events. Taking the critical example of domain reduction, we see that trace\\nevents are guided by the implementation: there are two events by special case Ilog Solver handles:\\nan event before and an event after. Their attributes depend on the case that is active. At the opposite,\\nour model and implementation provide a single unified event with all the data at a glance.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 183\\n\\nPrototype trace:\\n\\n1 newVariable v1 =[1,2,3]\\n2 newVariable v2 =[2,5,7]\\n\\nGnu-Prolog trace:\\n\\n3 newVariable v1 =[0-268435455]\\n4 newVariable v2 =[0-268435455]\\n5 newConstraint c1 fd_element([v1,[2,5,7],v2])\\n6 reduce c1 v1 =[1,2,3] W=[0,4-268435455]\\n7 reduce c1 v2 =[2,5,7] W=[0-1,3-4,6,8-268435455]\\n8 suspend c1\\n\\nFigure 8: Portions of traces, with some attributes produced by the prototype tracer and Gnu-Prolog\\ntracer for the introduction of new variables\\n\\nThe second existing tracer is an experimental tracer for Sicstus Prolog. Its trace model is dedicated\\nto Sicstus implementation. The tracer is based on a complete storage of the trace and postmortem\\ninvestigation. When a specific data on an event is asked for, the tracer has to traverse the trace back-\\nwards until the data is found or is able to be recomputed. Most of our trace model could be produced\\nthis way but it is not realistic for real-life executions.\\n\\n6 Validation\\n\\nAnother important problem when building a tracer is to validate the result. In particular, it is impor-\\ntant to be sure that the produced trace is indeed the expected one. As opposed to the prototype, the\\nefficient implementation has no obvious relation to the formal specification.\\n\\nOur methodology proposes to further take benefits of the prototype implementation in order to\\ncompare the traces produced by the actual tracer with the trace produced by the prototype. This\\ncomparison is not expected to be a bijection in the general case. Indeed, some events may not be\\nimplemented (see the discussion above), some information may not be available. In addition, the\\nactual tracer may also produce larger traces for example for the parts of the language and libraries\\nthat were not taken into account in the prototype. As a consequence, at present, the comparison\\nbetween the two types of traces has to be done by hand.\\n\\n6.1 Validation of the Gnu-Prolog tracer implementation\\n\\nFor our experiment we compared the traces of the executions of some small programs produced\\nby the prototype tracer and the Gnu-prolog tracer. Figure 8 shows portions of trace related to the\\nintroduction of a new variable. In the prototype tracer, the variables are directly introduced with\\ntheir specified domain. In the Gnu-Prolog solver, every time a new variable is introduced, its domain\\ninitially contains all the possible values and the following execution steps use the regular reduction\\nmechanism to reduce the domain to the one which was declared. In our example, the two events of\\nlines 1 and 2 produced by the prototype tracer correspond to the events of lines 3 to 8 produced by the\\nGnu-Prolog tracer. These events appear in Figure 3 and have already been explained in section 2.5.\\n\\n6.2 Discussion\\n\\nBesides the identification of some minor implementation problems, this analysis led us to refine the\\n',\n",
       "                'constraint identifiers to take into account the fact that in Gnu-Prolog some built-in constraints are\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n184 M. DUCASSÉ ET AL.\\n\\nsplit into several simpler constraints. The need for this refinement could probably have been detected\\nby other means, the systematic comparison of the two types of traces, however, was a good support\\nto find problems in the low-level implementation, and this quite early in the life time of the software.\\n\\n7 Conclusion\\n\\nIn this article we have presented a methodology to rigorously design and implement tracers in 5\\nsteps: 1) design a formal specification of the trace model, 2) derive a prototype tracer, 3) analyze the\\nproduced traces, 4) implement an efficient tracer, 5) compare the traces produced by the efficient\\nimplementation and the prototype.\\n\\nThe methodology has been used within the context of logic programming where there is a strong\\nbackground on semantics. We, however, believe that the state transition approach can be applied to\\nspecify formal trace models for other programming paradigms.\\n\\nEven if we advocate to follow the complete methodology, some of the steps can be useful with-\\nout the others. For example, even without a formal specification, starting with an easy to build and\\nunderstand prototype tracer is already a major improvement over starting directly by the implemen-\\ntation of a low-level tracer.\\n\\nWe have shown how this methodology has been used to design and implement a real tracer\\nfor CLP(FD) which is able to efficiently generate information required to build interesting graphical\\nviews of executions. The trace model has been designed following mainly user’s concerns whereas\\nusual tracers are designed following mainly implementation concerns. The resulting tracer has per-\\nformances comparable to efficient tracers, therefore the methodology improves the quality of the\\nproduced trace, and does not prevent efficiency.\\n\\nAcknowledgments\\n\\nThe authors would like to thank Rachid Zoumman who implemented the C code which generates\\nthe VRML used in some analyses. They are also grateful to the OADymPPaC partners for fruitful\\ncollaboration. In particular, Narendra Jussien and Jean-Daniel Fekkete helped tune the model.\\n\\nReferences\\n\\n[Apt99] K. Apt. The essence of constraint propagation. Theoretical Computer Science, 221(1-2):179–\\n210, 1999.\\n\\n[ASBC02] M. Agren, T. Szeredi, N. Beldiceanu, and M. Carlsson. Tracing and explaining execution\\nof CLP(FD) programs. In A. Tessier, editor, Proc. of the Workshop on Logic Proramming\\nEnvironmement. CoRR repository cs.SE/0207047, July 2002.\\n\\n[CH00] M. Carro and M. Hermenegildo. The VIFID/TRIFID tool. In Deransart et al. [DHM00],\\nchapter 10.\\n\\n[DHM00] P. Deransart, M. Hermenegildo, and J. Maluszynski, editors. Analysis and visualization tools\\nfor constraint programming, volume 1870 of Lecture Notes in Computer Science. Springer-\\nVerlag, 2000.\\n\\n[DN00] M. Ducassé and J. Noyé. Tracing Prolog programs by source instrumentation is efficient\\nenough. Journal of Logic Programming, 43(2):157–172, May 2000.\\n\\n[Duc99a] M. Ducassé. Abstract views of Prolog executions with Opium. In P. Brna, B. du Boulay, and\\nH. Pain, editors, Learning to Build and Comprehend Complex Information Structures: Prolog as\\na Case Study, Cognitive Science and Technology, chapter 10, pages 223–243. Ablex, 1999.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 185\\n\\n[Duc99b] M. Ducassé. Opium: An extendable trace analyser for Prolog. The Journal of Logic program-\\nming, 39:177–223, 1999. Special issue on Synthesis, Transformation and Analysis of Logic\\nPrograms, A. Bossi and Y. Deville (eds), Also Rapport Technique INRIA 3257.\\n\\n[FLT00] G. Ferrand, W. Lesaint, and A. Tessier. Value withdrawal explanation in CSP. In\\nM. Ducassé, editor, AADEBUG’00 (Fourth International Workshop on Automated Debugging),\\npages 188–201, 2000. The COmputer Research Repository (CORR) cs.SE/0012005.\\n\\n[GP01] GNU-Prolog. A clp(fd) system based on Standard Prolog (ISO) developed by D. Diaz,\\n2001. http://gprolog.sourceforge.net/ Distributed under the GNU license.\\n\\n[Ilo01] Ilog. SOLVER 5.1 reference manual, 2001.\\n\\n[Jah00] E. Jahier. Collecting graphical abstract views of Mercury program executions. In\\nM. Ducassé, editor, Proceedings of the International Workshop on Automated Debugging\\n(AADEBUG2000), Munich, August 2000. Refereed proceedings, the COmputer Research\\nRepository (CORR) cs.SE/0010038.\\n\\n[JB00] N. Jussien and V. Barichard. The palm system: explanation-based constraint program-\\nming. In Proceedings of TRICS: Techniques foR Implementing Constraint programming Systems,\\na post-conference workshop of CP 2000, pages 118–133, Singapore, September 2000.\\n\\n[JDR01] E. Jahier, M. Ducassé, and O. Ridoux. Specifying Prolog trace models with a continuation\\nsemantics. In K.-K. Lau, editor, Logic Based Program Synthesis and Transformation. Springer-\\nVerlag, Lecture Notes in Computer Science 2042, 2001.\\n\\n',\n",
       "                '[LDD03] L. Langevine, M. Ducassé, and P. Deransart. A propagation tracer for Gnu-Prolog: from\\nformal definition to efficient implementation. In C. Palamidessi, editor, Proceedings of the\\n19th Int. Conf. in Logic Programming. Springer-Verlag, Lecture Notes in Computer Science,\\nDecember 2003.\\n\\n[LDDJ01] L. Langevine, P. Deransart, M. Ducassé, and E. Jahier. Tracing executions of clp(fd) pro-\\ngrams: a trace model and an experimental validation environment. Rapport de Recherche\\nRR 4342, INRIA, Novembre 2001.\\n\\n[Lrg01] F. Laburthe and the OCRE research group. CHOCO, a Constraint Programming\\nkernel for solving combinatorial optimization problems, September 2001. Available at\\nhttp://www.choco-constraints.net.\\n\\n[NF89] T. Nicholson and N. Foo. A denotational semantics for Prolog. ACM Transactions on Pro-\\ngramming Languages and Systems, 11(4):650–665, 1989.\\n\\n[SA00] H. Simonis and A. Aggoun. Search-tree visualisation. In Deransart et al. [DHM00], chap-\\nter 7.\\n\\n[SH99] Z. Somogyi and F. Henderson. The implementation technology of the Mercury\\ndebugger. In Proceedings of the Tenth Workshop on Logic Programming Environ-\\nments, volume 30(4). Elevier, Electronic Notes in Theoretical Computer Science, 1999.\\nhttp://www.elsevier.nl/cas/tree/store/tcs/free/entcs/store/tcs30/cover.sub.sht.\\n\\n[SS94] L. Sterling and E. Shapiro. The Art of Prolog, second edition. MIT Press, Cambridge, Mas-\\nsachusetts, 1994. ISBN 0-262-19338-8.\\n\\n[TA95] A. Tolmach and A.W. Appel. A debugger for Standard ML. Journal of Functional Program-\\nming, 5(2):155–200, April 1995.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\tIntroduction\\n\\tFormal specification of a trace model\\n\\tInstrumenting an existing operational semantics\\n\\tSpecifying an abstract operational semantics\\n\\tInformal presentation of domain reduction\\n\\tSamples of formal event rules for CLP(FD)\\n\\tA Trace Example\\n\\tDiscussion\\n\\n\\tImplementation of a prototype tracer\\n\\tDerivation of a prototype tracer from the CLP(FD) trace model\\n\\tDiscussion\\n\\n\\tTrace analysis\\n\\tAnalysis of the produced trace\\n\\tA CLP(FD) visualization of variable updates\\n\\tDiscussion\\n\\n\\tEfficient implementation\\n\\tThe Gnu-Prolog tracer implementation\\n\\tDiscussion\\n\\n\\tValidation \\n\\tValidation of the Gnu-Prolog tracer implementation\\n\\tDiscussion\\n\\n\\tConclusion\\n\\n'],\n",
       "               'language': 'en',\n",
       "               'score': 2.931525707244873,\n",
       "               'vectorized': True}),\n",
       "             ('5ed5k9tq',\n",
       "              {'title': 'Quantification of recombinant core-like particles of bluetongue virus using immunosorbent electron microscopy.',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pubmed/10403670/',\n",
       "               'caption': 'Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody. The CLP concentration in purified preparations was determined to be 6.6 x 10(15) particles/l. CLP concentration in lysates of recombinant baculovirus-infected cells was determined at various times post-infection and shown to reach a value of 3 x 10(15) particles/l of culture medium at 96 h post-infection. The results indicated that immunosorbent electron microscopy, aided by an improved particle counting method, is a simple, rapid and accurate technique for the quantification of virus and virus-like particles produced in large scale in vitro systems.'],\n",
       "               'language': 'en',\n",
       "               'score': 2.728170871734619,\n",
       "               'vectorized': True}),\n",
       "             ('vnmg0zid',\n",
       "              {'title': 'Length of encapsidated cargo impacts stability and structure of in vitro assembled alphavirus core-like particles',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/',\n",
       "               'caption': 'In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs. We hypothesized that cargo neutralizes the basic region of the alphavirus capsid protein and if the cargo is long enough, it will also act to scaffold the CP monomers together. Experimentally we found that CLPs encapsidating short 27mer oligonucleotides were less stable than CLPs encapsidating 48mer or 90mer oligonucleotides under different chemical and thermal conditions. Furthermore, cryo-EM studies showed there were structural differences between CLPs assembled with 27mer and 48mer cargo. To mimic the role of the cargo in CLP assembly we made a mutant (4D) where we substituted a cluster of four Lys residues in the CP with four Asp residues. We found that these few amino acid substitutions were enough to initiate CLP assembly in the absence of cargo. The cargo-free 4D CLPs show higher resistance to ionic strength and increased temperature compared to wild-type cargo containing CLPs suggesting their CLP assembly mechanism might also be different.'],\n",
       "               'language': 'en',\n",
       "               'score': 2.4888174533843994,\n",
       "               'vectorized': True}),\n",
       "             ('aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDA5djEucGRm0',\n",
       "              {'title': None,\n",
       "               'name': '0001009v1.pdf',\n",
       "               'location': 'https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0001/0001009v1.pdf',\n",
       "               'caption': 'Fractal symbolic analysis com- pares a program and its transformed version by repeat- edly simplifying these programs until symbolic analysis becomes tractable, ensuring that equality of simplified programs is sufficient to guarantee equality of the origi- nal programs.',\n",
       "               'index': 'cogsrch-index-files',\n",
       "               'chunks': ['\\nFractal Symbolic Analysis for Program Transformations\\n\\nNikolay Mateev, Vijay Menon, Keshav Pingali\\nDepartment of Computer Science,\\n\\nCornell University, Ithaca, NY 14853\\n\\nAbstract\\n\\nRestructuring compilers use dependence analysis to\\nprove that the meaning of a program is not changed by a\\ntransformation. A well-known limitation of dependence\\nanalysis is that it examines only the memory locations\\nread and written by a statement, and does not assume\\nany particular interpretation for the operations in that\\nstatement. Exploiting the semantics of these operations\\nenables a wider set of transformations to be used, and is\\ncritical for optimizing important codes such as LU fac-\\ntorization with pivoting.\\n\\nSymbolic execution of programs enables the ex-\\nploitation of such semantic properties, but it is in-\\ntractable for all but the simplest programs. In this paper,\\nwe propose a new form of symbolic analysis for use in\\nrestructuring compilers. Fractal symbolic analysis com-\\npares a program and its transformed version by repeat-\\nedly simplifying these programs until symbolic analysis\\nbecomes tractable, ensuring that equality of simplified\\nprograms is sufficient to guarantee equality of the origi-\\nnal programs. We present a prototype implementation of\\nfractal symbolic analysis, and show how it can be used\\nto optimize the cache performance of LU factorization\\nwith pivoting.\\n\\n1 Introduction\\n\\nModern compilers perform source-level transformations\\nof programs to enhance locality and parallelism. Be-\\nfore such transformations can be performed, the source\\nprogram must be analyzed to ensure that the proposed\\ntransformation does not violate the semantics of the pro-\\ngram. The most commonly used analysis technique is\\ndependence analysis. The goal of this technique is to\\ncompute a partial order between the statements of the\\nprogram such that any statement reordering consistent\\nwith this partial order is guaranteed to leave the output\\n\\n0This work was supported by NSF grants CCR-9720211, EIA-\\n9726388 and ACI-9870687.\\n\\nS1: a = 2*a; a = a+b;\\nS2: b = 2*b; => b = 2*b;\\nS3: a = a+b; a = 2*a;\\n(a) Original program (b) Transformed program\\n\\nFigure 1: Simple Reordering of Statements\\n\\nof the program unchanged. In general, three kinds of de-\\npendences may exist from a statement S1 to a statement\\nS2 executed after it.\\n\\n1. Flow-dependence: A flow-dependence exists from\\nS1 to S2 if S1 may write to a memory location read\\nby S2.\\n\\n2. Anti-dependence: An anti-dependence exists from\\nS1 to S2 if S1 may read from a memory location\\nwritten by S2.\\n\\n3. Output-dependence: An output-dependence exists\\nfrom S1 to S2 if S1 may write to a memory location\\nwritten by S2.\\n\\nAlthough dependence analysis is very powerful, it\\nhas its shortcomings, as shown by the simple program in\\nFigure 1(a). In this program, there is a flow-dependence\\nfrom statement S1 to S3 and from S2 to S3, and there\\nis an anti-dependence and output-dependence from S1\\nto S3. There are only two statement reorderings consis-\\ntent with this partial order: the original program, and the\\nprogram obtained by reordering S2 and S1. In particu-\\nlar, the statement order shown in Figure 1(b) is not con-\\nsistent with this partial order, so a compiler that relies\\non dependence analysis will declare that this transfor-\\nmation is not legal since it may not respect the seman-\\ntics of the original program. It is not difficult however\\nto verify by symbolic execution that the two programs\\nin Figure 1 are equivalent (assuming the usual algebraic\\nlaws for numbers). If ����� and\\n\\n� ��� are the values of a\\nand b at the start of either program, the final value in a\\nis �\\t��\\n �����\\r� � ����� and the final value in b is �\\r� � ��� in both\\nprograms. Intuitively, the constraints imposed on trans-\\nformations by dependence analysis are sufficient but not\\nstrictly necessary to guarantee that transformations do\\nnot change the meaning of the program.\\n\\n\\n\\nA more precise variation of dependence analysis is\\nvalue-based dependence analysis [8, 17, 19]. While\\nstandard, or memory-based dependence analysis con-\\nsiders statements that touch the same memory location,\\nvalue-based dependence analysis also requires that there\\nare no intervening writes so that the statements touch the\\nsame value. Even though value-based dependence anal-\\nysis is less restrictive than memory-based dependence\\nanalysis, it is still too conservative for our purposes. It\\nis easy to verify that all dependencies in the example in\\nFigure 1 are also value dependencies.\\n\\nAlthough the program in Figure 1 is contrived, it\\nillustrates an inadequacy of dependence analysis that\\nshows up when dependence analysis is used to restruc-\\nture more realistic codes like LU with pivoting. Intu-\\nitively, dependence analysis considers only the sets of\\nlocations read and written by statements; it does not\\nassume any particular interpretation (meaning) for the\\noperations in each statement. As our simple example\\nshows, exploiting the semantics of these operations can\\n',\n",
       "                'lead to a richer space of program transformations.\\n\\nSymbolic analysis is the usual way of exploiting se-\\nmantics. To compare two programs for equality, we\\nderive expressions for the outputs of these programs as\\nfunctions of inputs, and attempt to prove that these ex-\\npressions are equal. In principle, symbolic analysis is\\nextremely powerful; not only does it subsume depen-\\ndence analysis but it can also be used to prove equal-\\nity of programs that implement very different algorithms\\nsuch as sorting programs that implement quicksort and\\nmergesort. However, for all but the simplest programs,\\nsymbolic execution and comparison is intractable. A\\nlimited kind of symbolic analysis called value number-\\ning [1] and a generalization called global value num-\\nbering [21] are used in optimizing compilers to iden-\\ntify opportunities for common subexpression elimina-\\ntion and constant propagation, but these techniques are\\nnot useful for comparing different programs. Faced with\\nthis intractability, compiler-writers have settled for sim-\\nple pattern-matching to identify computations in which\\nsemantic information can be exploited for restructuring.\\nFor example, all modern restructuring compilers attempt\\nto recognize reductions which are statements in which a\\ncommutative and associative operation like addition is\\napplied to the elements of an array [24]. Unfortunately,\\npattern matching techniques are fragile since they are\\neasily confused by small changes to the pattern such as\\nperforming a reduction to an array location rather than\\nto a scalar variable. Sophisticated symbolic analysis\\ntechniques for finding generalized induction variables\\nhave been developed by Haghighat and Polychronopou-\\nlos [11] and by Rauchwerger and Padua [20], but these\\ntechniques do not apply to the programs that we discuss.\\n\\nIn this paper, we propose a novel way of perform-\\ning symbolic analysis of programs that we call fractal\\nsymbolic analysis. It is based on three ideas.\\n\\n1. If the programs to be compared are too complicated\\nfor symbolic comparison, fractal symbolic analysis\\nsimplifies these programs in a way that ensures that\\nequality of the simplified programs conversatively\\nimplies equality of the original programs.\\n\\n2. In general, it is not clear how such a simplification\\nmay be accomplished, but for codes obtained by\\ncommon program transformations, the appropriate\\nsimplification may be derived from the transforma-\\ntion.\\n\\n3. This simplification process may be applied recur-\\nsively until tractable programs are obtained, which\\nis why we call this approach fractal symbolic anal-\\nysis.\\n\\nOur approach to simplification in this paper is in-\\nspired by Rinard and Diniz [22]. Their approach, called\\ncommutativity analysis, is based on the insight that a se-\\nquence of atomic operations could be executed in any\\npermuted order (e.g., in parallel in their case) if each\\npair of operations can be shown to commute. While\\ntheir analysis is not applicable to the program transfor-\\nmations we consider, we employ a more powerful vari-\\nation of this idea in fractal symbolic analysis.\\n\\nThe rest of this paper is organized as follows. In\\nSection 2, we introduce the highlights of our technol-\\nogy by discussing a small program that is a distillation\\nof LU factorization with pivoting. We then describe\\nour prototype implementation. In Section 3, we dis-\\ncuss the simplification process and derive the rules for\\ndifferent transformations in the literature. In Section 4,\\nwe demonstrate how we perform symbolic analysis once\\nthe programs to be compared are “simple enough”. We\\napply this technology to automatic blocking of LU fac-\\ntorization with pivoting in Section 5 and show that we\\nachieve performance comparable with that of the LA-\\nPACK library [2] on the SGI Octane. Finally, in Sec-\\ntion 6, we discuss ongoing work.\\n\\n2 A simple example\\n\\nFigure 2(a) shows an imperfectly-nested loop nest that\\nwrites to an array A of size N. A read-only array p,\\nwhose role is similar to that of the pivot array in LU fac-\\ntorization, is assumed to contain integers between 1 and\\nN such that p(j) � j. This information about array p\\nmust be provided by the programmer; in the actual LU\\ncode, it is easily deduced by the compiler, as we show\\nin Section 5. In iteration j of the outer loop, the values\\nin A(j) and A(p(j)) are swapped, and each element\\n\\n\\n\\ndo j = 1,N //swap\\nS1: //swap do j = 1,N\\n\\ntmp = A(j); tmp = A(j);\\nA(j) = A(p(j)); A(j) = A(p(j));\\nA(p(j)) = tmp; A(p(j)) = tmp;\\n\\nS2: //update //update\\ndo i = j+1,N do j = 1,N\\n\\nA(i) = A(i)/A(j) do i = j+1,N\\nA(i) = A(i)/A(j);\\n\\n(a) Original Program (b) Transformed Program\\n\\n.......... ..........\\n\\n.......... ..........\\n\\n?\\n\\nS1(1) S1(l)\\n\\nS2(m)\\n\\nS1(N)\\n\\nS2(N)S2(1)\\n\\nS1\\n\\nS2\\n\\n(c) Legality Check for Loop Distribution\\n\\nFigure 2: Loop distribution in a simple program\\n\\nA(i) in the sub-array A(j+1..N) is replaced by some\\nfunction of A(i) and A(j) (e.g., A(i)/A(j) in our\\ncase).\\n\\nIt is convenient to refer collectively to the three state-\\n',\n",
       "                'ments for the swap as S1, and to the update loop as S2.\\nEach dot in Figure 2(c) represents the execution of ei-\\nther S1 or S2 for some iteration of the j loop. We will\\nlet S2(m) denote the execution of statement S2 in iter-\\nation m of the outer loop. Similarly, S1(l) denotes the\\ninstance of S1 for which the j loop index is l.\\n\\nFigure 2(b) shows the result of distributing the j\\nloop over statements S1 and S2. In the transformed\\nprogram, all swaps are done before any of the updates.\\nSince loop distribution changes the order in which oper-\\nations are performed, it is not always legal. In this case,\\nit can be seen that both programs compute the same ar-\\nray A provided p(j) � j.\\n\\nHow can a compiler reach this conclusion?\\n\\n2.1 Dependence Analysis\\n\\nAs described in Section 1, dependence analysis com-\\nputes a partial order between statements (in loop pro-\\ngrams, between statement instances) by determining\\nflow-, anti- and output-dependences. In the program of\\nFigure 2(a), S2(1) reads and writes to location A(2)\\nwhich is later read and written by S1(2). There-\\nfore, there is a flow-dependence, an anti-dependence\\nand an output-dependence from S2(1) to S1(2). In\\nthe transformed program, the order of execution of these\\ntwo instances is reversed. Violating dependence order\\nmay change the answers produced by the program, so\\na compiler that uses dependence analysis will conclude\\nconservatively that loop distribution is not legal.\\n\\n2.2 Symbolic analysis\\n\\nThe most straight-forward kind of symbolic analysis\\nperforms symbolic execution of the program to com-\\npute expressions representing the values in array A at\\nthe end of execution of the original and transformed pro-\\ngrams, and attempts to prove that these expressions are\\nthe same in both programs. This approach is relatively\\nstraightforward for basic blocks such as the programs in\\nFigure 1, but it is not tractable for more complex pro-\\ngrams with loops, conditionals and arrays such as the\\nprograms in Figure 2. For example, what does it mean\\nto execute a loop when the loop bounds are symbolic\\nexpressions? We do not know any tractable way of per-\\nforming symbolic evaluation and comparison even for\\nthe simple program in Figure 2, let alone LU factoriza-\\ntion!\\n\\nA more subtle symbolic analysis strategy is to use\\nproof techniques like computational induction [10] to\\nprove program equality. This approach is used widely\\nin proving the correspondence of denotational and op-\\nerational semantics of programs for example, but it is\\nnot clear how to use this approach for our problem. The\\nintermediate values in array A are quite different in the\\ntwo programs, and it is only at the end of execution that\\nthe values in array A in the two programs are identical,\\nso it is difficult to think of a predicate which can be\\nproved correct using inductive reasoning on the num-\\nber of computational steps. Even if such a predicate can\\nbe designed, it is unclear how a compiler could invent it\\nduring restructuring.\\n\\n2.3 Fractal Symbolic Analysis\\n\\nThese difficulties led us to a new approach to program\\nanalysis that we call fractal symbolic analysis. If com-\\nparing two programs symbolically is too complicated,\\nwe simplify these programs but ensure that equality of\\nthe simplified programs implies equality of the origi-\\nnal programs. Intuitively, traditional symbolic analy-\\nsis attempts to prove a predicate that is both necessary\\nand sufficient to prove program equality, and gives up\\nwhen the programs are too complex; in contrast, frac-\\ntal symbolic analysis handles complexity by attempting\\nto prove stronger predicates that are sufficient (but not\\nalways necessary) for program equality.\\n\\n2.3.1 Simplifying Programs\\n\\nIt is not clear how to carry out this simplification in gen-\\neral, but in the context of this paper, we are interested\\nonly in comparing a program before and after some\\ntransformation. This suggest that we exploit the trans-\\nformation to derive the simplified programs. To under-\\n\\n\\n\\nS1(l): //swap S2(m)://update\\ntmp = A(l); do i = m+1,N\\nA(l) = A(p(l)); A(i) = A(i)/A(m)\\nA(p(l)) = tmp; S1(l)://swap\\n\\nS2(m): //update temp = A(l)\\ndo i = m+1,N A(l) = A(p(l));\\n\\nA(i) = A(i)/A(m) A(p(l)) = tmp;\\n\\n(a) S1(l) before S2(m) (b) S2(m) before S1(l)\\n\\n.......... ..........S1\\n\\nS2\\nS2(m) S2(N)S2(1)\\n\\n.......... ..........\\n\\nS1(l) S1(N)S1(1)\\n\\n(c) Partial loop distribution\\n\\nFigure 3: Two orders of executing statement instances\\n\\nstand this, consider the running example of Figure 2.\\nImagine that loop distribution is accomplished not in a\\nsingle step but incrementally by dragging instances of\\nS1 in Figure 2(c) to the left over instances of S2. When\\nall instances of S1 are scheduled before all instances\\nof S2, we have accomplished loop distribution. At any\\npoint during this process, consider an instance S1(l)\\nthat is executed immediately after an instance of S2(m)\\n(so l � m). Suppose we can show that S1(l) can be\\nscheduled immediately before S2(m) without changing\\nthe result of the program. If so, we can advance the pro-\\n',\n",
       "                'cess of loop distribution one more step; repeating this\\nargument, it is easy to see that loop distribution is le-\\ngal. Therefore, if, for all ������������� , S2(m) and\\nS1(l) can be executed in either order (they commute),\\nloop distribution is legal. The two simplified programs\\nwe have to compare are shown in Figure 3.\\n\\n2.3.2 Symbolic Comparison of Simplified Pro-\\ngrams\\n\\nOur core symbolic comparison engine, described in\\nmore detail in Section 4, can analyze these simpli-\\nfied programs directly since they involve only statement\\ncomposition and loops with no recurrences. Let � ��� de-\\nnote the values in array A before the execution of the\\nprograms in Figures 3(a,b), and let ��� and �\\t denote\\nthe values in array A after the execution of the programs\\nin Figures 3(a) and (b) respectively. Assuming that A is\\nthe only live variable at the end of either program, we\\nmust show that � � = �  .\\n\\nConsider the program of Figure 3(a) first. Let �\"!$#&%(\\'\\ndenote the values in array A after the swap statements\\nhave executed. Examination of the update loop shows\\nthat\\n\\n)+*$,$-/.�021�3547684 -:97; < ):=?>A@$BC,$-�.$D?)E=?>A@FBG, 6 .3 9H-:9 6 97; < ) =?>A@$B ,$-�.\\n\\nNext, we need to express �\"!I#&%(\\' in terms of � ��� . It\\nis easy to verify the following.\\n\\n):=?>A@$BC,$-/.�0KJL M -ON0QPSRT-ON0QUV,WPF.X< )ZY�[\\\\,$-/.-Z0]U^,WPF. < ) Y�[ ,WPF.-_0QP < ) Y�[ ,WUV,WPF.F.\\nBy combining the expressions for � � and �`!$#&%(\\' , we\\n\\ncan express � � in terms of � ��� as follows.\\n\\n)+*$,$-/.a0\\nJbbbbbbbbbbL bbbbbbbbbbM\\n\\n3 9c-Z9 684 ;<�) Yd[ ,$-�.3 9 6e4 -_0QPf97;<�)�Yd[g,WPF.$Dh)�Yd[g, 6 .3 9 6e4 -_0QUV,WPF.�97;<�) Yd[ ,WUV,WPi.F.$D?) Yd[ , 6 .3 9 6e4 -Z97;jR+,$-kN0QPF.�R+,$-kN0QUV,WPF.F.<�)�Yd[g,$-�.$D?)�Yd[\\\\, 6 .\\nWe call such an expression a guarded symbolic ex-\\n\\npression since it is a collection of symbolic terms with\\nguards or predicates that specify the domain of applica-\\nbility of each term.\\n\\nA similar procedure can be applied to compute �  in\\nterms of � ��� to obtain the following guarded symbolic\\nexpression for �  .\\n\\n)Elm,$-/.a0\\nJbbbbbbbbbbL bbbbbbbbbbM\\n\\n3 9c-Z9 684 ;<�) Yd[ ,$-�.3 9 6e4 -_0QPf97;<�)�Yd[g,WPF.$Dh)�Yd[g, 6 .3 9 6e4 -_0QUV,WPF.�97;<�) Yd[ ,WUV,WPi.F.$D?) Yd[ , 6 .3 9 6e4 -Z97;jR+,$-kN0QPF.�R+,$-kN0QUV,WPF.F.<�)�Yd[g,$-�.$D?)�Yd[\\\\, 6 .\\nTo compare ��� with �\\r , it is necessary to consider\\n\\npairs of guards obtained by taking one guard from ���\\nand one from �\\r , and to verify the equality of the cor-\\nresponding symbolic terms if the conjunction of the two\\nguards is true. In this example, it is trivial to verify that� � and �  are equal. We conclude that S1(l) and\\nS2(m) commute; therefore, the two programs in Fig-\\nure 2 are themselves equal.\\n\\nNote that in other programs, such as the programs in\\nFigure 1, we may need to exploit algebraic laws to prove\\nequality of guarded symbolic expressions. Therefore,\\nthe core symbolic comparison engine should itself be\\nable to invoke a symbolic algebra tool like Maple [5].\\n\\n2.3.3 Recursive Simplification\\n\\nIn general, the simplified programs that result by apply-\\ning these rules may themselves be too complicated to\\n\\n\\n\\nS1(l): //swap S2(m,i)://update body\\ntmp = A(l); A(i) = A(i)/A(m);\\nA(l) = A(p(l)); S1(l)://swap\\nA(p(l)) = tmp; temp = A(l);\\n\\nS2(m,i): //update body A(l) = A(p(l));\\nA(i) = A(i)/A(m); A(p(l)) = tmp;\\n\\nFigure 4: Recursive Simplification for the Running Ex-\\nample\\n\\nbe evaluated symbolically. If so, it may be necessary to\\napply these rules to the simplified programs recursively.\\nThis is the case for LU factorization with pivoting, as\\nwe show in Section 5. It is instructive to consider a re-\\ncursive simplification of the programs in Figure 3 that\\neliminates the update loop. We can reorder S1(l) and\\nS2(m) incrementally by dragging instances of the up-\\ndate loop S2(m,i) over S1(l). The legality of each\\nof these incremental steps can be determined by check-\\ning if the programs in Figure 4 produce the same output\\nfor all i,m,l such that �:�n�O��o/pm�q�n� .\\n\\nThe two programs in Figure 4 are delightfully simple\\nsince they are just straight-line programs, but it is easy\\nto show that they are not equal; for example, for rEsut :� � \\nFt � s�� ��� \\n�va\\nFt �m�Fw ��\\n�x � but �  \\nFt � sy� ��� \\nWv&\\n$t �I� . Had\\nwe carried out the simplification of the programs in Fig-\\nure 2 to this level, we would have concluded conserva-\\ntively that the program transformation in Figure 2 is not\\nlegal.\\n\\nThis discussion highlights an important aspect of\\nfractal symbolic analysis: successive applications of\\nsimplification produce successively stronger predicates\\nwhich are less likely to be true. Therefore, the core sym-\\nbolic comparison engine should be as powerful as pos-\\nsible so that simplification can be applied sparingly.\\n\\n3 Fractal Symbolic Analysis\\n\\nA fractal symbolic analyzer for checking legality of\\ntransformations has two components: (i) a core sym-\\nbolic comparison engine for comparing programs that\\nare “simple enough”, and (ii) simplification rules for\\nsimplifying programs that are not simple enough.\\n\\n',\n",
       "                'To prove that a program transformation is valid, the\\ncompiler first attempts symbolic comparison (described\\nin the next section). If the programs are not simple\\nenough, then the compiler invokes the top-level proce-\\ndure called Commute, in Figure 5 for performing fractal\\nsymbolic analysis, passing it two statements and some\\noptional bindings which are constraints on free vari-\\nables. These statements and bindings are obtained by\\nthe compiler from the table in Figure 6 which spec-\\nifies the legality conditions for a number of common\\nprogram transformations [24]. The bindings also in-\\nclude any constraints that the compiler can determine\\nbetween free variables. The Commute procedure returns\\n\\nCommute(!$z|{`z$} , !$z|{`zW~ , � ���/������� ! , � ����� � %(��! ) �\\nif Simple(!Iz|{\"z } ) then\\n\\nif Simple(!$z|{`z ~ )\\nreturn Compare( � !$z|{`z$} ; !$z|{`zW~C� , � !$z|{`zW~ ; !$z|{`z$}I� ,� ����������� ! , � ����� � %(��! )\\n\\nelse\\nreturn Commute(!Iz|{\"zW~ , !$z|{`z$} , � ����������� ! , � ����� � %(�m! )\\n\\nelse\\ncase (!$z|{`z } ) �� !$z|{`z�� } ;!$z|{`z�� �}����\\n\\nreturn Commute(!$z|{`z�� } , !$z|{`z ~ ,� ����������� ! , � ����� � %(�m! ) � Commute(!$z|{`z�� �} , !$z|{`zW~ ,� ����������� ! , � ����� � %(�m! )�\\nif \\'�� �$� then !$z|{`z�� } else !$z|{`z�� �}����\\n\\nreturn Commute(!$z|{`z�� } , !$z|{`zW~ ,� ����������� !(�i\\'�� �$� , � ����� � %(��! ) � Commute(!$z|{`z�� �} ,!Iz|{\"zW~ , � ���/������� !(�?�A\\'�� �$� , � ����� � %��m! )�\\ndo\\n�\\n\\n= � , � !$z|{`z�� }m� �d� �/�\\nreturn Commute(!$z|{`z�� }m� ��� , !$z|{`z ~ ,� ����������� !(�?� �F� �A� � �E� , � ����� � %(��! )��\\n\\nFigure 5: Verifying Commute Conditions\\n\\ntrue if it can prove that the two statements commute\\nunder the constraints expressed by the bindings, and\\nreturns false otherwise. For example, to determine if\\nthe loop distribution in Figure 2 is legal, the compiler\\nwould invoke the Commute procedure with the two state-\\nments S1(l) and S2(m) in Figure 3 and the binding���n�O�����c�&\\n�� � ��� .\\n\\nThe validity of the legality conditions in Figure 6 fol-\\nlows from the following result, variations of which have\\nappeared in the literature [12].\\n\\nLemma 1 Let ��s ��� �(\\xa0 �  g\\xa0 �¢¡ \\xa0(£�£¤£¥\\xa0 � ��¦ be a se-\\nquence of program fragments, and let v be any permuta-\\ntion on � . Define §¨\\n�v � sy�g\\nF� � p��S© �\"ª �¨�nr«�\\xad¬q�n®�¯v&\\nWr � �nv&\\nW¬ � ¦ as the set of pairs of statements reordered\\nby v . Then, the program � is equivalent to the programv&\\n$� � sK�/� \\' � � � \\xa0 � \\' �  � \\xa0 � \\' � ¡ � \\xa0�£¤£�£�\\xa0 � \\' � �G� ¦ if ��� � \\xa0 � © ¦ is\\nequivalent to �/� © \\xa0 � � ¦ where \\n$� � p�� © �±° §¨\\n�v � .\\n\\nProof: The Lemma follows from induction on the cardi-\\nnality of ² ,WUV. . If ³I² ,WU^. ³ 0µ´ then clearly ¶ 0yUV, ¶ . .\\nOtherwise, there must exist an · such that\\n\\nUV, ·^¸ 3 . 4 UV, · . ,\\nwhich implies that\\n\\n, ¶ BC¹ Y�º�*¼»¼½ ¶ B¤¹ YW» .Z¾ ² ,WUV. . Since ¶ B¤¹ Y�»\\nand ¶ BC¹ Y�º�*¼» commute and are adjacent in\\n\\nUV, ¶ . , trans-\\nposing them gives us an equivalent program\\n\\nUÀ¿h, ¶ . where² ,WU�¿|.�Á ² ,WUV. and ³I² ,WU�¿�. ³ 0 ³I² ,WU^. ³�Â 3 . By induction,¶ 0QUV, ¶ . . Ã\\nIntuitively, Lemma 1 allows us to reformulate the\\n\\nproblem of checking legality of a transformation as a\\nproblem of verifying commutativity of statement in-\\nstances that are reordered by that transformation. The\\nvalidity of the rules given in Figure 6 follows directly\\nfrom this result.\\n\\nLet us now consider how the Commute procedure\\nworks. This procedure can be considered to be param-\\neterized by a function called Compare that is the core\\n\\n\\n\\nTransformation Legality Condition\\nLoop Peeling, Index Set Splitting, Skewing Inner\\nby Outer Loop, Stripmining\\n\\ntrue\\n\\nStatement Reordering\\nS1; S2; <-> S2; S1; ÄFÅ {`{ � z � � �dÆ ��Ç Æ  � �\\nLoop Fusion/Fission\\ndo i = 1,n do i = 1,n\\n\\nS1(i); <-> S1(i);\\nS2(i); do i = 1,n\\n\\nS2(i);\\n\\nÄFÅ {`{ � z � � �dÆ � � � � Ç Æ  � { � �¥È �fÉgÊ { É � ÉgÊ �À�\\nLoop Reversal\\ndo i = 1,n do i = n,1,-1\\n\\nS(i); <-> S(i);\\nÄFÅ {`{ � z � � �dÆ � �d� Ç Æ � © � �±È �±ÉgÊ � É © É^Ê �G�\\n\\nLoop Interchange\\ndo i = 1,n do j = 1,m\\n\\ndo j = 1,m <-> do i = 1,n\\nS(i,j); S(i,j);\\n\\nÄFÅ {`{ � z � � �dÆ � \\' ÇWË � Ç Æ � � Ç ! � �fÈ �fÉ^Ê \\' É � ÉgÊ � � �±ÉgÊ ! É:Ë`ÉgÊ { �\\nLinear Loop Transformations\\ndo (i1,i2,...,ik) do (i1’,i2’,...,ik’)\\nS(i1,i2,...,ik); <-> = T(i1,i2,...,ik)\\n\\nS(i1,i2,...,ik);\\nÄFÅ {`{ � z � � �dÆ � Ì �d� Ç Æ �dÌ© � �fÈiÌ �SÍ Ì© �_Î � Ì ����Ï Î �dÌ© ���\\n\\nLoop Tiling\\ndo i = 1,n do I = 1,n,Bi\\n\\ndo j = 1..m <-> do J = 1,m,Bj\\nS(i,j); do i = I,I+Bi-1\\n\\ndo j = J,J+Bj-1\\nS(i,j);\\n\\nÄFÅ {`{ � z � � �dÆ � \\' ÇWË � Ç Æ � � Ç ! � �fÈ�� \\' Ç|Ë ��Í � � Ç ! � � ��Ð ÇWÑ\"Ç \\' Ç|Ë ��Ï ��Ò Ç Æ Ç � Ç ! ���\\nFigure 6: Legality Conditions for Common Program Transformations\\n\\nTransformation Simplification Rule\\nStatement Sequence\\n{S1’; S1\";} B2; <-> B2; {S1\"; S1’;} ÄFÅ {`{ � z � � �dÆ � � ÇWÓ� � � �«ÄFÅ {`{ � z � � ��Æ � � � ÇWÓ� � �\\nLoop\\ndo i = l,u B2;\\n\\nS1(i); <-> do i = l,u\\nB2; S1(i);\\n\\nÄFÅ {`{ � z � � �dÆ � � ��� Ç�Óa ��È � ÉgÊ � É^Ê � �\\nConditional Statement\\nif (pred) then B2;\\n\\nS1’; if (pred) then\\nelse <-> S1’;\\n\\nS1\"; else\\nB2; S1\";\\n\\n',\n",
       "                'ÄFÅ {`{ � z � � �dÆ � � ÇWÓ� ��È \\'�� �I��� �_ÄFÅ {`{ � z � � ��Æ � � � ÇWÓ� �¥È �A\\'�� �$���\\nFigure 7: Recursive Simplification Rules\\n\\nsymbolic comparison engine, invoked when both input\\nstatements are simple enough. We discuss an implemen-\\ntation of this function in Section 4. The boolean function\\nSimple checks whether a statement is simple enough for\\nCompare. If both statements are simple, the comparison\\nengine is invoked; otherwise, the recursive simplifica-\\ntion rules shown in Figure 7 are used to simplify the\\nstatements further. These rules are based on the syntac-\\ntic structure of the two programs to be compared.\\n\\nAs mentioned in Section 2, the precision of frac-\\ntal symbolic analysis depends on the power of the core\\nsymbolic comparison engine. Notice that the procedure\\nin Figure 5 stops simplifying as soon as the statements\\nbeing compared can be handled by the Compare proce-\\ndure. A more powerful Compare procedure will result in\\nfewer levels of simplification and potentially more ac-\\ncurate symbolic analysis.\\n\\n4 Symbolic Comparison\\n\\nWe now describe the core symbolic comparison proce-\\ndure that is invoked after simplification. As mentioned\\nearlier, it is important for this procedure to be as pow-\\nerful as is tractable so that simplification can be applied\\nsparingly. In our work, we have found that it is suffi-\\ncient if the symbolic comparison procedure can handle\\nthe following class of programs.Ô Programs consist of assignment statements, for-\\n\\nloops and conditionals. No unstructured control\\nflow is allowed.Ô Loops do not have loop-carried dependences.Ô Array indices and loop bounds are restricted to\\nbe affine functions of enclosing loop variables and\\nsymbolic constants, and predicates are restricted to\\nbe conjunctions and disjunctions of affine inequal-\\n\\n\\n\\nÕ � ÌÖ � Ê8×ØØØØÙ ØØØØÚ\\n� � %(� � } � ÌÖ � � �$Û \\'�� � !I! � Å � } � ÌÖ �� � %(� � ~ � ÌÖ � � �$Û \\'�� � !I! � Å � ~ � ÌÖ �\\n\\n.\\n\\n.\\n\\n.� � %�� �CÜ � ÌÖ � � �$Û \\'�� � !$! � Å �^Ü � ÌÖ �\\nFigure 8: Guarded Symbolic Expressions\\n\\nCompare(!$z|{`z } , !Iz|{\"z ~ , � ����������� ! , � ����� � %(��! ) �� ����� } = set of live altered variables in !Iz|{\"z$}� ����� ~ = set of live altered variables in !Iz|{\"zW~\\nif(� ����� }fÝÊ � ����� ~ )\\n\\nreturn false\\n\\nfor each % � ÌÖ � in � ����� } �z|� �$� } Ê Build Expr Tree(!$z|{`z$} , % � ÌÖ � ,Þ )z|� �$� ~aÊ Build Expr Tree(!$z|{`z ~ , % � ÌÖ � ,Þ )� ! � } = Normalize GSE(z|� �$� } , � ����������� ! )� ! � ~ = Normalize GSE(z|� �$� ~ , � ����������� ! )\\nif(� Compare GSEs(\\n\\n� ! � } , � ! � ~ )\\nreturn false�\\n\\nreturn true�\\nFigure 9: Comparision of Simple Programs\\n\\nities.\\n\\nThe important constraint is the second one. Al-\\nthough a loop may write to a section of an array that\\nis potentially unbounded at compile-time, at most one\\niteration may effect the value of any given location in an\\narray. This ensures that the symbolic value of a given el-\\nement of the array can be expressed finitely. Techniques\\nsuch as scalar expansion [24] should be used to aggres-\\nsively eliminate loop-carried dependences.\\n\\nWe can then summarize the unbounded set of expres-\\nsions for the values in an entire array with a finite ex-\\npression called a guarded symbolic expression (or GSE\\nfor short) which contains symbolic expressions that hold\\nfor affinely constrained portions of the array as shown\\nin Figure 8. Section 2 contains a number of examples of\\nguarded symbolic expressions.\\n\\nFigure 9 provides a high-level overview of our sym-\\nbolic comparison algorithm. We consider each altered\\nscalar or array variable in the two programs being com-\\npared. Note that we only need to consider live vari-\\nables [1]. If the GSE’s corresponding to each live altered\\nvariable are equal, the two programs are declared to be\\nequal. We now describe how GSE’s are constructed and\\ncompared.\\n\\n4.1 Generation of Conditional Expression\\nTrees\\n\\nA guarded symbolic expression is essentially a descrip-\\ntion of the effect of a program on an array. As an in-\\n\\nBuild Expr Tree(!$z|{`z , z|� �$� , � ���������/� ! ) �\\ncase (z|� �$� ) �\\n\\nOp(Å \\' , z|� �$� } ,..., z|� �I� Ü ) �\\nreturn Op(Å \\' ,\\n\\nBuild Expr Tree(!$z|{`z , z|� �$� } , � ����������� ! ),...,\\nBuild Expr Tree(!$z|{`z , z|� �$� } , � ����������� ! ))\\n\\nCond(\\'�� �$� , z|� �$��ß , z|� �$�(à ) �\\nreturn Cond(\\'�� �$� ,\\n\\nBuild Expr Tree(!$z|{`z , z|� �$� ß , � ����������� ! ),\\nBuild Expr Tree(!$z|{`z , z|� �$�(à , � ����������� ! ))\\n\\nA( ÌÖ ) �\\ncase (!$z|{`z ) ��\\n\\nA’(Îâá Ì ��ã Ä ) = z|� �$� } � Ì ��� ���\\nif (A Ê A’) then\\n\\nreturn Cond(� ����������� !(� ÌÖ Ê ÎTá Ì ��ã Ä ,z|� �$� } � Î�ä } á � ÌÖ\\tå Ä ��� ,A( ÌÖ ))\\nelse\\n\\nreturn A( ÌÖ )� !Iz|{\"z$} ;!$z|{`zW~ ���\\nreturn Build Expr Tree(!$z|{`z } ,\\n\\nBuild Expr Tree(!$z|{`zW~ , z|� �I� , � ����������� ! ),� ����������� ! )�\\nif \\'�� �$� then !$z|{`z$} else !$z|{`zW~ �/�\\n\\nreturn Cond(� ����������� !(�i\\'�� �$� ,\\nBuild Expr Tree(!$z|{`z$} , z|� �I� , � ����������� ! ),\\nBuild Expr Tree(!$z|{`z ~ , z|� �I� , � ����������� ! ))�\\n\\ndo\\n�¼æ\\n\\n= � æ , � æ !$z|{`z$} �\\\\�\\nreturn Build Expr Tree(!$z|{',\n",
       "                \"`z } , z|� �$� ,� ����������� !(�?ç �¼æÀ� � æ � �¼æ �E� æ )���\\n\\nFigure 10: Expression Tree Generation\\n\\nCond(çG© � { ã � � © �Eè�� Ö Ê © ,\\nOp(é ,\\n\\nCond(\\nÖ Ê ' � � � ,A(l),Cond(\\n\\nÖ Ê � ,A(p(l)),A(k))),\\nCond({ Ê ' � � � ,A(l),Cond({ Ê � ,A(p(l)),A(m)))),\\n\\nCond(\\nÖ Ê ' � � � ,A(l),Cond(\\n\\nÖ Ê � ,A(p(l)),A(k))))\\n\\n(i) Conditional Expression Tree for Figure 2(a)\\n\\nCond(\\nÖ Ê ' � � � ,\\n\\nCond(çÀ© � { ã � � © �Eè��_� Ê © ,\\nOp(é ,A(l),A(m)),\\nA(l)),\\n\\nCond(\\nÖ Ê � ,\\n\\nCond(çÀ© � { ã � � © �¨èO� ' � � � Ê © ,\\nOp(é ,A(p(l)),A(m)),\\nA(p(l))),\\n\\nCond(çÀ© � { ã � � © �¨èO� Ö Ê © ,\\nOp(é ,A(k),A(m)),\\nA(k))))\\n\\n(ii) Conditional Expression Tree for Figure 2(b)\\n\\nFigure 11: Two Examples of Conditional Expression\\nTrees\\n\\ntermediate step towards the construction of this descrip-\\ntion, we build a symbolic representation of the program\\nthat we call a conditional expression tree. A conditional\\nexpression tree may be viewed as a functional represen-\\ntation of the portion of the program required to compute\\nthe final values of a given array. Figure 10 shows an al-\\ngorithm to generate such trees. This algorithm processes\\n\\n\\n\\nFactor(z|� �$� ) �\\ncase (z|� �$� ) �\\n\\nOp(Å ' , z|� �I� } ,...,Cond( '�� �$� , z|� �$� z¼ê , z|� �$� ë ê ),..., z|� �I� Ü ) �\\nreturn Factor(Cond('�� �I� ,\\n\\nOp(Å ' , z|� �$� } ,..., z|� �$� z ê ,..., z|� �$��Ü ),\\nOp(Å ' , z|� �$� } ,..., z|� �$� ë ê ,..., z|� �I� Ü )))\\n\\nOp(Å ' , z|� �I� } ,..., z|� �$��Ü ) �\\nreturn Op(Å ' ,Factor(z|� �$� } ),...,,Factor(z|� �$� Ü ))\\n\\nCond('�� �$� , z|� �$��ß , z|� �$��à ) �\\nreturn Cond('�� �$� ,Factor(z|� �$��ß ),Factor(z|� �$�(à ))\\n\\nA( ÌÖ ) �\\nreturn A( ÌÖ )��\\n\\nBuild GSE(z|� �$� , � � %(� � )\\nif (\\n� � %(� � ) then\\ncase (z|� �$� ) �\\n\\nCond('�� �I� , z|� �$� ß , z|� �$�(à ) �\\nreturn Build GSE(z|� �$��ß , � � %�� � � '�� �$� ) ì\\n\\nBuild GSE(z|� �$�(à ,\\n� � %�� � � �A'�� �I� )\\n\\nOp(Å ' , z|� �$� } ,..., z|� �$��Ü ) �\\nA( ÌÖ ) �\\n\\nreturn � � � � %(� � Ç �$Û '�� � ��\\nelse\\n\\nreturn Þ�\\nNormalize GSE(z|� �$� , � ���������/� ! ) �\\n\\nreturn Build GSE(Factor(z|� �$� ),� ���������/� ! )�\\nFigure 12: From Expression Trees to GSE’s\\n\\nthe statements of a program in reverse order, determin-\\ning at each step the tree corresponding to relevant output\\ndata in terms of input data and linking these together to\\nproduce the final result. Figure 11 illustrates the condi-\\ntional expression trees generated from the programs in\\nFigure 2.\\n\\n4.2 Normalization to Guarded Symbolic Ex-\\npressions\\n\\nThe conditional expression trees generated above con-\\ntain a mix of conditions predicated by affine constraints\\non one hand and symbolic expressions on the other. To\\nconvert these to guarded symbolic expressions, we need\\nto separate the two. We accomplish this by factoring the\\naffine constraints outside of the symbolic operations by\\nrepeated application of the following transformation.\\n\\nOp(Å ' , z|� �$� } ,...,Cond( '�� �I� , z|� �$� z ê , z|� �$� ë ê ),..., z|� �$��Ü )í\\nCond('�� �I� ,Op( Å ' , z|� �$� } ,..., z|� �$� z ê ,..., z|� �$��Ü ),\\n\\nOp(Å ' , z|� �$� } ,..., z|� �$� ë ê ,..., z|� �$��Ü ))\\n\\nAt this point, the guards are generated by combining\\nthe predicates at the top of the factored expression tree,\\nand the corresponding symbolic expressions are simply\\ntaken from the subtrees beneath these predicates. This\\nis shown in Figure 12.\\n\\nCompare GSEs(\\n� ! � } , � ! � ~ ) �\\n\\nfor each (\\n� � %�� � } , �$Û '�� } ) in\\n\\n� ! � } �\\nfor each (\\n\\n� � %(� � ~ ,\\n�IÛ '�� ~ ) in\\n\\n� ! � ~ �\\nif (\\n� � %(� � } � � � %(� � ~ ÝÊkî�ï�ð ñ�ò )\\nif (\\n�$Û '���} ÝÊ �$Û '��F~ )\\nreturn false��\\n\\nreturn true�\\nFigure 13: Comparision of GSE’s\\n\\n4.3 Comparison of Guarded Symbolic Expres-\\nsions\\n\\nFinally, Figure 13 illustrates the comparison of two\\nguarded symbolic expressions. There are two steps to\\nthis comparison. First, we must compare each pair of\\naffine guards of the two guarded symbolic expressions.\\nSecond, for any two guards that potentially intersect,\\nwe must compare the corresponding symbolic expres-\\nsions. If all such symbolic expression match, then the\\nguarded symbolic expressions are declared to be equal.\\nThe validity of this conclusion follows from the follow-\\ning argument. Each guard specifies some region of the\\nindex space of the array in question, and the union of\\nthese regions in a guarded symbolic expression is equal\\nto the entire index space of that array. If the values in the\\ntwo guarded symbolic expressions are identical when-\\never their guards intersect, the two array values are ob-\\nviously equal.\\n\\nFor comparison of affine guards, we may employ\\nan integer programming tool such as the Omega Li-\\nbrary [18], which we have chosen for our implemen-\\ntation. If our tool can automatically verify that a pair of\\naffine guards do not intersect, there is no need for further\\ncomparison.\\n\\nFor comparison of symbolic expressions, we cur-\\nrently test for syntactic equality. This is sufficient both\\nfor our simple example and, as we shall see in Section 5,\\nfor LU factorization. It would be easy to use Maple\\nor some other symbolic algebra tool for this test if we\\n\",\n",
       "                'wished to exploit algebraic properties of numbers.\\n\\n5 Blocking LU with pivoting\\n\\nFractal symbolic analysis was developed for use in an\\nongoing project on optimizing the cache behavior of\\ndense numerical linear algebra programs. LU factoriza-\\ntion with partial pivoting is a key routine in this appli-\\ncation area since it is used to solve systems of linear\\nequations of the form Ax = b. Figure 14 shows the\\ncanonical right-looking version of LU factorization with\\npivoting that appears in the literature [9]. In iteration j\\nof the outer loop, computations are performed on col-\\numn j of the matrix A, and a portion of the matrix to\\n\\n\\n\\nthe right of this column is updated. The i and k loops\\nin the update step can be interchanged, giving two ver-\\nsions of right-looking LU factorization. A rather differ-\\nent version of LU factorization is called left-looking LU\\nfactorization; intuitively, this version delays the updates\\nmade by the right-looking version to a column till it is\\ntime to compute with that column.\\n\\nCache-optimized versions of LU factorization can\\nbe found in the LAPACK library [2]. These blocked\\ncodes are too complex to be reproduced here, but they\\nperform much better than the point version shown in\\nFigure 14. Figure 19 shows the performance of the\\npoint version and two blocked versions on an SGI Oc-\\ntane1. One blocked version was obtained from the\\nNetlib repository2, and it is a portable blocked LU that\\ncalls BLAS [9] routines tuned for the Octane to per-\\nform key operations like matrix multiplication. The sec-\\nond blocked version was written at SGI for the Octane.\\nFigure 19 shows that the performance of the point ver-\\nsion degrades to about 70 MFlops for large matrix sizes;\\nin contrast, the Netlib blocked code obtains about 425\\nMFlops, while the SGI blocked code obtains about 475\\nMFlops.\\n\\nLU factorization with pivoting poses a number of\\nchallenges for compiler writers.\\n\\n1. Given point-wise LU factorization with pivoting,\\ncan a compiler automatically generate a cache-\\noptimized version by blocking the code? If so, how\\ndoes the performance of the compiler-optimized\\ncode compare with that of hand-blocked code?\\n\\n2. Modern restructuring compilers can transform one\\nversion of right-looking LU factorization to the\\nother automatically by interchanging the two loops\\nof the update step. Can a compiler transform right-\\nlooking LU to left-looking LU and vice versa?\\n\\nFractal symbolic analysis is crucial to address both\\nthese challenges. For lack of space, we discuss only the\\nproblem of blocking.\\n\\n5.1 Automatic Blocking of LU factorization\\n\\nTo obtain code competitive with LAPACK code, Carr\\nand Lehoucq suggest carrying out the following se-\\nquence of transformations [4].\\n\\n1. Stripmine the outer loop to operate on block-\\ncolumns.\\n\\n2. Index-set-split the expensive update operation to\\n\\n1This 300MHz machine has a 2MB L2 cache, and an R12K pro-\\ncessor. All compiled code was generated using the SGI MIPSpro f77\\ncompiler with flags: -O3 -n32 -mips4.\\n\\n2http://www.netlib.org\\n\\ndo j = 1, N\\n// Pick the pivot\\np(j) = j\\ndo i = j+1, N\\n\\nif abs(A(i,j)) > abs(A(p(j),j))\\np(j) = i\\n\\n// Swap rows\\ndo k = 1, N\\n\\ntmp = A(j,k)\\nA(j,k) = A(p(j),k)\\nA(p(j),k) = tmp\\n\\n// Scale current column\\ndo i = j+1, N\\n\\nA(i,j) = A(i,j) / A(j,j)\\n\\n// Update portion of matrix\\n// to right of column j\\ndo k = j+1, N\\n\\ndo i = j+1, N\\nA(i,k) = A(i,k) - A(i,j)*A(j,k)\\n\\nFigure 14: LU Factorization with Pivoting\\n\\nm+1\\n\\nl\\n\\np(l)\\n\\nAout(s,t)=\\n\\nAin(p(l),t)\\n\\nAin(l,t)-Ain(l,m)*Ain(m,t)\\n\\nAin(s,t)\\n\\nAin(l,t)\\n\\nAin(p(l),t)-Ain(p(l),m)*Ain(m,t)\\n\\nAin(s,t)-Ain(s,m)*Ain(m,t)\\n\\nFigure 15: Regions and Expressions for Simplified LU\\n\\nseparate computation outside the current block-\\ncolumn from that inside.\\n\\n3. Distribute the inner of the stripmined loops to iso-\\nlate the out-of-column update.\\n\\n4. Tile the out-of-column update.\\n\\nThe first of two steps, stripmining and index-set-\\nsplitting, are trivially legal as they do not reorder any\\ncomputation. The next step, loop distribution, is not\\nnecessarily legal. If this legality is checked using depen-\\ndence analysis, the compiler declares the distribution il-\\nlegal if there is a dependence from an iteration B2(m) to\\nan iteration B1(l) where l � m. In fact, such a depen-\\ndence exists in our program; for example, both B2(j)\\nand B1(j+1) read and write to A(m+1,jB+B..N).\\nTherefore, a compiler that relies on dependence analysis\\ncannot block LU with pivoting using the transformation\\nstrategy of Carr and Lehoucq.\\n\\nCarr and Lehoucq suggest that a compiler may be\\nendowed with application-specific information to rec-\\nognize the swap and update operations in LU factoriza-\\ntion, and to realize that they can be legally interchanged.\\n\\n\\n\\ndo jB = 1, N, B\\ndo j = jB, jB+B-1\\n\\nB1(j):\\n// Pick the pivot\\np(j) = j\\ndo i = j+1, N\\n\\nif abs(A(i,j)) > abs(A(p(j),j))\\np(j) = i\\n\\n// Swap rows\\ndo k = 1, N\\n\\ntmp = A(j,k)\\nA(j,k) = A(p(j),k)\\nA(p(j),k) = tmp\\n\\n// Scale column\\ndo i = j+1, N\\n\\nA(i,j) = A(i,j) / A(j,j)\\n\\n// In-Column Update\\ndo k = j+1, jB+B-1\\n\\ndo i = j+1, N\\n',\n",
       "                'A(i,k) = A(i,k) - A(i,j)*A(j,k)\\n\\nB2(j):\\n// Right-Looking Update\\ndo k = jB+B, N\\n\\ndo i = j+1, N\\nA(i,k) = A(i,k) - A(i,j)*A(j,k)\\n\\ndo jB = 1, N, B\\ndo j = jB, jB+B-1\\n\\nB1(j):\\n// Pick the pivot\\np(j) = j\\ndo i = j+1, N\\nif abs(A(i,j)) > abs(A(p(j),j))\\n\\np(j) = i\\n\\n// Swap rows\\ndo k = 1, N\\ntmp = A(j,k)\\nA(j,k) = A(p(j),k)\\nA(p(j),k) = tmp\\n\\n// Scale column\\ndo i = j+1, N\\nA(i,j) = A(i,j) / A(j,j)\\n\\n// In-Column Update\\ndo k = j+1, jB+B-1\\ndo i = j+1, N\\n\\nA(i,k) = A(i,k) - A(i,j)*A(j,k)\\n\\n// Distributed Loop\\ndo j = jB, jB+B-1\\n\\nB2(j):\\n// Right-Looking Update\\ndo k = jB+B-1, N\\ndo i = j+1, N\\n\\nA(i,k) = A(i,k) - A(i,j)*A(j,k)\\n\\n(a) Before Loop Distribution (b) After Loop Distribution\\nFigure 16: LU Factorization: Distribution Step\\n\\nFractal symbolic analysis is a general-purpose technique\\nthat makes this unnecessary.\\n\\nThe rules for legality of loop distribution in Fig 6 re-\\nquire that B1(l) commute with B2(m) where ¬¢óô�xõ�Xt+�ö¬¢ó � óø÷�� , as shown in Figure 17. The\\ncompiler invokes the Commute method in Figure 5 with\\nthese parameters. However, these simpler programs are\\nnot “simple enough”; the loop that computes the pivot\\nin B1.b(l) is a recurrence that cannot be handled by\\nour core symbolic comparison engine, as we discussed\\nin Section 4. Therefore, these programs are simplified\\nagain using the rule for statement sequences in Figure 7.\\nThis requires the compiler to test whether B2(m) com-\\nmutes with the five subblocks in B1(l). With the ex-\\nception of B1.c(l), the data touched by each of the\\nsubblocks of B1(l) is disjoint from the data touched by\\nB2(m). Therefore, the compiler deduces that these sub-\\nblocks commute with B2(m) (a small detail is that the\\nanalysis of whether B1.b(l) commutes with B2(m)\\nrequires an additional step of simplification to eliminate\\nthe recurrence in B1.b(l)).\\n\\nThe difficult part of this process is to demonstrate\\nthat B1.c(l) and B2(m) commute as shown in Fig-\\nure 18. At this point, these programs are “simple\\nenough”, and the Compare method in Figure 9 is invoked\\nto establish equality of the simplified programs. In fact,\\nthey are quite similar to those in our simple example and\\nguarded expressions are generated in the same fashion\\n\\nas discussed in Section 4. The only live, altered variable\\nin either program is the array A, and the Compare method\\ngenerates guarded symbolic expressions for A from each\\nprogram. Both GSE’s generated from Figure 18 contain\\nsix guarded regions, correlating directly to the picture in\\nFigure 15. To prove that the GSE’s are actually equiv-\\nalent, Compare GSEs is invoked to test the 36 pairwise\\nintersections, and the Omega library [18] is used to test\\nthe satisfiability. Only six intersections are non-empty,\\nand the corresponding symbolic expressions are syntac-\\ntically identical in each case. Thus, the compiler is able\\nto demonstrate the equality of the simplified programs\\nand, therefore, the programs in Figure 16.\\n\\nNote that the programs are only equivalent given thatv&\\nW¬ � �c¬ . Techniques such as value propagation [16, 7]\\nhave been developed to perform this type of analysis for\\nindirect array accesses to more accurately compute de-\\npendences. It is clear that this information may easily be\\ninferred from the pivot computation in B1.a and B1.b.\\nThis information should be passed by the compiler as\\nbindings to the method Commute along with the legality\\nconditions in Figure 6.\\n\\nWith this information, our implementation of frac-\\ntal symbolic analysis is able to automatically establish\\nthe legality of the loop distribution transformation in\\nFigure 16. Although the algorithm is exponential (e.g.,\\nthe Omega library itself is exponential), in practice it\\nis reasonably fast. For this example, our implementa-\\n\\n\\n\\nB2(m): do k = jB+B, N\\ndo i = m+1, N\\n\\nA(i,k) = A(i,m) - A(i,m)*A(m,k)\\n\\nB1.a(l): p(l) = l\\n\\nB1.b(l): do i = l+1, N\\nif abs(A(i,l)) > abs(A(p(l),l))\\n\\np(l) = i\\n\\nB1.c(l): do k = 1, N\\ntmp = A(l,k)\\nA(l,k) = A(p(l),k)\\nA(p(l),k) = tmp\\n\\nB1.d(l): do i = l+1, N\\nA(i,l) = A(i,l) / A(l,l)\\n\\nB1.e(l): do k = l+1, jB+B-1\\ndo i = l+1, N\\n\\nA(i,k) = A(i,k) - A(i,l)*A(l,k)\\n\\nB1.a(l): p(l) = l\\n\\nB1.b(l): do i = l+1, N\\nif abs(A(i,l)) > abs(A(p(l),l))\\n\\np(l) = i\\n\\nB1.c(l): do k = 1, N\\ntmp = A(l,k)\\nA(l,k) = A(p(l),k)\\nA(p(l),k) = tmp\\n\\nB1.d(l): do i = l+1, N\\nA(i,l) = A(i,l) / A(l,l)\\n\\nB1.e(l): do k = l+1, jB+B-1\\ndo i = l+1, N\\n\\nA(i,k) = A(i,k) - A(i,l)*A(l,k)\\n\\nB2(m): do k = jB+B, N\\ndo i = m+1, N\\n\\nA(i,k) = A(i,m) - A(i,m)*A(m,k)\\n\\n(a) B2(m); B1(l) (b) B1(l); B2(m)\\nFigure 17: Simplified Comparison #1\\n\\nB2(m): do k = jB+B, N\\ndo i = m+1, N\\n\\nA(i,k) = A(i,m) - A(i,m)*A(m,k)\\n\\nB1.c(l): do k = 1, N\\ntmp = A(l,k)\\nA(l,k) = A(p(l),k)\\nA(p(l),k) = tmp\\n\\nB1.c(l): do k = 1, N\\ntmp = A(l,k)\\nA(l,k) = A(p(l),k)\\nA(p(l),k) = tmp\\n\\nB2(m): do k = jB+B, N\\ndo i = m+1, N\\n\\nA(i,k) = A(i,m) - A(i,m)*A(m,k)\\n\\n(a) B2(m); B1.c(l) (b) B1.c(l); B2(m)\\nFigure 18: Simplified Comparison #2\\n\\ntion, prototyped in Caml-Light [14], took slightly less\\nthan one second, much faster than the corresponding re-\\nduction in execution time of a single application of LU\\n',\n",
       "                'for medium and large size matrices. Most of the analy-\\nsis time is spent on the construction and comparison of\\nguarded symbolic expressions. We are pursuing several\\nstrategies to improve the analysis time.\\n\\n5.2 Experimental Results\\n\\nTo study the effects of automatic blocking, we ran the\\nSGI compiler on the LU code in Figure 16, after loop\\ndistribution is performed. Given just this slightly trans-\\nformed code, the SGI compiler is now able to produce\\nsignificantly faster code that does not degrade as ma-\\ntrices exceed the cache. Once the loop is distributed,\\nthe compiler is able to automatically tile the right-\\nlooking update (B2) and essentially accomplish the last\\nCarr/Lehoucq step listed above.\\n\\nNevertheless, this code, at 200 MFlops, is still a fac-\\ntor of two slower than the LAPACK codes. Further ex-\\nperimentation found the remaining performance gap due\\nthe compiler’s suboptimal treatment of the right-looking\\nupdate computation. Although, the SGI compiler is able\\n\\nto now block the update, we surmise that it may have\\nbeen confused by the partially triangular loop bounds of\\nthe update. When we index-set split the i loop by hand\\nto separate the triangular and rectangular portions of the\\nupdate, the compiler generated substantially faster code\\nachieving over 300 MFlops. Finally, we note that if we\\nreplace the triangular and rectangular portions of the up-\\ndate with the corresponding BLAS-3 calls (DTRSM and\\nDGEMM) used in LAPACK, the resulting code achieves\\nnearly 400 MFlops and is within 10% of Netlib LA-\\nPACK and 20% of the best hand-optimized code. Thus,\\nwith the ability to isolate the update, we believe that\\ncompilers should be able to nearly match the LAPACK\\nas their ability to match the performance of BLAS on\\nperfectly nested codes improves.\\n\\n6 Conclusions and Future Work\\n\\nIn this paper, we presented a new analysis technique\\ncalled fractal symbolic analysis for proving the validity\\nof program transformations.\\n\\nWe are currently exploring different options in the\\ndesign of the fractal symbolic analyzer. In principle,\\n\\n\\n\\n0\\n\\n50\\n\\n100\\n\\n150\\n\\n200\\n\\n250\\n\\n300\\n\\n350\\n\\n400\\n\\n450\\n\\n500\\n\\n10\\n0\\n\\n30\\n0\\n\\n50\\n0\\n\\n70\\n0\\n\\n90\\n0\\n\\n11\\n00\\n\\n13\\n00\\n\\n15\\n00\\n\\n17\\n00\\n\\n19\\n00\\n\\nsize\\n\\nM\\nF\\n\\nlo\\np\\n\\ns\\n\\nSGI Optimized LAPACK\\n\\nNetlib LAPACK\\n\\nDistributed update-BLAS\\n\\nDistributed update-split\\n\\nDistributed update\\n\\nRight-looking LU\\n\\nFigure 19: Transforming LU with Pivoting\\n\\nthe symbolic comparison engine can be extended to rec-\\nognize and summarize reductions involving associative\\narithmetic operations like addition and multiplication,\\nperhaps using the techniques of Haghighat and Poly-\\nchronopoulos [11].\\n\\nAt present, we only perform syntactic comparisons\\nof the symbolic expressions in guarded symbolic ex-\\npressions. A symbolic algebra tool like Maple [5] will\\nadd to the power of the comparison engine, and this\\npower will be useful once we recognize and summa-\\nrize reductions. These enhancements might eliminate\\nthe need for recursive simplification in some programs,\\nbut we do not yet have any applications where this addi-\\ntional power is needed.\\n\\nThe algorithm for generating guarded symbolic ex-\\npressions in Section 2.3.2 is reminiscent of backward\\nslicing [23] which is a technique that isolates the por-\\ntion of a program that may affect the value of a variable\\nat some point in the program. Our algorithm is simpler\\nthan the usual algorithms for backward slicing since the\\nprograms it must deal with have been simplified before-\\nhand by recursive simplification, an operation that has\\nno analog in backward slicing. A similar statement can\\nbe made about the computation of last-write informa-\\ntion [6].\\n\\nFinally, we note that dependence information for\\nloops can be represented abstractly using dependence\\nvectors, cones, polyhedra etc. These representations\\nhave been exploited to synthesize transformation se-\\nquences [3, 13, 15]. At present, we do not know suitable\\nrepresentations for the results of fractal symbolic anal-\\nysis, nor do we know how to synthesize transformation\\nsequences from such information.\\n\\nReferences\\n\\n[1] A. V. Aho, R. Sethi, and J. D. Ullman. Compilers:\\nPrinciples, Techniques and Tools. Addison Wes-\\n\\nley, Reading, MA, second edition, 1986.\\n\\n[2] E. Anderson, Z. Bai, C. Bischof, J. Dem-\\nmel, J. Dongarra, J. Du Croz, A. Greenbaum,\\nS. Hammarling, A. McKenney, S. Ostrouchov, and\\nD. Sorensen, editors. LAPACK Users’ Guide. Sec-\\nond Edition. SIAM, Philadelphia, 1995.\\n\\n[3] U. Banerjee. A theory of loop permutations. In\\nLanguages and compilers for parallel computing,\\npages 54–74, 1989.\\n\\n[4] S. Carr and R. B. Lehoucq. Compiler blockabil-\\nity of dense matrix factorizations. ACM Transac-\\ntions on Mathematical Software, 23(3):336–361,\\nSeptember 1997.\\n\\n[5] B. Char, K. Geddes, and G. Gonnet. The Maple\\nsymbolic computation system. SIGSAM Bulletin\\n(ACM Special Interest Group on Symbolic and\\nAlgebraic Manipulation), 17(3/4):31–42, August/\\nNovember 1983.\\n\\n[6] J.-F. Collard and M. Griebl. A precise fixpoint\\nreaching definition analysis for arrays. In Proc.\\n',\n",
       "                'of 12th International Workshop on Languages\\nand Compilers for Parallel Computing, (LCPC99),\\nAugust 1999.\\n\\n[7] L. A. DeRose. Compiler techniques for MAT-\\nLAB programs. Technical Report 1956, Depart-\\nment of Computer Science, University of Illinois at\\nUrbana-Champaign, Urbana, Illinois, May 1996.\\n\\n[8] P. Feautrier. Dataflow analysis of array and scalar\\nreferences. International Journal of Parallel Pro-\\ngramming, 20(1):23–53 (or 23–52??), February\\n1991.\\n\\n[9] G. Golub and C. V. Loan. Matrix Computations.\\nThe Johns Hopkins University Press, 1996.\\n\\n[10] C. A. Gunter. Semantics of Programming Lan-\\nguages. Foundations of Computing Series. MIT\\nPress, Cambridge, Massachusetts, 1992.\\n\\n[11] M. R. Haghighat and C. D. Polychronopoulos.\\nSymbolic analysis for parallelizing compilers.\\nACM Transactions on Programming Languages\\nand Systems, 18(4):477–518, July 1996.\\n\\n[12] S. M. Johnson. Generation of permutations by\\nadjacent transposition (in Technical Notes and\\nShort Papers). Mathematics of Computation,\\n17(83):282–285, July 1963.\\n\\n\\n\\n[13] M. S. Lam, E. E. Rothberg, and M. E. Wolf. The\\ncache performance and optimizations of blocked\\nalgorithms. In Fourth International Conference\\non Architectural Support for Programming Lan-\\nguages and Operating Systems, pages 63–74, Apr.\\n8–11, 1991.\\n\\n[14] X. Leroy. The Caml Light system, release 0.71.\\nDocumentation and user’s manual. Technical re-\\nport, INRIA, March 1996. Available from Projet\\nCristal at http://pauillac.inria.fr.\\n\\n[15] W. Li and K. Pingali. A singular loop transfor-\\nmation based on non-singular matrices. Inter-\\nnational Journal of Parallel Programming, 22(2),\\nApril 1994.\\n\\n[16] V. Maslov. Enhancing array dataflow dependence\\nanalysis with on-demand global value propagation.\\nIn Proc. International Conference on Supercom-\\nputing, pages 265–269, July 1995.\\n\\n[17] D. E. Maydan, S. P. Amarasinghe, and M. S. Lam.\\nData dependence and data-flow analysis of arrays.\\nIn 5th Workshop on Languages and Compilers for\\nParallel Computing, pages 434–448, August 1992.\\n\\n[18] W. Pugh. The Omega test: A fast and practi-\\ncal integer programming algorithm for dependence\\nanalysis. In Communications of the ACM, pages\\n102–114, Aug. 1992.\\n\\n[19] W. Pugh and D. Wonnacott. An exact method\\nfor analysis of value-based array data depen-\\ndences. Technical Report CS-TR-3196, Univer-\\nsity of Maryland, College Park, Portland, Ore., De-\\ncember 1993.\\n\\n[20] L. Rauchwerger and D. A. Padua. The LRPD test:\\nSpeculative run-time parallelization of loops with\\nprivatization and reduction parallelization. IEEE\\nTransactions on Parallel and Distributed Systems,\\n10(2), February 1999.\\n\\n[21] J. H. Reif and R. E. Tarjan. Symbolic program\\nanalysis in almost linear time. SIAM Journal on\\nComputing, 11(1):81–93, February 1982.\\n\\n[22] M. C. Rinard and P. C. Diniz. Commutativity anal-\\nysis: a new analysis technique for parallelizing\\ncompilers. ACM Transactions on Programming\\nLanguages and Systems, 19(6):942–991, Novem-\\nber 1997.\\n\\n[23] M. Weiser. Program slicing. IEEE Transactions\\non Software Engineering, 10(4):352–357, 1984.\\n\\n[24] M. Wolfe. High Performance Compilers for Paral-\\nlel Computing. Addison-Wesley Publishing Com-\\npany, 1995.\\n\\n\\n'],\n",
       "               'language': 'en',\n",
       "               'score': 2.2942707538604736,\n",
       "               'vectorized': True}),\n",
       "             ('u2g30x1j',\n",
       "              {'title': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7131174/',\n",
       "               'caption': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP).',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['The isotype antibody responses to bovine IND P(5), G6 and simian SA11 P(2), G3 rotavirus and SA11 rotavirus proteins (VP4, VP6 and VP7) in serum, colostrum and milk were analysed by ELISA in three groups of vaccinated cows and nonvaccinated controls. Pregnant cows were vaccinated intramuscularly and intramammarily with recombinant baculovirus-expressed SA11 rotavirus VLP (triple-layered virus-like particles containing rotavirus VP2, VP4, VP6 and VP7); CLP (double-layered core-like particles containing rotavirus VP2 and VP6); or inactivated SA11 rotavirus, respectively. Rotavirus antigen titers were highest (30–200-fold) in ELISA in the VLP vaccine compared to the inactivated SA11 vaccine. The IgG1, IgG2 and IgM geometric mean antibody titers (GMT) to rotavirus (titers to bovine rotavirus vs SA11 rotavirus did not differ significantly for any isotype or group) and the IgG2 GMT to VP6 in serum at calving in the vaccinated groups were significantly (P <0.05) higher than in the control group. In colostrum, IgG1 and IgA rotavirus antibody titers were significantly elevated for VLP (IgG1 GMT 832225; IgA GMT 16384), CLP (IgG1 GMT 660561; IgA GMT 10321) and SA11 (IgG1 GMT 131072; IgA GMT 1448) vaccinated cows compared to control cows (IgG1 GMT 11585; IgA GMT 45). The IgG1 and IgA GMT to rotavirus were significantly elevated (6–100-fold) in milk of VLP and CLP vaccinated cows compared to SA11 vaccinated or control cows. The isotype antibody responses to VP6 in serum, colostrum and milk paralleled the responses to rotavirus, but titers were ∼2–10-fold lower. Only cows vaccinated with VLP had significantly enhanced serum, colostral and milk antibody titers to rotavirus VP4 and VP7. These results demonstrate that rotavirus antibody titers in serum, colostrum and milk are significantly enhanced by use of non-infectious VLP, CLP and inactivated SA11 rotavirus vaccines, but the VLP or CLP vaccines induced the highest antibody responses, corresponding to their higher rotavirus antigen titers measured by ELISA.'],\n",
       "               'language': 'en',\n",
       "               'score': 2.1349570751190186,\n",
       "               'vectorized': True}),\n",
       "             ('5o38ihe0',\n",
       "              {'title': 'A model of tripeptidyl-peptidase I (CLN2), a ubiquitous and highly conserved member of the sedolisin family of serine-carboxyl peptidases',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC280685/',\n",
       "               'caption': 'BACKGROUND: Tripeptidyl-peptidase I, also known as CLN2, is a member of the family of sedolisins (serine-carboxyl peptidases). In humans, defects in expression of this enzyme lead to a fatal neurodegenerative disease, classical late-infantile neuronal ceroid lipofuscinosis.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['BACKGROUND: Tripeptidyl-peptidase I, also known as CLN2, is a member of the family of sedolisins (serine-carboxyl peptidases). In humans, defects in expression of this enzyme lead to a fatal neurodegenerative disease, classical late-infantile neuronal ceroid lipofuscinosis. Similar enzymes have been found in the genomic sequences of several species, but neither systematic analyses of their distribution nor modeling of their structures have been previously attempted. RESULTS: We have analyzed the presence of orthologs of human CLN2 in the genomic sequences of a number of eukaryotic species. Enzymes with sequences sharing over 80% identity have been found in the genomes of macaque, mouse, rat, dog, and cow. Closely related, although clearly distinct, enzymes are present in fish (fugu and zebra), as well as in frogs (Xenopus tropicalis). A three-dimensional model of human CLN2 was built based mainly on the homology with Pseudomonas sp. 101 sedolisin. CONCLUSION: CLN2 is very highly conserved and widely distributed among higher organisms and may play an important role in their life cycles. The model presented here indicates a very open and accessible active site that is almost completely conserved among all known CLN2 enzymes. This result is somehow surprising for a tripeptidase where the presence of a more constrained binding pocket was anticipated. This structural model should be useful in the search for the physiological substrates of these enzymes and in the design of more specific inhibitors of CLN2.'],\n",
       "               'language': 'en',\n",
       "               'score': 2.0748074054718018,\n",
       "               'vectorized': True}),\n",
       "             ('4mnaicki',\n",
       "              {'title': 'Subversion of Cellular Autophagosomal Machinery by RNA Viruses',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1084330/',\n",
       "               'caption': 'Subversion of Cellular Autophagosomal Machinery by RNA Viruses. Infection of human cells with poliovirus induces the proliferation of double-membraned cytoplasmic vesicles whose surfaces are used as the sites of viral RNA replication and whose origin is unknown.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['Infection of human cells with poliovirus induces the proliferation of double-membraned cytoplasmic vesicles whose surfaces are used as the sites of viral RNA replication and whose origin is unknown. Here, we show that several hallmarks of cellular autophagosomes can be identified in poliovirus-induced vesicles, including colocalization of LAMP1 and LC3, the human homolog of Saccharomyces cerevisiae Atg8p, and staining with the fluorophore monodansylcadaverine followed by fixation. Colocalization of LC3 and LAMP1 was observed early in the poliovirus replicative cycle, in cells infected with rhinoviruses 2 and 14, and in cells that express poliovirus proteins 2BC and 3A, known to be sufficient to induce double-membraned vesicles. Stimulation of autophagy increased poliovirus yield, and inhibition of the autophagosomal pathway by 3-methyladenine or by RNA interference against mRNAs that encode two different proteins known to be required for autophagy decreased poliovirus yield. We propose that, for poliovirus and rhinovirus, components of the cellular machinery of autophagosome formation are subverted to promote viral replication. Although autophagy can serve in the innate immune response to microorganisms, our findings are inconsistent with a role for the induced autophagosome-like structures in clearance of poliovirus. Instead, we argue that these double-membraned structures provide membranous supports for viral RNA replication complexes, possibly enabling the nonlytic release of cytoplasmic contents, including progeny virions, from infected cells.'],\n",
       "               'language': 'en',\n",
       "               'score': 2.0603506565093994,\n",
       "               'vectorized': True}),\n",
       "             ('gdsfkw1b',\n",
       "              {'title': 'Protein secretion in Lactococcus lactis : an efficient way to increase the overall heterologous protein production',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC545053/',\n",
       "               'caption': 'Lactococcus lactis, the model lactic acid bacterium (LAB), is a food grade and well-characterized Gram positive bacterium. It is a good candidate for heterologous protein delivery in foodstuff or in the digestive tract. L. lactis can also be used as a protein producer in fermentor.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['Lactococcus lactis, the model lactic acid bacterium (LAB), is a food grade and well-characterized Gram positive bacterium. It is a good candidate for heterologous protein delivery in foodstuff or in the digestive tract. L. lactis can also be used as a protein producer in fermentor. Many heterologous proteins have already been produced in L. lactis but only few reports allow comparing production yields for a given protein either produced intracellularly or secreted in the medium. Here, we review several works evaluating the influence of the localization on the production yields of several heterologous proteins produced in L. lactis. The questions of size limits, conformation, and proteolysis are addressed and discussed with regard to protein yields. These data show that i) secretion is preferable to cytoplasmic production; ii) secretion enhancement (by signal peptide and propeptide optimization) results in increased production yield; iii) protein conformation rather than protein size can impair secretion and thus alter production yields; and iv) fusion of a stable protein can stabilize labile proteins. The role of intracellular proteolysis on heterologous cytoplasmic proteins and precursors is discussed. The new challenges now are the development of food grade systems and the identification and optimization of host factors affecting heterologous protein production not only in L. lactis, but also in other LAB species.'],\n",
       "               'language': 'en',\n",
       "               'score': 1.5520832538604736,\n",
       "               'vectorized': True}),\n",
       "             ('t35n7bk9',\n",
       "              {'title': 'Multi-faceted, multi-versatile microarray: simultaneous detection of many viruses and their expression profiles',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC420498/',\n",
       "               'caption': 'Multi-faceted, multi-versatile microarray: simultaneous detection of many viruses and their expression profiles. There are hundreds of viruses that infect different human organs and cause diseases. Some fatal emerging viral infections have become serious public health issues worldwide.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['There are hundreds of viruses that infect different human organs and cause diseases. Some fatal emerging viral infections have become serious public health issues worldwide. Early diagnosis and subsequent treatment are therefore essential for fighting viral infections. Current diagnostic techniques frequently employ polymerase chain reaction (PCR)-based methods to quickly detect the pathogenic viruses and establish the etiology of the disease or illness. However, the fast PCR method suffers from many drawbacks such as a high false-positive rate and the ability to detect only one or a few gene targets at a time. Microarray technology solves the problems of the PCR limitations and can be effectively applied to all fields of molecular medicine. Recently, a report in Retrovirology described a multi-virus DNA array that contains more than 250 open reading frames from eight human viruses including human immunodeficiency virus type 1. This array can be used to detect multiple viral co-infections in cells and in vivo. Another benefit of this kind of multi-virus array is in studying promoter activity and viral gene expression and correlating such readouts with the progression of disease and reactivation of latent infections. Thus, the virus DNA-chip development reported in Retrovirology is an important advance in diagnostic application which could be a potent clinical tool for characterizing viral co-infections in AIDS as well as other patients.'],\n",
       "               'language': 'en',\n",
       "               'score': 1.5344668626785278,\n",
       "               'vectorized': True}),\n",
       "             ('wutnzzhg',\n",
       "              {'title': 'Pro/con clinical debate: Isolation precautions for all intensive care unit patients with methicillin-resistant Staphylococcus aureus colonization are essential',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC468889/',\n",
       "               'caption': 'This issue, coupled with recent outbreaks of illnesses that pose a direct risk to ICU staff (such as SARS [severe acute respiratory syndrome]), has led to renewed emphasis on infection control measures and practitioners in the ICU. Infection control measures frequently cause clinicians to practice in a more time consuming way.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': [\"Antibiotic-resistant bacteria are an increasingly common problem in intensive care units (ICUs), and they are capable of impacting on patient outcome, the ICU's budget and bed availability. This issue, coupled with recent outbreaks of illnesses that pose a direct risk to ICU staff (such as SARS [severe acute respiratory syndrome]), has led to renewed emphasis on infection control measures and practitioners in the ICU. Infection control measures frequently cause clinicians to practice in a more time consuming way. As a result it is not surprising that ensuring compliance with these measures is not always easy, particularly when their benefit is not immediately obvious. In this issue of Critical Care, two experts face off over the need to isolate patients infected with methicillin-resistant Staphylococcus aureus.\"],\n",
       "               'language': 'en',\n",
       "               'score': 1.4881280660629272,\n",
       "               'vectorized': True}),\n",
       "             ('bbvxu8op',\n",
       "              {'title': 'Comparisons of substitution, insertion and deletion probes for resequencing and mutational analysis using oligonucleotide microarrays',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549431/',\n",
       "               'caption': 'Although oligonucleotide probes complementary to single nucleotide substitutions are commonly used in microarray-based screens for genetic variation, little is known about the hybridization properties of probes complementary to small insertions and deletions.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': ['Although oligonucleotide probes complementary to single nucleotide substitutions are commonly used in microarray-based screens for genetic variation, little is known about the hybridization properties of probes complementary to small insertions and deletions. It is necessary to define the hybridization properties of these latter probes in order to improve the specificity and sensitivity of oligonucleotide microarray-based mutational analysis of disease-related genes. Here, we compare and contrast the hybridization properties of oligonucleotide microarrays consisting of 25mer probes complementary to all possible single nucleotide substitutions and insertions, and one and two base deletions in the 9168 bp coding region of the ATM (ataxia telangiectasia mutated) gene. Over 68 different dye-labeled single-stranded nucleic acid targets representing all ATM coding exons were applied to these microarrays. We assess hybridization specificity by comparing the relative hybridization signals from probes perfectly matched to ATM sequences to those containing mismatches. Probes complementary to two base substitutions displayed the highest average specificity followed by those complementary to single base substitutions, single base deletions and single base insertions. In all the cases, hybridization specificity was strongly influenced by sequence context and possible intra- and intermolecular probe and/or target structure. Furthermore, single nucleotide substitution probes displayed the most consistent hybridization specificity data followed by single base deletions, two base deletions and single nucleotide insertions. Overall, these studies provide valuable empirical data that can be used to more accurately model the hybridization properties of insertion and deletion probes and improve the design and interpretation of oligonucleotide microarray-based resequencing and mutational analysis.'],\n",
       "               'language': 'en',\n",
       "               'score': 1.322686791419983,\n",
       "               'vectorized': True}),\n",
       "             ('2su7oqbz',\n",
       "              {'title': 'Locked nucleic acid (LNA) mediated improvements in siRNA stability and functionality',\n",
       "               'name': 'metadata.csv',\n",
       "               'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC546170/',\n",
       "               'caption': 'Locked nucleic acid (LNA) mediated improvements in siRNA stability and functionality. Therapeutic application of the recently discovered small interfering RNA (siRNA) gene silencing phenomenon will be dependent on improvements in molecule bio-stability, specificity and delivery.',\n",
       "               'index': 'cogsrch-index-csv',\n",
       "               'chunks': [\"Therapeutic application of the recently discovered small interfering RNA (siRNA) gene silencing phenomenon will be dependent on improvements in molecule bio-stability, specificity and delivery. To address these issues, we have systematically modified siRNA with the synthetic RNA-like high affinity nucleotide analogue, Locked Nucleic Acid (LNA). Here, we show that incorporation of LNA substantially enhances serum half-life of siRNA's, which is a key requirement for therapeutic use. Moreover, we provide evidence that LNA is compatible with the intracellular siRNA machinery and can be used to reduce undesired, sequence-related off-target effects. LNA-modified siRNAs targeting the emerging disease SARS, show improved efficiency over unmodified siRNA on certain RNA motifs. The results from this study emphasize LNA's promise in converting siRNA from a functional genomics technology to a therapeutic platform.\"],\n",
       "               'language': 'en',\n",
       "               'score': 1.2667738199234009,\n",
       "               'vectorized': True}),\n",
       "             ('aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDE1djEucGRm0',\n",
       "              {'title': 'arXiv:cs/0001015v1  [cs.AI]  19 Jan 2000',\n",
       "               'name': '0001015v1.pdf',\n",
       "               'location': 'https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0001/0001015v1.pdf',\n",
       "               'caption': '• Second, the set of conceivable worlds—the union of the set of “possible” worlds considered when evaluating L and the set of “impossible” worlds considered when evaluating N—is fixed, independent of the situation (W,w); it is always the set of all truth assignments.',\n",
       "               'index': 'cogsrch-index-files',\n",
       "               'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n00\\n\\n01\\n01\\n\\n5v\\n1 \\n\\n [\\ncs\\n\\n.A\\nI]\\n\\n  1\\n9 \\n\\nJa\\nn \\n\\n20\\n00\\n\\nMulti-Agent Only Knowing\\n\\nJoseph Y. Halpern\\n\\nDepartment of Computer Science\\nCornell University\\nIthaca, NY 14850\\n\\nhalpern@cs.cornell.edu\\nhttp://www.cs.cornell.edu/home/halpern\\n\\nGerhard Lakemeyer\\n\\nDepartment of Computer Science\\nAachen University of Technology\\n\\nD-52056 Aachen, Germany\\ngerhard@cs.rwth-aachen.de\\n\\nhttp://www-i5.informatik.rwth-aachen.de/gerhard\\n\\nFebruary 1, 2008\\n\\nAbstract\\n\\nLevesque introduced a notion of “only knowing”, with the goal of capturing certain types\\n\\nof nonmonotonic reasoning. Levesque’s logic dealt with only the case of a single agent.\\n\\nRecently, both Halpern and Lakemeyer independently attempted to extend Levesque’s logic\\n\\nto the multi-agent case. Although there are a number of similarities in their approaches, there\\n\\nare some significant differences. In this paper, we reexamine the notion of only knowing,\\n\\ngoing back to first principles. In the process, we simplify Levesque’s completeness proof,\\n\\nand point out some problems with the earlier definitions. This leads us to reconsider what\\n\\nthe properties of only knowing ought to be. We provide an axiom system that captures our\\n\\ndesiderata, and show that it has a semantics that corresponds to it. The axiom system has\\n\\nan added feature of interest: it includes a modal operator for satisfiability, and thus provides\\n\\na complete axiomatization for satisfiability in the logic K45.\\n\\nhttp://arXiv.org/abs/cs/0001015v1\\nhttp://www.cs.cornell.edu/home/halpern\\nhttp://www-i5.informatik.rwth-aachen.de/gerhard\\n\\n\\n1 Introduction\\n\\nLevesque [14] introduced a notion of “only knowing”, with the goal of capturing\\ncertain types of nonmonotonic reasoning. In particular, he hoped to capture the type\\nof reasoning that says “If all I know is that Tweety is a bird, and that birds typically\\nfly, then I can conclude that Tweety flies”.1 Levesque’s logic dealt only with the\\ncase of a single agent. It is clear that in many applications of such nonmonotonic\\nreasoning, there are several agents in the picture. For example, it may be the case\\nthat all Jack knows about Jill is that Jill knows that Tweety is a bird and that birds\\ntypically fly. Jack may then want to conclude that Jill knows that Tweety flies.\\n\\nRecently, each of us [5, 12] independently attempted to extend Levesque’s logic to\\nthe multi-agent case. Although there are a number of similarities in the approaches,\\nthere are some significant differences. In this paper, we reexamine the notion of only\\nknowing, going back to first principles. In the process, we point out some problems\\nwith both of the earlier definitions. This leads us to consider what the properties\\nof only knowing ought to be. We provide an axiom system that captures all our\\ndesiderata, and show that it has a semantics that corresponds to it. The axiom\\nsystem has an added feature of interest: it involves enriching the language with a\\nmodal operator for satisfiability, and thus provides an axiomatization for satisfiability\\nin K45. Unfortunately, the semantics corresponding to this axiomatization is not as\\nnatural as we might like. It remains an open question whether there is a natural\\nsemantics for only knowing that corresponds to this axiomatization.\\n\\nThe rest of this paper is organized as follows. In the next section, we review\\nthe basic ideas of Levesque’s logic and provide an alternative semantics. The use of\\nthe alternative semantics leads to a simplification of Levesque’s completeness proof.\\nIn Section 3, we review Lakemeyer’s approach, which we call the canonical-model\\napproach, and discuss some of its strengths and weaknesses. In Section 4, we go\\nthrough the same process for Halpern’s approach. In Section 5, we consider our new\\napproach. Much of the discussion in Sections 3, 4, and 5 is carried out in terms of\\nthree critical properties of Levesque’s approach which we cull out in Section 2. In\\nparticular, we examine to what extent each of the approaches satisfies these properties.\\nIn Section 6, we show how the logic can be used, and discuss its relationship to Moore’s\\nautoepistemic logic [15]. Levesque showed that the single-agent version of his logic of\\nonly knowing was closely connected to autoepistemic logic. We extend his result to\\nthe multi-agent case. We conclude in Section 7 with some discussion of only knowing.\\n\\n2 Levesque’s Logic of Only Knowing\\n\\nWe begin by reconsidering Levesque’s definition. Let Φ be a set of primitive propo-\\nsitions. Let ONL(Φ) be a propositional modal language formed by starting with\\nthe primitive propositions in Φ, and closing off under the classical operators ¬ and\\n∨ and two modalities, L and N . We omit the Φ whenever it is clear from context\\nor not relevant to the discussion. We freely use other connectives like ∧, ⇒, and\\n⇔ as syntactic abbreviations of the usual kind. In addition, we take Oα to be an\\n\\n1The reader should feel free to substitute “believe” anywhere we say “know”. Indeed, the formal\\n',\n",
       "                'logic that we use, which is based on the modal logic K45, is more typically viewed as a logic of belief\\nrather than knowledge.\\n\\n1\\n\\n\\n\\nabbreviation for Lα∧N¬α. Here Lα should be read as “the agent knows or believes\\n(at least) α”, Nα should be read as “the agent believes at most ¬α” (so that N¬α is\\n“the agent believes at most α”) and Oα should be read as “the agent knows only α”.\\nWe define an objective formula to be a propositional formula (i.e., a formula with no\\nmodal operators), a subjective formula to be a Boolean combination of formulas of\\nthe form Lϕ or Nϕ, and a basic formula to be a formula which does not mention N .\\n\\nLevesque gave semantics to knowing and only knowing using the standard possible-\\nworlds approach. In the single-agent case, we can identify a situation with a pair\\n(W,w), where w is a possible world (represented as a truth assignment to the primitive\\npropositions) and W consists of a set of possible worlds. Intuitively, W is the set of\\nworlds which the agent considers (epistemically) possible, and w describes the real\\nworld. We do not require that w ∈ W or that W 6= ∅.2 As usual, we say that the\\nagent knows (at least) α if α is true in all the worlds that the agent considers possible.\\nFormally, the semantics of the modality L and the classical connectives is given as\\nfollows.\\n\\n(W,w) |= p if w |= p if p is a primitive proposition.\\n(W,w) |= ¬α if (W,w)|6=α.\\n(W,w) |= α ∨ β if (W,w) |= α or (W,w) |= β.\\n(W,w) |= Lα if (W,w′) |= α for all w′ ∈ W .\\n\\nNotice that if Lα holds, then the agent may know more than α. For example, Lp\\ndoes not preclude L(p∧ q) from holding. This is why we should think of Lα as saying\\nthat the agent knows at least α.\\n\\nIt is well-known that this logic is characterized by the axiom system K45. For\\nconvenience, we describe K45 here:\\n\\nAxioms:\\n\\nP. All instances of axioms of propositional logic.\\nK. (Lϕ ∧ L(ϕ⇒ ψ)) ⇒ Lψ.\\n4. Lϕ⇒ LLϕ.\\n5. ¬Lϕ⇒ L¬Lϕ.\\n\\nInference Rules:\\n\\nR1. From ϕ and ϕ⇒ ψ infer ψ.\\nR2. From ϕ infer Lϕ.\\n\\nThe axioms 4 and 5 are called the positive introspection axiom and negative intro-\\nspection axiom, respectively. They are appropriate for agents that are sufficiently\\nintrospective so that they know what they know and do not know.\\n\\nHow do we give precise semantics to N? That is, when should we say that (W,w) |=\\nNβ? Intuitively, Nβ is true if β is true at all the worlds that the agent does not\\nconsider possible. It seems fairly clear from the intuition that we need to evaluate\\nthe truth of β in worlds w′ /∈W ,3 since these are the worlds that the agent considers\\nimpossible in (W,w). But if β is a complicated formula involving nested L operators,\\nthen we cannot simply evaluate the truth of β at a world w′. We need to have a set\\nof worlds too. In fact, the set of possible worlds we use is still W . That is, while\\n\\n2By requiring that W is nonempty, we get the modal logic KD45; by requiring that w ∈ W , we\\nget S5.\\n\\n3Note that, since we defined worlds extensionally as truth assignments, the set of impossible\\nworlds is well-defined and fixed for a given W .\\n\\n2\\n\\n\\n\\nevaluating the truth of β in the impossible worlds, the agent keeps the set of worlds\\nhe considers possible fixed. Formally, we define\\n\\n(W,w) |= Nα if (W,w′) |= α for all w′ /∈W .\\n\\nLet us stress three important features of this definition.\\n\\n• First, as we have already observed, the set of possibilities is kept fixed when we\\nevaluate Nα.\\n\\n• Second, the set of conceivable worlds—the union of the set of “possible” worlds\\nconsidered when evaluating L and the set of “impossible” worlds considered\\nwhen evaluating N—is fixed, independent of the situation (W,w); it is always\\nthe set of all truth assignments.\\n\\n• Finally, for every set of conceivable worlds, there is a model where that set is\\nprecisely the set of worlds that the agent considers possible.\\n\\nRoughly speaking, the first property is what is required for A4, while the second\\nproperty is what is required for A5. The intent of the third property is to make it\\npossible that any objective formula can be “all you know.” As we shall see in Section 5,\\nin a precise sense, the third property is somewhat stronger than we actually need. All\\nwe really need is that for any objective formulas the set of all worlds satisfying these\\nformulas can be considered possible. We return to these properties for guidance when\\nwe discuss possible ways of extending Levesque’s semantics to the multi-agent case.\\n\\nSince Oα is an abbreviation for Lα ∧N¬α, we have that\\n\\n(W,w) |= Oα if for all worlds w′, w′ ∈ W iff (W,w′) |= α.\\n\\nAs it stands, the semantics has the somewhat odd property that there are situa-\\ntions that agree on all basic beliefs yet disagree on what is only believed. As pointed\\nout by Levesque [14], the problem is that there are far too many sets of worlds than\\nthere are basic belief sets. In order to find a perfect match between the sets of ba-\\nsic beliefs an agent may hold and sets of worlds, Levesque introduces what he calls\\nmaximal sets of worlds. ',\n",
       "                'In essence, a maximal set is the largest set in the sense that\\nadding any other world to it would change the agent’s basic beliefs. Furthermore,\\nevery set of worlds can be extended to a unique maximal set of worlds. It is well\\nknown that in the logic K45, an agent’s beliefs are completely determined by his be-\\nliefs about objective formulas (see, for example, [8] for a proof). Thus, we define a\\nmaximal set as follows:\\n\\nDefinition 2.1 If W is a set of worlds, let\\n\\nW+ = {w | for all objective formulas ϕ, if (W,w)|=Lϕ then (W,w)|=ϕ}.\\n\\nW is called maximal iff W = W+.\\n\\nLevesque defines validity and satisfiability with respect to maximal sets only. In\\nparticular, a formula α is valid iff for every maximal set of worlds W and every world\\nw ∈W , we have (W,w)|=α.\\n\\nWe end this review of Levesque’s logic by presenting (a slight variant of) his proof\\ntheory.\\n\\n3\\n\\n\\n\\nAxioms:\\n\\nA1. All instances of axioms of propositional logic.\\nA2. L(α⇒ β) ⇒ (Lα⇒ Lβ).\\nA3. N(α⇒ β) ⇒ (Nα ⇒ Nβ).\\nA4. σ ⇒ Lσ ∧Nσ for every subjective formula σ.\\nA5. Nα⇒ ¬Lα if ¬α is a propositionally consistent objective formula.\\n\\nInference Rules:\\n\\nMP. From α and α⇒ β infer β.\\nNec. From α infer Lα and Nα.\\n\\nAxioms A2–A4 tell us that that L and N separately have all the properties of K45-\\noperators. Actually, A4 tells us more; it says that L andN are mutually introspective,\\nso that, for example, Lϕ⇒ NLϕ is valid. Perhaps the most interesting axiom is A5,\\nwhich gives only-knowing its desired properties. Its soundness depends on the fact\\nthat the union of the set of worlds considered when evaluating L and the set of worlds\\nconsidered when evaluating N is the set of all conceivable worlds.4\\n\\nTheorem 2.2 [14] If Φ is infinite, then Levesque’s axiomatization is sound and com-\\nplete for the language ONL(Φ) with respect to Levesque’s semantics.\\n\\nAs we shall see, the assumption that there are infinitely many primitive proposi-\\ntions in Φ is crucial for Levesque’s completeness result. Extra axioms are required if\\nΦ is finite. In addition, it is interesting to note that the assumption that L and N are\\ninterpreted with respect to complementary sets of worlds is not forced by the axioms.\\nIn particular, for the soundness of Axiom A5, it suffices that the sets considered for\\nL and N cover all conceivable worlds; they may overlap. The following semantics\\nmakes this precise.\\n\\nDefine an extended situation to be a triple (WL,WN , w), where WL and WN are\\nsets of worlds (truth assignments) such that WL∪WN consists of all truth assignments.\\nDefine a new satisfaction relation |=x that is exactly like Levesque’s except for L- and\\nN -formulas. For them, we have\\n\\n(WL,WN , w) |=x Lα if (WL,WN , w\\n′) |=x α for all w′ ∈ WL\\n\\n(WL,WN , w) |=x Nα if (WL,WN , w\\n′) |=x α for all w′ ∈WN .\\n\\nNote that L and N are now treated in a completely symmetric way.\\n\\nTheorem 2.3 For all Φ, Levesque’s axiomatization is sound and complete for the\\nlanguage ONL(Φ) with respect to |=x.\\n\\nProof We omit the soundness proof, which is straightforward. Note that for axiom\\nA5 to be sound it suffices that WL and WN together cover all worlds. In particular,\\nit does not matter whether or not the two sets overlap.\\n\\nTo prove completeness, we use the notion of a maximal consistent set. Given an\\narbitrary axiom system AX , we say that a formula ϕ is consistent with respect to AX\\n\\n4Note that, while unusual, the axiom schema A5 is recursive, since consistency of formulas in\\nclassical propositional logic is decidable. Hence the axioms themselves are recursive. As noted in [14],\\nthis is a problem in the first-order case, however. In fact, Levesque’s proof theory for the first-order\\nversion of his logic was recently shown to be incomplete [7].\\n\\n4\\n\\n\\n\\nif it is not the case that AX ⊢ ¬ϕ, where, as usual, we use ⊢ to denote provability. A\\nfinite set of formulas ϕ1, . . . , ϕn is consistent with respect to AX if the conjunction\\nϕ1∧ . . .∧ϕn is consistent with respect to AX . An infinite set of formulas is consistent\\nwith respect to AX if every finite subset of its formulas is consistent with respect to\\nAX . Finally, given a set F of formulas, a maximal consistent subset of F is a subset\\nF ′ of F which is consistent with respect to AX such that any superset of F ′ is not\\nconsistent with respect to AX .\\n\\nIn the following, provability, consistency, and maximal consistency all refer to\\nLevesque’s axiom system unless stated otherwise. To prove completeness we show\\nthat every consistent formula is satisfiable with respect to |=x, using a standard\\ncanonical model construction [9, 10].\\n\\nLet Γ0 be the set of all maximal consistent sets of formulas in ONL(Φ). For\\nθ ∈ Γ0, define θ/L = {α | Lα ∈ θ} and θ/N = {α | Nα ∈ θ}. We then define\\n\\n• ΓθL = {θ′ ∈ Γ0 | θ/L ⊆ θ′},\\n\\n• ΓθN = {θ′ ∈ Γ0 | θ/N ⊆ θ′}.\\n\\nIf we view maximal consistent sets as worlds, then ΓθL and ΓθN represent the worlds\\naccessible from θ for L and N , respectively. The following lemma reflects the fact\\nthat L and N are both fully and mutually introspective (axiom A4).\\n\\n',\n",
       "                'Lemma 2.4 If θ′ ∈ ΓθL ∪ ΓθN , then Γθ\\n′\\n\\nL = ΓθL and Γθ\\n′\\n\\nN = ΓθN .\\n\\nProof We prove the lemma for θ′ ∈ ΓθL. The case θ′ ∈ ΓθN is completely symmetric.\\n\\nTo show that ΓθL = Γθ\\n′\\n\\nL , it clearly suffices to show that θ/L = θ′/L. Let α ∈ θ/L.\\nThen Lα ∈ θ and also LLα ∈ θ by axiom A4. Thus Lα ∈ θ′ (since θ′ ∈ ΓθL implies\\nthat θ/L ⊆ θ′) and, hence, α ∈ θ′/L.\\n\\nFor the converse, let α ∈ θ′/L. Thus, Lα ∈ θ′. Assume that α 6∈ θ/L. Then\\n¬Lα ∈ θ (since θ is a maximal consistent set) and, therefore, L¬Lα ∈ θ, from which\\n¬Lα ∈ θ′ follows, a contradiction.\\n\\nThe proof that Γθ\\n′\\n\\nN = ΓθN proceeds the same way, that is, we show that θ/N =\\nθ′/N . Let α ∈ θ/N . Then Nα ∈ θ and also LNα ∈ θ by axiom A4. Hence Nα ∈ θ′,\\nso α ∈ θ′/N .\\n\\nFor the converse, let α ∈ θ′/N . Thus, Nα ∈ θ′. Assume that α 6∈ θ/N . Then\\n¬Nα ∈ θ and also L¬Nα ∈ θ, from which ¬Nα ∈ θ′ follows, a contradiction.\\n\\nIn traditional completeness proofs using maximal consistent sets (see, for example,\\n[9, 10]), a situation is constructed whose worlds consists of all maximal consistent sets.\\nHere, we must be a little more careful.\\n\\nWe say that a maximal consistent set θ contains a truth assignment w if for all\\natomic formulas p, we havew |= p iff p ∈ θ. Clearly a maximal consistent set θ contains\\nexactly one world; we denote this world by wθ. For θ ∈ Γ0, let W θ\\n\\nL = {wθ′ | θ\\n′ ∈ ΓθL}\\n\\nand W θ\\nN = {wθ′ | θ′ ∈ ΓθN}.\\n\\nLemma 2.5 (a) (W θ\\nL,W\\n\\nθ\\nN , wθ) is an extended situation.\\n\\n(b) For all α, we have α ∈ θ iff (W θ\\nL,W\\n\\nθ\\nN , wθ) |=\\n\\nx α.\\n\\n5\\n\\n\\n\\nProof For part (a), to show that (W θ\\nL,W\\n\\nθ\\nN , wθ) is an extended situation, we must\\n\\nshow that W θ\\nL ∪ W θ\\n\\nN consists of all truth assignments. By way of contradiction,\\nsuppose there is a truth assignment w not in W θ\\n\\nL ∪W θ\\nN . Let Fw = {p ∈ Φ | w |=\\n\\np} ∪ {¬p | p ∈ Φ, w |= ¬p}. Fw ∪ θ/L cannot be consistent, for otherwise there\\nwould be some θ′ ∈ ΓθL that contains Fw , which would mean that w ∈ W θ\\n\\nL. Similarly\\nFw ∪ θ/N cannot be consistent. Thus, there must be formulas ϕ1, ϕ2, ϕ3, ϕ4 such\\nthat ϕ1 and ϕ2 are both conjunctions of a finite number of formulas in Fw , ϕ3 is\\nthe conjunction of a finite number of formulas in θ/L, and ϕ4 is the conjunction of\\na finite number of formulas in θ/N , and both ϕ1 ∧ ϕ3 and ϕ2 ∧ ϕ4 are inconsistent.\\nThus, we have ⊢ ϕ3 ⇒ ¬ϕ1 and ⊢ ϕ4 ⇒ ¬ϕ2. Using standard modal reasoning\\n(A2, A3, and Nec), we have ⊢ Lϕ3 ⇒ L¬ϕ1 and Nϕ4 ⇒ N¬ϕ2. Since Lψ ∈ θ for\\neach conjunct ψ of ϕ3, standard modal reasoning shows that Lϕ3 ∈ θ. Similarly, we\\nhave Nϕ4 ∈ θ. Since θ is a maximal consistent set, both L¬ϕ1 and N¬ϕ2 are in θ.\\nSince ⊢ L¬ϕ1 ⇒ L(¬ϕ1 ∨ ¬ϕ2) and ⊢ N¬ϕ2 ⇒ N(¬ϕ1 ∨ ¬ϕ2), it follows that both\\nL(¬ϕ1 ∨ ¬ϕ2) and N(¬ϕ1 ∨ ¬ϕ2) are in θ. But this contradicts A5, since ϕ1 ∧ ϕ2 is\\na propositionally consistent objective formula.\\n\\nFor part (b), the proof proceeds by induction on the structure of α. The statement\\nholds trivially for atomic propositions, conjunctions, and negations. In the case of\\nLα, we proceed by the following chain of equivalences:\\n\\nLα ∈ θ\\niff for all θ′ ∈ ΓθL, we have α ∈ θ′\\n\\niff for all θ′ ∈ ΓθL, we have (W θ′\\n\\nL ,W\\nθ′\\n\\nN , wθ′) |=\\nx α (using the induction hypothesis)\\n\\niff for all wθ′ ∈ W θ\\nL, we have (W θ\\n\\nL,W\\nθ\\nN , wθ′) |=\\n\\nx α (by Lemma 2.4)\\niff (W θ\\n\\nL,W\\nθ\\nN , wθ) |=\\n\\nx Lα.\\nThe case Nα is completely symmetric.\\n\\nThe completeness result now follows easily. Let α be a consistent formula and θ a\\nmaximal consistent set of formulas containing α. By Lemma 2.5, (W θ\\n\\nL,W\\nθ\\nN , wθ) |=\\n\\nx α.\\n\\nLevesque considered only maximal sets in his definition of validity. In fact, this\\nrestriction has no effect on the notion of validity.\\n\\nCorollary 2.6 A formula α ∈ ONL(Φ) is valid iff (W,w) |= α for all situations\\n(W,w) (including nonmaximal W ).\\n\\nProof If Φ is finite, it is easy to check that W+ = W for all sets W , so the result\\nis trivially true if Φ is finite. So suppose Φ is infinite. Notice that each situation\\n(W,w) corresponds to an extended situation (WL,WN , w), where WL = W and WN\\n\\nis the complement of W . Let us call such an (WL,WN , w) an extended complemen-\\ntary situation. Theorems 2.2 and 2.3 together imply the valid formulas obtained when\\nconsidering all extended situations remain the same when we restrict ourselves to com-\\nplementary situations with maximal WL. The corollary then follows from the fact\\nthat the set of all extended situations properly includes the set of all extended com-\\nplementary situations, which in turn includes the set of all extended complementary\\nsituations with maximal WL.\\n\\nAs Theorem 2.3 shows, for the |=x semantics, Levesque’s axioms are sound and\\ncomplete for all sets Φ of primitive propositions. On the other hand, as we said earlier,\\n\\n6\\n\\n\\n\\nLevesque’s completeness proof (with respect to his semantics) depends crucially on\\nthe fact that Φ is infinite. If Φ is finite, Levesque’s axioms are still sound with respect\\nto his semantics, but they are no longer complete. For example, if Φ = {p}, then\\n¬L¬p ⇒ N¬p would be valid under |=; ',\n",
       "                'this does not follow from the axioms given\\nabove. In fact, for each finite set Φ of primitive propositions, we can find a new axiom\\nscheme that, taken together with the previous axioms, gives a complete axiomatization\\nfor ONL(Φ) for Levesque’s semantics if Φ is finite.5 The new axiom, which subsumes\\naxiom A5, allows us to reduce formulas involving N formulas involving only L.\\n\\nNote that worlds, which are truth assignments to the primitive propositions Φ, are\\nthemselves finite if Φ is finite. Hence we can identify a world w with the conjunction\\nof all literals over Φ that are true at w. For example, if Φ = {p, q} and w makes p\\ntrue and q false, then we identify w with p ∧ ¬q. For any objective formula α, let\\nWα,Φ be the set of all worlds (over the primitive propositions Φ) that satisfy α. The\\naxiom system AXΦ is then obtained from Levesque’s system by replacing A5 by the\\nfollowing axiom:\\n\\nA5Φ. Nα ≡\\n∧\\nw∈W¬α,Φ\\n\\n¬L¬w if ¬α is a propositionally consistent objective formula.\\n\\nThe axiom is easily seen to be sound since it merely expresses that Nα holds at W\\njust in case W contains all worlds that satisfy ¬α. Note that this property depends\\nonly on the fact that L and N are defined with respect to complementary sets of\\nworlds and, hence, also holds in the case of infinite Φ. However, it is only in the\\nfinite case that we can express this axiomatically. Completeness is also very easy to\\nestablish. Levesque [14] showed that in his system, even without A5, every formula\\nis provably equivalent to one without nested modalities. With A5Φ, we then obtain\\nan equivalent formula that does not mention N . In other words, given a formula\\nconsistent with respect to AXΦ, a satisfying model can be constructed with the usual\\ntechnique for K45 alone.\\n\\nTheorem 2.7 AXΦ is sound and complete for the language ONL(Φ) with respect\\nto Levesque’s semantics, if Φ is finite.\\n\\n3 The Canonical-Model Approach\\n\\nHow do we extend our intuitions about only knowing to the multi-agent case? First we\\nextend the language ONL(Φ) to the case of many agents. That is, we now consider a\\nlanguage ONLn(Φ), which is just like ONL except that there are modalities Li and\\nNi for each agent i, 1 ≤ i ≤ n, for some fixed n. In the remainder of the paper, we\\nomit the Φ, just writing ONL and ONLn, since the set of primitive propositions does\\nnot play a significant role. By analogy with the single-agent case, we call a formula\\nbasic if it does not mention any of the operators Ni (i = 1, . . . , n) and i-subjective\\nif it is a Boolean combination of formulas of the form Liϕ and Niϕ. What should\\nbe the analogue of an objective formula? It clearly is more than just a propositional\\nformula. From agent 1’s point of view, a formula like L2p or even L2L1p is just as\\n“objective” as a propositional formula. We define a formula to be i-objective if it is\\na Boolean combination of primitive propositions and formulas of the form Ljϕ and\\n\\n5This was also the situation for the logic considered in [4]. In that paper, a simple axiomatization\\nwas provided for the case where Φ was infinite; for each finite Φ, an extra axiom was needed (that\\ndepended on Φ).\\n\\n7\\n\\n\\n\\nNjϕ, j 6= i, where ϕ is arbitrary. Thus, q∧N2L1p is 1-objective, but L1p and q∧L1p\\nare not. The i-objective formulas true at a world can be thought of as characterizing\\nwhat is true apart from agent i’s subjective knowledge of the world.\\n\\nThe standard model here is to have a Kripke structure with worlds and accessi-\\nbility relations that describe what worlds the agents consider possible in each world.\\nFormally, a (Kripke) structure or model is a tuple M = (W,π,K1, . . . ,Kn), where W\\nis a set of worlds,6 π associates with each world a truth assignment to the primitive\\npropositions, and Ki is agent i’s accessibility relation. Given such a Kripke structure\\nM , let KMi (w) = {w′ : (w,w′) ∈ Ki}.7 KMi (w) is the set of worlds that agent i\\nconsiders possible at w in structure M . As usual, we define\\n\\n(M,w) |= Liα if (M,w′) |= α for all w′ ∈ KMi (w).\\n\\nWe focus on structures where the accessibility relations are Euclidean and transitive,\\nwhere a relation R on W is Euclidean if (u, v) ∈ R and (u,w) ∈ R implies that\\n(v, w) ∈ R, and R is transitive if (u, v) ∈ R and (v, w) ∈ R implies that (u,w) ∈ R.\\nWe call such structures K45n-structures. It is well known [2, 9] that these assumptions\\nare precisely what is required to get belief to obey the K45 axioms (generalized to n\\nagents). We say that a formula consistent with these axioms is K45n-consistent. An\\ninfinite set of formulas is said to be K45n-consistent if the conjunction of the formulas\\nin every one of its finite subsets is K45n-consistent.\\n\\nNow the question is how to define the modal operator Ni. The problem in the\\nmulti-agent case is that we can no longer identify a possible world with a truth\\nassignment. In the single-agent case, knowing the set of truth assignments that the\\nagent considers possible completely determines his knowledge. This is no longer true\\nin the multi-agent case. ',\n",
       "                'Somehow we must take the accessibility relations into account.\\nA general semantics for an N -like operator was first given by Humberstone [11] and\\nlater by Ben-David and Gafni [1]. In this approach, the semantics of Ni is given as\\nfollows:\\n\\n(M,w) |= Niα if (M,w′) |= α for all w′ ∈W −KMi (w).\\n\\nThe problem with this definition is that it misses out on the intuition that when\\nevaluating Niα, we keep the set of worlds that agent i considers possible fixed. If\\nw′ ∈W −KMi (w), there is certainly no reason to believe that KMi (w) = KMi (w′).\\n\\nOne approach to solving this problem is as follows: If w and w′ are two worlds\\nin M , we write w ≈i w′ if KMi (w) = KMi (w′), i.e., if w and w′ agree on the possible\\nworlds according to agent i. We then define\\n\\n(M,w) |= Niα if (M,w′) |= α for all w′ such that w′ ∈W −KMi (w) and w ≈i w\\n′.\\n\\nWhile this definition does capture the first of Levesque’s properties, it does not\\ncapture the second. To see the problem, suppose we have only one agent and a\\nstructure M with only one possible world w. Suppose that (w,w) ∈ KM1 and p is\\ntrue at w. Then it is easy to see that (M,w) |= L1p ∧ N1p, contradicting axiom\\nA5. The problem is that since the structure has only one world and it is in KM1 (w),\\n\\n6Note that here W denotes the set of all worlds of the particular model M , not just the (epis-\\ntemically) possible ones as in Levesque’s logic.\\n\\n7We use the superscript M since we shall later need to talk about the Ki relations in more than\\none model at the same time.\\n\\n8\\n\\n\\n\\nthere are no worlds in W − KM1 (w). Thus, N1p is vacuously true. Intuitively, there\\njust aren’t enough “impossible” worlds in this case; the set of conceivable worlds is\\nnot independent of the model. To deal with this problem, we focus attention on one\\nparticular model, the canonical model, which intuitively has “enough” worlds. Its\\nworlds consist of all the maximal consistent subsets of basic formulas. (Recall that\\nmaximal consistent sets were defined in the proof of Theorem 2.3.) Thus, in some\\nsense, the canonical model has as many worlds as possible.\\n\\nDefinition 3.1 The canonical model (for K45n) M c = (W c, πc,Kc1, . . . ,K\\nc\\nn) is de-\\n\\nfined as follows:\\n\\n• W c = {w | w is a maximal consistent set of basic formulas with respect to K45n},\\n\\n• for all primitive propositions p and w ∈ W c, π(w)(p) = true iff p ∈ w,\\n\\n• (w,w′) ∈ Kci iff w/Li ⊆ w′, where w/Li = {α | Liα ∈ w}.\\n\\nValidity in the canonical-model approach is defined with respect to the canonical\\nmodel only. More precisely, a formula α is said to be valid in the canonical-model\\napproach, denoted |=c α, iff M c|=α, that is, if for all worlds w in the canonical model\\nwe have (M c, w)|=α.\\n\\nWe clearly cannot use the canonical model in a practical way. It can be shown\\nthat it has uncountably many worlds. Each of its worlds is characterized by an infinite\\nset of formulas, so cannot be described easily. Moreover, in general, both Kci (w) and\\nW c −Kci (w) are infinite, so we cannot compute whether Liϕ or Niϕ holds at a given\\nworld. Thus, our interest in the canonical model is mainly to understand whether it\\ngives reasonable semantics to the Ni operator.\\n\\nWe start by arguing that, for an appropriate notion of “possibility” and “conceiv-\\nability”, this semantics satisfies the first two of Levesque’s properties. What then is\\na conceivable world? Intuitively, it is an objective state of affairs from agent i’s point\\nof view, which does not include i’s beliefs. In the single-agent case, this is simply a\\ntruth assignment. In the multi-agent case, things are more complicated, since beliefs\\nof other agents are also part of i’s objective world. One way of characterizing a state\\nof affairs from i’s point of view is by the set of i-objective formulas that are true at\\na particular world. For technical reasons, in this section we restrict even further to\\nthe i-objective basic formulas—that is, those formulas that do not mention any of the\\nmodal operators Nj, j = 1, . . . , n—that are true. If we assume that the basic formulas\\ndetermine all the other formulas, which can be shown to be true in the single-agent\\ncase, and under this semantics for the multi-agent case, then it is arguably reasonable\\nto restrict to basic formulas. However, as we shall see in Section 4, it is not clear that\\nthis restriction is appropriate, although we make it for now.\\n\\nDefinition 3.2 Given a situation (M,w), let obji(M,w) consist of all the i-objective\\nbasic formulas that are true at (M,w). let Obji(M,w) = {obji(M,w′) | w′ ∈ KMi (w)},\\nand let subji(M,w) = {basic Liα | (M,w)|=Liα} ∪ {basic ¬Liα | (M,w)|6=Liα}.\\n\\nWe take obji(M,w) to be i’s state at (M,w). Notice that obji(M,w) is a maximal\\nconsistent set of i-objective basic formulas. For ease of exposition, we say i-set from\\nnow on rather than “maximal set of i-objective basic formulas”. Thus, the set of\\n\\n9\\n\\n\\n\\nconceivable states for agent i is the set of all i-sets. Notice that the set of conceivable\\nstates is independent of the model. ',\n",
       "                'It is easy to show that this is a generalization of\\nthe single-agent case, since in the single-agent case the i-objective basic formulas are\\njust the propositional formulas, and an i-set can be identified with a truth assignment.\\n\\nObji(M,w) is the set of i-sets that agent i considers possible in situation (M,w);\\nsubji(M,w) characterizes i’s basic beliefs in (M,w). Notice that if α is an i-objective\\nbasic formula, then Liα ∈ subji(M,w) iff α is in every i-set in Obji(M,w).\\n\\nWith these definitions, we can show that the first two of Levesque’s properties\\nhold in the canonical model. The first property says that at all worlds w′ considered\\nin evaluating a formula of the form Niϕ at a world w, the set of possible states—that\\nis, the set {obji(M\\n\\nc, w′′) | w′′ /∈ Kci (w\\n′)}—is the same for all w′ ∈ Kci (w). This is easy\\n\\nto see, since the only worlds w′ we consider are those such that Kci (w\\n′) = Kci (w). The\\n\\nsecond property says that the union of the set of states associated with the worlds\\nused in computing Liϕ at w and the set of states associated with the worlds used in\\ncomputing Niϕ at w should consist of all conceivable states. To show this, we must\\nshow that for every world w in the canonical model, the set {obji(M\\n\\nc, w′) | w′ ≈i w}\\nconsists of all i-sets.\\n\\nTo prove this, we need two preliminary lemmas.\\n\\nLemma 3.3 Let w and w′ be worlds in M c. Then w ≈i w′ iff agent i has the same\\nbasic beliefs at w and w′, that is, subji(M\\n\\nc, w) = subji(M\\nc, w′).\\n\\nProof The “only if” direction is immediate because w and w′ are assumed to have\\nthe same Ki-accessible worlds. To prove the “if” direction, suppose that subji(M\\n\\nc, w) =\\nsubji(M\\n\\nc, w′) but w 6≈i w′. Without loss of generality, there is a world w∗ ∈\\nKci (w) − Kci (w\\n\\n′). By the definition of the canonical model, there must be a basic\\nformula Liα ∈ w′ such that α 6∈ w∗. By assumption, Liα ∈ w, contradicting the\\nassumption that w∗ ∈ Kci (w).\\n\\nLemma 3.4 Suppose Γ consists only of i-objective basic formulas, Σ consists only\\nof i-subjective basic formulas, and Γ and Σ are both K45n-consistent. Then Γ ∪ Σ is\\nK45n-consistent.\\n\\nProof This follows immediately from part (c) of Proposition 4.2 below.\\n\\nWe can now prove that the set of conceivable states for agent i is the same at all\\nworlds of the canonical model. This follows from the following result.\\n\\nTheorem 3.5 Let w ∈ W c. Then for every i-set Γ there is exactly one world w∗\\n\\nsuch that obji(M\\nc, w∗) = Γ and w ≈i w∗.\\n\\nProof Let Σ = subji(M\\nc, w). Since Γ consists of i-objective basic formulas only, Σ\\n\\nconsists of i-subjective formulas, and Γ and Σ are both K45n-consistent, by Lemma 3.4,\\nΓ ∪ Σ is K45n-consistent. Let w∗ be a maximal consistent set that contains Γ ∪ Σ.\\nSince w and w∗ agree on Σ, w ≈i w∗ by Lemma 3.3. The uniqueness of w∗ follows\\nby a simple induction argument.\\n\\n10\\n\\n\\n\\nWhat about the third property? This says that every subset of i-sets arises as the\\nset of i-sets associated with the worlds that i considers possible in some situation;\\nthat is, for every set S of i-sets, there should be some situation (M c, w) such that S =\\nObji(M\\n\\nc, w). As we now show, this property does not hold in the canonical model.\\nWe do this by showing that the set of i-sets associated with the worlds considered\\npossible in any situation in the canonical model all have a particular property we call\\nlimit closure.8\\n\\nDefinition 3.6 We say that an i-set Γ is a limit of a set S of i-sets if, for every finite\\nsubset ∆ of Γ, there is a set Γ′ ∈ S such that ∆ ⊂ Γ′. A set S of i-sets is limit closed\\nif every limit of S is in S.\\n\\nLemma 3.7 For every world w in M c, the set Obji(M\\nc, w) is limit closed.\\n\\nProof Let w be a world in the canonical model and let Γ be an i-set which is a limit\\nof Obji(M\\n\\nc, w). We want to show that Γ ∈ Obji(M\\nc, w). Let Σ = {basic β | Liβ ∈ w}.\\n\\nWe claim that Γ∪Σ is K45n-consistent. For suppose not. Then there must be a finite\\nsubset ∆ ⊆ Γ such that ∆∪Σ is inconsistent. Since Γ is a limit of Obji(M\\n\\nc, w), there\\nmust be some world w′ in Obji(M\\n\\nc, w) such that (M c, w′) |= ∆. By construction of\\nthe canonical model, since w′ ∈ Kci (w), we must have that (M c, w′) |= Σ. Thus ∆∪Σ\\nis consistent, contradicting our assumption.\\n\\nSince Γ ∪ Σ is consistent, there is a world w∗ in the canonical model such that\\n(M c, w∗) |= Γ ∪ Σ. Clearly Γ = obji(M\\n\\nc, w∗). Moreover, by construction, we must\\nhave w∗ ∈ Kci (w). Thus, Γ ∈ Obji(M\\n\\nc, w), as desired.\\n\\nSince there are clearly sets of i-sets that are not limit closed, it follows that this\\nsemantics does not satisfy the third property. One consequence of this is a result\\nalready proved in [12], which we reprove here, using an approach that will be useful\\nfor later results.\\n\\nProposition 3.8 [12] If p ∈ Φ and i 6= j, then |=c ¬Oi¬Ojp.\\n\\nProof We proceed by contradiction. Our goal is to show that if (M c, w) |= Oi¬Ojp,\\nthen the set Obji(M\\n\\nc, w) must contain a set that includes Ojp, for otherwise it would\\nnot be limit closed. ',\n",
       "                'It follows that there is some world v ∈ Kci (w) such that (M c, v) |=\\nOjp, contradicting the assumption that (M c, w) |= Li¬Ojp.\\n\\nWe first need a definition and a lemma. We say that a basic formula ψ is (K45)-\\nindependent of a basic formula ϕ if neither ⊢K45n\\n\\nϕ⇒ ψ nor ⊢K45n\\nϕ⇒ ¬ψ hold.\\n\\nLemma 3.9 If n ≥ 2 (i.e., there are at least two agents) and ϕ1, . . . , ϕm are consistent\\nbasic i-objective formulas, then there exists a basic i-objective formula ψ of the form\\nLjψ\\n\\n′ which is independent of each of ϕ1, . . . , ϕm.\\n\\nProof Define the depth of a basic formula ϕ, denoted d(ϕ), inductively:\\n\\n8This turns out to be closely related to the limit closure property discussed in [3]; a detailed\\ncomparison would take us too far afield here though.\\n\\n11\\n\\n\\n\\n• d(p) = 0 for a primitive proposition p,\\n\\n• d(ϕ ∧ ψ) = max(d(ϕ), d(ψ)),\\n\\n• d(¬ϕ) = d(ϕ),\\n\\n• d(Liϕ) = 1 + d(ϕ).\\n\\nSuppose that ϕ1, . . . , ϕm are i-objective formulas such that max(d(ϕ1(, . . . , d(ϕk)) =\\nK. Let p be an arbitrary primitive proposition, and suppose j 6= i. (Such a j exists,\\nsince we are assuming n ≥ 2.) Let ψ be the formula (LjLi)\\n\\nK+1p, where by (LjLi)\\nK+1\\n\\nwe mean K + 1 occurrences of LjLi. Standard model theoretic arguments show that\\nψ is independent of ϕ1, . . . , ϕm. Very briefly: By results of [9], we know that ϕi is\\nsatisfiable in a treelike structure of depth at most d(ϕi), for i = 1, . . . ,m. It is easy\\nto see that this can be extended to two structures, one of which satisfies ψ, and the\\nother of which satisfies ¬ψ. Hence, ψ is independent of ϕi.\\n\\nContinuing with the proof of Proposition 3.8, suppose by way of contradiction\\nthat (M c, w) |= Oi¬Ojp. Let w be a world such that (M c, w)|=Ojp and let Γ =\\nobji(M\\n\\nc, w). We claim that Γ is a limit of Obji(M\\nc, w). To see this, consider any\\n\\nfinite subset ∆ of Γ. Let ψ be an i-objective basic formula of the form Ljψ\\n′ which\\n\\nis independent both of the conjunction of the formulas in ∆ and of p. The existence\\nof such a formula follows from Lemma 3.9. Let Σ = subji(M\\n\\nc, w). By Lemma 3.4,\\nΣ∪∆∪{Ljψ′} is consistent. Thus, there is some world w′ ∈W c such that (M c, w′) |=\\nΣ ∪ ∆ ∪ {Ljψ′}. By Lemma 3.4 again, there is some world w′′ satisfying p ∧ ¬Ljψ′\\n\\nsuch that w′′ ≈i w′. Since (M c, w′) |= Ljψ\\n′, we cannot have w′′ ∈ Kcj(w\\n\\n′). It follows\\nthat (M c, w′) |= ¬Nj¬p, and hence (M c, w′) |= ¬Ojp. Moreover, since w′ and w\\nagree on all i-subjective formulas, the canonical model construction guarantees that\\nw′ ≈i w. Since (M c, w) |= Oi¬Ojp , (M c, w′) |= ¬Ojp, and w′ ≈i w, we must have\\nthat w′ ∈ Kci (w). Thus, obji(M\\n\\nc, w′) ∈ Obji(M\\nc, w). Moreover, by construction,\\n\\n∆ ⊆ obji(M\\nc, w′). Since ∆ was chosen arbitrarily, it follows that Γ is a limit of\\n\\nObji(M\\nc, w). By Lemma 3.7, Γ ∈ Obji(M\\n\\nc, w). Thus, there is some world v ∈ Kci (w)\\nsuch that obji(M\\n\\nc, v) = Γ. It is a simple property of the canonical-model approach\\nthat two worlds that agree on all basic beliefs of an agent also agree on what the\\nagent only believes. Hence, since w and v agree on j’s basic beliefs, it follows that\\n(M c, v)|=Ojp, contradicting the assumption that (M c, w)|=Oi¬Ojp.\\n\\nIt may seem unreasonable that ¬Oi¬Ojp should be valid in the canonical-model\\napproach. Why should it be impossible for i to know only that j does not only know\\np? After all, j can (truthfully) tell i that it is not the case that all he (j) knows is p.\\nWe return to this issue in Sections 4 and 5. For now, we focus on a proof theory for\\nthis semantics.\\n\\n3.1 A Proof Theory\\n\\nWe now consider an axiomatization for the language. The following axiomatization is\\nexactly like Levesque’s except that axiom A5 now requires K45n-consistency instead\\nof merely propositional consistency. For ease of exposition, we use the same names\\nfor the axioms as we did in the single-agent case with a subscript n to emphasize that\\nwe are looking at the multi-agent version.\\n\\n12\\n\\n\\n\\nAxioms:\\n\\nA1n. Axioms of propositional logic.\\nA2n. Li(α⇒ β) ⇒ (Liα⇒ Liβ).\\nA3n. Ni(α⇒ β) ⇒ (Niα⇒ Niβ).\\nA4n. σ ⇒ Liσ ∧Niσ if σ is an i-subjective formula.\\nA5n. Niα⇒ ¬Liα if ¬α is a K45n-consistent i-objective basic formula.\\n\\nInference Rules:\\n\\nMPn. From α and α⇒ β infer β.\\nNecn. From α infer Liα and Niα.\\n\\nNotice that A5n assumes that α ranges only over basic i-objective formulas. We need\\nthis restriction in order to appeal to satisfiability in the existing logic K45n.9 To get\\na more general version of A5n, that applies to arbitrary formulas, we will need to\\nappeal to consistency within the logic that the axioms are meant to characterize. We\\nreturn to this issue in Section 5. It is not hard to show that these axioms are sound.\\n\\nTheorem 3.10 [12] For all α in ONLn, if ⊢α then |=c α.\\n\\nProof The proof proceeds by the usual induction on the length of a derivation. Here\\nwe show only the soundness of A5n. Suppose α is a basic i-objective formula such\\nthat ¬α is K45n-consistent. Thus, there is an i-set containing ¬α. By Theorem 3.5, it\\nfollows that for each world w ∈W c, there is a world w′ ≈i w such that (M c, w′) |= ¬α.\\n',\n",
       "                'If w′ ∈ Kci (w), it follows that (M c, w) |= ¬Liα. If w′ /∈ Kci (w), then (M c, w) |= ¬Niα.\\nThus, (M c, w) |= ¬Liα∨¬Niα; equivalently, (M c, w) |= Niα⇒ ¬Liα. It follows that\\n|= Niα⇒ ¬Liα.\\n\\nWe show in Section 4 that this axiomatization is incomplete. In fact, the formula\\n¬Oi¬Ojp is not provable. Intuitively, part of the problem here is that A5n is restricted\\nto basic formulas. For completeness, we would need an analogue of A5n for arbitrary\\nformulas. However, we obtain completeness for a restricted language, which we call\\nONL−\\n\\nn . Roughly, the restriction amounts to limiting what an agent can only know.\\nIn particular, only knowing can only be applied to basic formulas.\\n\\nDefinition 3.11 ONL−\\n\\nn consists of all formulas α in ONLn such that, in α, no Nj\\nmay occur within the scope of an Ni or Li for i 6= j.\\n\\nFor example, NiLi¬Nip and Ni(Ljp∨Ni¬p) are in ONL−\\n\\nn , and NiNjp and NiLjNip\\nare not, for distinct i and j. Note that formulas such as Oi¬Ojp cannot be expressed\\nin ONL−\\n\\nn .\\nTo prove completeness for the sublanguage ONL−\\n\\nn , we need four preliminary\\nlemmas. The first describes a normal form for formulas. Having such a normal form\\ngreatly simplifies the completeness proof.\\n\\n9Note that this peculiar axiom schema is recursive since satisfiability in propositional K45n is\\ndecidable [9].\\n\\n13\\n\\n\\n\\nLemma 3.12 Every formula α in ONLn is provably equivalent to a disjunction of\\nformulas of the following form:\\n\\nσ ∧ L1ϕ10 ∧ ¬L1ϕ11 ∧ . . . ∧ ¬L1ϕ1m1\\n∧ . . . ∧ Lnϕn0 ∧ ¬Lnϕn1 ∧ . . . ∧ ¬Lnϕnmn\\n\\n∧\\nN1ψ10 ∧ ¬N1ψ11 ∧ . . . ∧ ¬N1ψ1k1 ∧ . . . ∧Nnψn0 ∧ ¬Nnψn1 ∧ . . . ∧ ¬Nnψnkn\\n\\n,\\n\\nwhere σ is a propositional formula and ϕij and ψij are all i-objective formulas. More-\\nover, if α in ONL−\\n\\nn , we can assume that ϕij and ψij are i-objective basic formulas.\\n\\nProof We proceed by induction on the structure of ϕ. The only nontrivial cases are\\nif ϕ is of the form Liϕ\\n\\n′ or Niϕ\\n′. If ϕ is of the form Liϕ\\n\\n′, then, since ϕ ∈ ONL−\\n\\nn , Nj\\ndoes not appear in ϕ′ for j 6= i. We use the inductive hypothesis to get ϕ′ into the\\nnormal form described in the lemma. Notice that Nj does not appear in the normal\\nform for j 6= i. We now use the the following equivalences to get Liϕ\\n\\n′ into the normal\\nform:\\n\\n• Li(ψ ∧ ψ′) ⇔ (Liψ ∧ Liψ′)\\n\\n• Li(ψ ∨ Liψ′) ⇔ (Liψ ∨ Liψ′)\\n\\n• Li(ψ ∨ ¬Liψ′) ⇔ (Liψ ∨ ¬Liψ′)\\n\\n• LiLiψ ⇔ Liψ\\n\\n• (¬Lifalse ∧ Li¬Liψ) ⇔ ¬Liψ\\n\\n• LiNiψ ⇔ Niψ\\n\\n• Li¬Niψ ⇔ ¬Niψ.\\n\\nThe first five of these equivalences are standard K45n properties; the last two are\\ninstances of axiom A4n. Similar arguments work in the case that ϕ is of the form\\nNiϕ\\n\\n′. We leave the straightforward details to the reader.\\n\\nThe next two lemmas give us some basic facts about the satisfiability and validity\\nof formulas in ONL−\\n\\nn .\\n\\nLemma 3.13 If Sj is a set of consistent j-sets, j = 1, . . . , n, and σ is a consistent\\npropositional formula, then there is a K45n situation (M,w) such that (M,w) |= σ\\nand Objj(M,w) = Sj.\\n\\nProof This follows immediately from part (b) of Proposition 4.2 below.\\n\\nLemma 3.14 If ϕ and ψ are i-objective basic formulas such that Liϕ ∧Niψ is con-\\nsistent, then ϕ ∨ ψ is valid.\\n\\nProof Suppose that ¬ϕ ∧ ¬ψ is consistent. Then, by Axiom A5n, Ni(ϕ ∨ ψ) ⇒\\n¬Li(ϕ ∨ ψ) is provable. It follows that Niψ ⇒ ¬Liϕ is provable, contradicting the\\nconsistency of Liϕ ∧Niψ.\\n\\n14\\n\\n\\n\\nThe last lemma gives us a sharper condition on when w′ /∈ Kci (w). This condition\\nwill prove useful in the completeness proof.\\n\\nLemma 3.15 If w,w′ are worlds in the canonical model such that w ≈i w′ and\\nw′ /∈ Kci (w), then there is an i-objective basic formula ϕ such that Liϕ ∈ w and\\nϕ /∈ w′.\\n\\nProof By the construction of the canonical model, we know that if w′ /∈ Kci (w),\\nthen there is some basic formula ϕ such that Liϕ ∈ w and ϕ /∈ w′. From Lemma 3.12,\\nit follows that we can assume without loss of generality that ϕ is in the normal\\nform described by that lemma. Let A consist of all subformulas of ϕ that are of\\nthe form Liψ and do not appear in the scope of any other modal operator. Let\\nϕA be\\n\\n∧\\nψ∈A∩w ψ ∧\\n\\n∧\\nψ∈A−w ¬ψ. It is easy to see that ϕA ∈ w (since each of its\\n\\nconjuncts is). Since w ≈i w′, it follows that ϕA ∈ w′. Let ϕ′ be the result of replacing\\neach subformula Liψ of ϕ that is in A by either true or false, depending on whether\\nLiψ ∈ w. By construction, ϕ′ is i-objective. It is easy to see that ϕA ⇒ (ϕ ⇔ ϕ′)\\nis provable. It follows that ϕ′ /∈ w′. It also follows that LiϕA ⇒ (Liϕ ⇔ Liϕ\\n\\n′)\\nis provable. Since ϕA is an i-subjective formula, ϕA ⇒ LiϕA is provable. Hence,\\nLiϕA ∈ w. Since Liϕ ∈ w, it follows that Liϕ\\n\\n′ ∈ w. This gives us the desired result.\\n\\nWe are finally ready to prove the completeness result.\\n\\nTheorem 3.16 [12] For all α ∈ ONL−\\n\\nn , if |=c α then ⊢α.\\n\\nProof As usual, it suffices to show that if the formula α ∈ ONL−\\n\\nn is consistent, then\\nit is satisfiable in the canonical model. Without loss of generality, we can assume\\nthat α is in the normal form described in Lemma 3.12:\\n\\nσ ∧ L1ϕ10 ∧ ¬L1ϕ11 ∧ . . . ∧ ¬L1ϕ1m1\\n∧ . . . ∧ Lnϕn0 ∧ ¬Lnϕn1 ∧ . . . ∧ ¬Lnϕnmn\\n\\n∧\\n',\n",
       "                'N1ψ10 ∧ ¬N1ψ11 ∧ . . . ∧ ¬N1ψ1k1 ∧ . . . ∧Nnψn0 ∧ ¬Nnψn1 ∧ . . . ∧ ¬Nnψnkn\\n\\n.\\n\\nMoreover, since α ∈ ONL−\\n\\nn , we can assume that ϕij and ψij are i-objective basic\\nformulas. Let Ai consist of all the consistent formulas of the form ϕi0 ∧ψi0 ∧¬ϕij or\\nϕi0 ∧ ψi0 ∧ ¬ψij , j ≥ 1. Let ξi be a formula that is independent of all the formulas\\nin Ai; such a formula exists by Lemma 3.9. Let Si consist of all i-sets containing\\nϕi0 ∧ (¬ψi0 ∨ (ψi0 ∧ ξi)). By Lemma 3.13, there is a K45n structure (M,w) such\\nthat Obji(M,w) = Si, i = 1, . . . , n, and (M,w) |= σ. Thus, there must be a world\\nw∗ in the canonical model such that w∗ = {basic ϕ′ | (M,w) |= ϕ′}. We claim that\\n(M c, w∗) |= α.\\n\\nTo see this, let α′ be the formula σ∧L1ϕ10∧¬L1ϕ11∧. . .∧¬L1ϕ1m1\\n∧. . .∧Lnϕn0∧\\n\\n¬Lnϕn1 ∧ . . .∧¬Lnϕnmn\\n. We first show that (M,w) |= α′. By construction, we have\\n\\nthat (M,w) |= σ. Furthermore, by definition, each world w′ ∈ KMi (w) satisfies ϕi0,\\nso we have that (M,w) |= Liϕi0. Since Liϕi0 ∧ ¬Liϕij is consistent for each j ≥ 1,\\nit must be the case that ϕi0 ∧ ¬ϕij is consistent. Thus, one of ϕi0 ∧ ¬ψi0 ∧ ¬ϕij\\nor ϕi0 ∧ ψi0 ∧ ¬ϕij is consistent. If the latter is consistent, then by the choice of ξ,\\nϕi0∧ψi0∧ξi∧¬ϕij must be consistent as well. Since Si consists of all i-sets containing\\nϕi0 ∧ (¬ψi0 ∨ (ψi0 ∧ ξi)), it follows that there must be an i-set in Si containing ¬ϕij .\\n\\n15\\n\\n\\n\\nIt follows that (M,w) |= ¬Liϕij , for j ≥ 1. Thus, we have shown that (M,w) |= α′.\\nSince (M,w) and (M c, w∗) agree on basic formulas, it follows that (M c, w∗) |= α′.\\n\\nNext, we show that (M c, w∗) |= N1ψ10 ∧ . . . ∧ Nnψn0. To this end, suppose\\nthat w′ ≈i w∗ and w′ /∈ Kci (w\\n\\n∗). By Lemma 3.15, there must be some i-objective\\nbasic formula ϕ′ such that Liϕ\\n\\n′ ∈ w∗ and ¬ϕ′ ∈ w′. Since Liϕ\\n′ ∈ w∗, it follows that\\n\\n(M,w) |= Liϕ\\n′, and hence ϕ′ is in every i-set in Si. It follows that obji(w\\n\\n′) /∈ Si. Now,\\none of the following four formulas must be in obji(w\\n\\n′): (1) ϕi0 ∧ ψi0, (2) ϕi0 ∧ ¬ψi0,\\n(3) ¬ϕi0 ∧ ψi0, (4) ¬ϕi0 ∧ ¬ψi0. Since Liϕi0 ∧Niψi0 is consistent, it cannot be (4),\\nby Lemma 3.14. It cannot be (2), for otherwise w′ would be in Si. Thus, it must\\nbe (1) or (3), so ψi0 ∈ obji(w\\n\\n′). Since this is true for all w′ such that w′ ≈i w∗ and\\nw′ /∈ Kci (w\\n\\n∗), it follows that (M c, w∗) |= Niψi0, for i = 1, . . . , n.\\nFinally, we must show that (M∗, w∗) |= ¬N1ψij , for i = 1, . . . , n and j = 1, . . . , ki.\\n\\nClearly ψi0 ∧ ¬ψij is consistent, for otherwise Niψi0 ∧ ¬Niψij would be inconsistent.\\nThus, at least one of (1) ψi0 ∧ ¬ψij ∧ ¬ϕi0 or (2) ψi0 ∧ ¬ψij ∧ ϕi0 is consistent. In\\ncase (2), by choice of ξi, the formula ψi0 ∧ ¬ψij ∧ ϕi0 ∧ ¬ξi is consistent. Let β\\nbe ψi0 ∧ ¬ψij ∧ ¬ϕi0 if it is consistent, and ψi0 ∧ ¬ψij ∧ ϕi0 ∧ ¬ξi otherwise. By\\nconstruction, β is consistent. By Lemma 3.4, there is a situation (M ′, v) such that\\nsubji(M\\n\\n′, v) = subji(M\\n∗, w∗) and (M ′, v) |= β. There is a world w′′ in the canonical\\n\\nmodel which agrees with (M ′, v) on the basic formulas. By construction, we have\\nw′′ ≈i w∗. Moreover, since (M c, w) |= Li(ϕi0 ∧ (¬ψi0 ∨ (ψi0 ∧ ξ))), it follows that\\n(M c, w∗) |= Li¬β. Since (M c, w′) |= β, we have that w′ /∈ Kci (w\\n\\n∗). Moreover, since\\n(M c, w′) |= ¬ψij , it follows that (M c, w∗) |= ¬Niψij , as desired. This completes the\\nproof.\\n\\n3.2 Discussion\\n\\nAs we have shown, the canonical-model semantics for Ni has some attractive features,\\nin particular when restricted to the language ONL−\\n\\nn . It is for this sublanguage that\\nwe have a nice proof-theoretic characterization. There is some evidence, however, that\\nthe semantics may not have the behavior we desire when we move beyond ONL−\\n\\nn . For\\none thing, the formula ¬Oi¬Ojp is valid in the canonical model: it is impossible that\\nall i knows is that it is not the case that all j knows is p. While it is certainly consistent\\nfor ¬Oi¬Ojp to hold, it seems reasonable to have a semantics that allowsOi¬Ojp to be\\nhold as well. As we have seen, the validity of ¬Oi¬Ojp follows from the fact that the\\ncanonical-model semantics does not have the third property of Levesque’s semantics\\nin the single-agent case: not all subsets of conceivable states are possible. In the\\nnext section, we discuss a different approach to giving semantics to only knowing—\\nessentially that taken in [5]—that has all three of Levesque’s properties, at least\\nas long as we continue to represent an agent’s objective state of affairs using basic\\nformulas only. The approach agrees with the canonical-model approach on formulas\\nin ONL−\\n\\nn , but makes Oi¬Ojp satisfiable. Unfortunately, as we shall see, it too suffers\\nfrom problems.\\n\\n4 The i-Set Approach\\n\\nIn the i-set approach, we maintain the intuition that the set of conceivable states for\\neach agent i can be identified with the set of i-sets. We no longer restrict attention\\n\\n16\\n\\n\\n\\nto the canonical model though; we consider all Kripke structures.\\nWe define a new semantics |=′ as follows: all the clauses of |=′ are identical to the\\n\\ncorresponding clauses for |=, except that for Ni. In this case, we have\\n\\n',\n",
       "                '(M,w) |=′ Niϕ iff (M ′, w′) |=′ ϕ for all situations (M ′, w′) such that\\nObji(M,w) = Obji(M\\n\\n′, w′) and obji(M\\n′, w′) /∈ Obji(M,w).\\n\\nNotice that |= and |=′ agree for basic formulas; in general, as we shall see, they differ.\\nWe remark that this definition is equivalent to the one given in [5], except that there,\\nrather than i-sets, i-objective trees were considered. We did not want to go through\\nthe overhead of introducing i-objective trees here, since it follows from results in\\n[5, 6] that i-sets are equivalent to i-objective trees: every i-set uniquely determines\\nan i-objective tree and vice versa.\\n\\nHow well does this approach fare in terms of computing the truth of a formula at a\\ngiven world. Since we now allow arbitrary structures, not just the canonical model, it\\nseems that for computational reasons, it seems we ought to focus on finite structures.\\nHowever, when it comes to formulas of the form Niα, where α is i-objective, satisfiable\\nformula, it can be shown that (M,w) |=′ ¬Niα. There are simply too few sets in\\nObji(M,w) if M is finite to have ¬α hold in all “impossible” situations. This means\\nthat to really model interesting situations with only knowing, we must use infinite\\nmodels, and we are back to the problems discussed in the case of the canonical model.\\nThus, again we focus on whether this approach gives reasonable semantics to the Ni\\noperator.\\n\\nNotice that to decide if Niϕ holds in (M,w), we consider all situations that agree\\nwith (M,w) on the set of possible states, hence this semantics satisfies the first of\\nthe three properties we isolated in the single-agent case. It is also clear that the\\ni-sets considered in evaluating the truth of Niϕ are precisely those not considered in\\nevaluating the truth of Liϕ; hence we satisfy the second property. Finally, as we now\\nshow, for every set S of i-sets, there is a situation (M,w) such that Obji(M,w) = S.\\nIn fact, we prove an even stronger result.\\n\\nDefinition 4.1 Let ob\\uf6be+i (M,w) consist of all i-objective formulas (not necessarily\\njust i-objective basic formulas) true at (M,w) (with respect to |=′) and let Ob\\uf6be+i (M,w)\\n= {ob\\uf6be+i (M,w′) | w′ ∈ KMi (w)}.\\n\\nProposition 4.2 Let Γ be a satisfiable set of i-objective formulas, let Si be a set of\\nmaximal satisfiable sets of i-objective formulas, i = 1, . . . , n, let Σ be a satisfiable set\\nof i-subjective formulas, and let σ be a satisfiable propositional formula. Then\\n\\n(a) there exists a situation (M1, w1) such that Γ ⊆ ob\\uf6be+i (M1, w1) and Si = Ob\\uf6be+i (M1, w1).\\n\\n(b) there exists a situation (M2, w2) such that (M2, w2) |= σ and Ob\\uf6be+j (M2, w2) =\\nSj, j = 1, . . . , n.\\n\\n(c) there exists a situation (M3, w3) such that (M3, w3) |= Γ ∧ Σ.\\n\\nProof For part (a), we first show that, given an arbitrary situation (M,w), we can\\nconstruct a situation (M∗, w∗) such that ob\\uf6be+i (M∗, w∗) = ob\\uf6be+i (M,w) and there are\\n\\n17\\n\\n\\n\\nno worlds i-accessible from w∗. The idea is to have M∗ be the result of adding w∗\\n\\nto the worlds in M , where w∗ is just like w except that it has no i-accessible worlds\\nand w∗ is not accessible from any world. More formally, if M = (W,π,K1, . . . ,Kn),\\nwe take M∗ = (W ∗, π∗,K∗\\n\\n1, . . . ,K\\n∗\\n\\nn), where W ∗ = W ∪ {w∗}, π∗(w′) = π(w′) for\\nw′ ∈ W , π∗(w∗) = π(w), K∗\\n\\nj = Kj ∪ {(w∗, w′) | w′ ∈ Kj(w)} for j 6= i, and K∗\\n\\ni = Ki.\\nIt is easy to see that K∗\\n\\nj is Euclidean and transitive. By construction, there are no\\nworlds i-accessible from w∗ and (w′, w∗) /∈ K∗\\n\\nj for all w′ and all j. Moreover, if ψ is\\nan i-objective formula, we have (M∗, w∗) |=′ ψ iff (M,w) |=′ ψ, since for j 6= i, we\\nhave Kj(w∗) = Kj(w). In particular, this means that ob\\uf6be+i (M∗, w∗) = ob\\uf6be+i (M,w).\\n\\nFor each ∆ ∈ S′ = Si ∪ {Γ}, there is a situation (M∆, w∆) |=′ ∆, where\\nM∆ = (W∆, π∆,K∆\\n\\n1 , . . . ,K\\n∆\\nn ). By the argument above, we can assume without\\n\\nloss of generality that there are no worlds i-accessible from w∆ and w∆ is not ac-\\ncessible from any world. We define M1 = (W,π,K1, . . . ,Kn) by taking W to be the\\nunion of all the worlds in W∆, ∆ ∈ S′. (We can assume without loss of general-\\nity that these are disjoint sets of worlds.) We define π so that π|W∆ = π∆. We\\ndefine Kj = ∪∆∈S′K∆\\n\\nj for j 6= i, and Ki to be the least transitive, Euclidean set\\n\\ncontaining ∪∆∈S′K∆\\ni ∪ {(wΓ, w∆) | ∆ ∈ S}. It is easy to check that ob\\uf6be+i (M1, w\\n\\n∆) =\\nob\\uf6be+i (M∆, w∆) (although this depends on the fact that w∆ is not j-accessible from\\nany world for j 6= i). Thus, Ob\\uf6be+i (M1, w\\n\\nΓ) = Si and ob\\uf6be+i (M1, w\\nΓ) ⊇ Γ. Thus, we can\\n\\ntake w1 = wΓ, completing the proof of part (a).\\nTo summarize the construction of part (a), we start with an arbitrary situation\\n\\n(M,w) satisfying Γ, convert it to a situation satisfying Lifalse ∧ Γ, essentially by\\nmodifying the i-accessibility relation at w so that there are no worlds i-accessible from\\nw and w is not accessible from any world, and then again modifying the i-accessibility\\nrelation at w so that we get a structure (M1, w1) such that Ob\\uf6be+i (Mi, wi) = Si. Note\\n',\n",
       "                'that in doing this construction, we did not change the propositional formulas true\\nat w, nor did we change the worlds that were j-accessible from w for j 6= i. Thus,\\nstarting with a situation that satisfies a propositional formula σ, we can repeat this\\nconstruction for each i in turn, for i = 1, . . . , n. The resulting situation is (M2, w2),\\nand it clearly has the desired properties. This proves part (b).\\n\\nFor part (c), suppose (M ′, w′) |= Σ; let Ob\\uf6be+i (M ′, w′) = Si. By part (a), there\\nis a situation (M3, w3) such that Ob\\uf6be+i (M3, w3) = Si and (M3, w3) |= Γ. Since the\\nset of subjective formulas true at a situation (M,w) is completely determined by\\nOb\\uf6be+i (M,w), and Ob\\uf6be+i (M ′, w′) = Ob\\uf6be+i (M3, w3), it follows that (M3, w3) |= Σ as\\nwell.\\n\\nHow does this semantics compare to the canonical model semantics? First of all,\\nit is easy to see that the axioms are sound. We write |=′ ϕ if (M,w) |=′ ϕ for every\\nsituation (M,w). Then we have the following result.\\n\\nTheorem 4.3 [5] For all α ∈ ONLn, if ⊢ α then |=′ α.\\n\\nProof As usual, the proof is by induction on the length of a derivation. All that\\nneeds to be done is to show that all the axioms are sound. Again, this is straightfor-\\nward. The proof in the case of A5n proceeds just as that in the proof of Theorem 3.10,\\nusing the fact that this semantics satisfies Levesque’s second property.\\n\\nMoreover, we again get completeness for the sublanguage ONL−\\n\\nn .\\n\\n18\\n\\n\\n\\nTheorem 4.4 [5] For all α ∈ ONL−\\n\\nn , ⊢ α iff |=′ α.\\n\\nProof As usual, it suffices to show that if α is consistent with the axioms, then α is\\nsatisfiable under the |=′ semantics. From Theorem 3.16, we know that α is satisfiable\\nin the canonical model under the |= semantics. Thus, it suffices to show that for\\nall formulas α ∈ ONL−\\n\\nn , we have (M c, w) |= α iff (M c, w) |=′ α. By Lemma 3.12,\\nit suffices to consider formulas α in normal form. We proceed by induction on the\\nstructure of formulas. The only nontrivial case obtains if α is of the form Niα\\n\\n′. Since\\nα is in normal form, we can assume that α′ is basic. Suppose (M c, w) |=′ Niα\\n\\n′.\\nTo show that (M c, w) |= Niα\\n\\n′, we must show that if w′ ≈i w and w′ /∈ Kci (w),\\nthen (M c, w′) |= α. By definition, if w′ ≈i w, then Obji(M\\n\\nc, w′) = Obji(M\\nc, w).\\n\\nMoreover, we must have obji(M\\nc, w′) /∈ Obji(M\\n\\nc, w), for otherwise we would have\\nw′ ∈ Kci (w). Hence, we must have (M c, w′) |=′ α′. By the induction hypothesis, we\\nhave (M c, w′) |= α′. Thus, (M c, w) |= Niα\\n\\n′, as desired.\\nFor the converse, suppose that (M c, w) |= Niα\\n\\n′. We want to show that (M c, w) |=′\\n\\nNiα\\n′. Suppose that (M ′, w′) is such that Obji(M\\n\\n′, w′) = Obji(M\\nc, w) and obji(M\\n\\n′, w′) /∈\\nObji(M\\n\\nc, w). We must show that (M ′, w′) |=′ α. It is easy to see that for every sit-\\nuation (M,w) and basic formula ϕ, we have that (M,w) |= Liϕ iff (M,w) |=′ Liϕ iff\\nϕ is in every set in Obji(M,w). Thus, it follows that subji(M\\n\\n′, w′) = subji(M\\nc, w).\\n\\nThere must be a world w′′ in M c such that (M c, w′′) agrees with (M ′, w′) on all\\nbasic formulas according to the |= semantics. Since subji(M\\n\\nc, w′′) = subji(M\\nc, w),\\n\\nit follows from Lemma 3.3 that w ≈i w′′. Since obji(M\\n′, w′) /∈ Obji(M\\n\\nc, w) and\\nobji(M\\n\\n′, w′) = obji(M\\nc, w′′), it follows that w′′ /∈ Kci (w). Since (M c, w) |= Niα\\n\\n′, we\\nmust have that (M c, w′′) |= α′. And since (M c, w′′) and (M ′, w′) agree on basic for-\\nmulas, it follows that (M ′, w′) |= α′. Finally, since |= and |=′ agree for basic formulas,\\nwe have (M ′, w′) |=′ α′. This completes the proof that (M,w) |= Niα\\n\\n′.\\n\\nAlthough our axiomatization is complete for ONL−\\n\\nn , as we now show, it is not\\ncomplete for the full language, for neither |= nor |=′. Since the axiomatization is sound\\nfor both |= and |=′, to prove incompleteness, it suffices to provide a formula which\\nis satisfiable with respect to |=′ and not |=, and another formula which is satisfiable\\nwith respect to |= and not |=′. As is shown in Proposition 4.5, Oi¬Ojp is satisfiable\\nwith respect to |=′ and (by Proposition 3.8) not with respect to |=. On the other\\nhand, it is easy to see that Ljfalse ∧Nj¬Oi¬Ojp is satisfiable with respect to |= (in\\nfact, it is equivalent to Ljfalse); as shown in Proposition 4.6, it is not satisfiable with\\nrespect to |=′.\\n\\nProposition 4.5 Oi¬Ojp is satisfiable under the |=′ semantics.\\n\\nProof Let S = {ob\\uf6be+i (M,w) | (M,w) |=′ ¬Ojp}. By Proposition 4.2, there is a sit-\\nuation (M∗, w∗) such that Ob\\uf6be+i (M∗, w∗) = S. We claim that (M∗, w∗) |=′ Oi¬Ojp.\\nClearly (M∗, w∗) |=′ Li¬Ojp, since ¬Ojp is true at all worlds i-accessible from\\nw∗. To see that (M∗, w∗) |=′ NiOjp, suppose that Obji(M,w) = Obji(M\\n\\n∗, w∗)\\nand obji(M,w) /∈ Obji(M\\n\\n∗, w∗). We want to show that (M,w) |=′ Ojp. Sup-\\npose that (M,w) |=′ ¬Ojp. By definition, ob\\uf6be+i (M,w) ∈ S, so there is some world\\nw′ ∈ KM\\n\\n∗\\n\\ni (w∗) such that ob\\uf6be+i (M∗, w′) = ob\\uf6be+i (M,w). In particular, this means that\\nobji(M\\n\\n∗, w′) = obji(M,w). But this contradicts the assumption that obji(M,w) /∈\\nObji(M\\n\\n∗, w∗). Thus, (M,w) |= Ojp as desired, and (M∗, w∗) |= Oi¬Ojp.\\n\\n19\\n\\n\\n\\n',\n",
       "                'Proposition 4.6 There is a formula β such that |=′ β but ¬β is satisfiable under the\\n|= semantics.\\n\\nProof We first show that if ϕ is an i-objective formula that is satisfiable under the |=′\\n\\nsemantics, then |=′ Lifalse ⇒ ¬Ni¬ϕ. For suppose that ϕ is satisfiable in a situation\\n(M,w). By Proposition 4.2, there is a situation (M∗, w∗) such that ob\\uf6be+i (M∗, w∗) =\\nob\\uf6be+i (M,w) and Ob\\uf6be+i (M∗, w∗) = ∅. This means that (M∗, w∗) |=′ ϕ∧Lifalse. Now let\\n(M ′, w′) be any situation satisfying Lifalse. Then Obji(M\\n\\n′, w′) = Obji(M\\n∗, w∗) = ∅,\\n\\nand obji(M\\n∗, w∗) /∈ Obji(M\\n\\n′, w′). It follows that (M ′, w′) |=′ ¬Ni¬ϕ. Thus, we\\nhave shown that |=′ Lifalse ⇒ ¬Ni¬ϕ. Since, as we showed in Proposition 4.5,\\nthe formula Oj¬Oip is satisfiable, this means that |=′ Lifalse ⇒ ¬Ni¬Oj¬Oip. On\\nthe other hand, since Oj¬Oip is not satisfiable with respect to |=, as we showed in\\nProposition 3.8, neither is ¬Ni¬Oj¬Oip, and hence Lifalse ⇒ ¬Ni¬Oj¬Oip is not\\nvalid under the |= semantics. Indeed, Lifalse ∧ Ni¬Oj¬Oip is equivalent to Lifalse\\nunder the |= semantics.\\n\\nWe can now show that our axiom system is incomplete for the full language with\\nrespect to both the |= and |=′ semantics.\\n\\nTheorem 4.7 There exist formulas α and β in ONLn such that 6⊢ α and |= α, and\\n6⊢ β and |=′ β.\\n\\nProof By Propositions 3.8 and 4.5, we have that |= ¬Oj¬Oip, but 6|=′ ¬Oj¬Oip.\\nSince ⊢ is sound with respect to |=′, we cannot have ⊢ ¬Oj¬Oip (for otherwise we\\nwould have |=′ ¬Oj¬Oip). Thus, we can take α to be ¬Oj¬Oip. A similar argument\\nshows we can take β to be Lifalse ⇒ ¬Ni¬OjOip.\\n\\nThe fact that neither |= nor |=′ is complete with respect to the axiomatization\\ndescribed earlier is not necessarily bad. We may be able to find a natural complete\\naxiomatization. However, as we suggested above, the fact that ¬Oj¬Oip is valid under\\nthe |= semantics suggests that this semantics does not quite satisfy our intuitions with\\nregards to only-knowing for formulas in ONLn −ONL−\\n\\nn . As we now show, |=′ also\\nhas its problems. We might hope that if ϕ is a satisfiable i-objective formula, then\\nNiϕ⇒ ¬Liϕ would be valid under the |=′ semantics. Unfortunately, it is not.\\n\\nProposition 4.8 The formula Ni¬Ojp ∧ Li¬Ojp is satisfiable under the |=′ seman-\\ntics.\\n\\nProof First we show that for any situation (M,w) that satisfies Ojp, there exists\\nanother situation (M ′, w′) such that (M,w) and (M ′, w′) agree on all basic formulas,\\nbut (M ′, w′) |=′ ¬Ojp. We can construct (M ′, w′) as follows: Choose a particular\\nset Γ ∈ Objj(M,w). It easily follows from Proposition 4.2 that there is a situation\\n(M ′, w′) such that Objj(M\\n\\n′, w′) = Objj(M,w) − {Γ} and objj(M\\n′, w′) = objj(M,w).\\n\\nWe now show that for any basic formula ϕ, we have (M,w) |=′ ϕ iff (M ′, w′) |=′ ϕ. If\\nϕ is a j-objective formula, this is immediate from the construction. Thus, it suffices\\nto deal with the case that ϕ is of the form Ljϕ\\n\\n′. By Lemma 3.12, we can assume\\n\\n20\\n\\n\\n\\nwithout loss of generality that ϕ′ is j-objective. Suppose that ϕ′ is a consistent j-\\nobjective formula. In this case, it is almost immediate from the definitions that if\\n(M,w) |=′ Ljϕ\\n\\n′ then (M ′, w′) |=′ Ljϕ\\n′. For the converse, suppose that (M,w) |=′\\n\\n¬Ljϕ′. Then there is some world w′′ ∈ KMj (w) such that (M,w′′) |= ¬ϕ′. Since\\n(M,w) |=′ Ljp, we have that (M,w′′) |=′ p ∧ ¬ϕ′. Let ψ be a j-objective basic\\nformula that is independent of p∧¬ϕ′. Let ϕ′′ be ϕ′ ∧ p∧¬ψ if ψ ∈ Γ, and ϕ′ ∧ p∧ψ\\notherwise. Since ψ is independent of p ∧ ¬ϕ′, it follows that ϕ′′ is consistent. Let ∆\\nbe any j-set containing ϕ′′. It must be the case that ∆ ∈ Objj(M,w), for if not, let\\n(M∗, w∗) be a situation such that Objj(M\\n\\n∗, w∗) = Objj(M,w) and objj(M\\n∗, w∗) = ∆\\n\\n(such a situation exists by Proposition 4.2). Then (M∗, w∗) |= p, contradicting the\\nassumption that (M,w) |= Nj¬p. By construction, ∆ 6= Γ. Thus, there is some\\n\\nworld v ∈ KM\\n′\\n\\nj (w′) such that objj(M\\n′, v) = ∆. It follows that (M ′, v) |=′ ¬ϕ′,\\n\\nso (M ′, w′) |=′ ¬Ljϕ\\n′. Thus, (M ′, w′) agrees with (M,w) on all basic formulas.\\n\\nHowever, since Γ /∈ Objj(M,w), it follows that (M ′, w′) |= ¬Nj¬p, and hence that\\n(M ′, w′) |= ¬Ojp.\\n\\nLet S = {ob\\uf6be+i (M,w) | (M,w) |=′ ¬Ojp}. By Proposition 4.2, there is a situation\\n(M∗, w∗) such that Ob\\uf6be+i (M∗, w∗) = S. Clearly (M∗, w∗) |=′ Li¬Ojp. We now show\\nthat (M∗, w∗) |=′ Ni¬Ojp as well. For suppose that (M,w) is a situation such that\\nObji(M,w) = Obji(M\\n\\n∗, w∗) and obji(M,w) /∈ Obji(M\\n∗, w∗). Moreover, suppose, by\\n\\nway of contradiction, that (M,w) |=′ Ojp. By the arguments above, it follows that\\nthere is a situation (M ′, w′) such that (M ′, w′) |=′ ¬Ojp and (M,w) and (M ′, w′)\\nagree on all basic formulas. By construction, ob\\uf6be+i (M ′, w′) ∈ S = Ob\\uf6be+i (M∗, w∗),\\nso obji(M\\n\\n′, w′) ∈ Obji(M\\n∗, w∗). Since obji(M,w) = obji(M\\n\\n′, w′), we must also have\\nobji(M,w) ∈ Obji(M\\n\\n∗, w∗), contradicting the choice of (M,w). Thus, (M,w) |=\\n¬Ojp, as desired, and so (M∗, w∗) |= Li¬Ojp ∧Ni¬Ojp.\\n\\n4.1 Discussion\\n\\nProposition 4.8 shows that although the i-set semantics has the three properties we\\n',\n",
       "                'claimed were appropriate, Ni and Li still do not always interact in what seems to be\\nthe appropriate way. Intuitively, the problem here is that there is more to i’s view of\\na world than just the i-objective basic formulas that are true there. We should really\\nidentify i’s view of a situation (M,w) with the set of all i-objective formulas that are\\ntrue there. In the canonical-model approach, the i-objective basic formulas that are\\ntrue at a world can be shown to determine all the i-objective formulas that are true\\nat that world. This is not true at all situations under the i-set approach.\\n\\nIndeed, it is no longer true that the i-set approach has the second of the three\\nproperties once we take i’s view of (M,w) to be ob\\uf6be+i (M,w). For consider the situation\\n(M∗, w∗) constructed in the proof of Proposition 4.8. As the proof of that lemma\\nshows, {ob\\uf6be+i (M∗, w) | w ∈ KM\\n\\n∗\\n\\ni (w∗)}∪{ob\\uf6be+i (M ′, w′) | obji(M\\n′, w′) /∈ Obji(M\\n\\n∗, w∗)}\\ndoes not include all maximal sets of i-objective formulas. In particular, it does not\\ninclude those maximal sets that satisfy Ojp.\\n\\nTo summarize: while the i-set approach arguably has enough worlds, it suffers\\nfrom the fact that the full complement of worlds is not always taken into account for\\nLi and Ni, as the above example shows. While the canonical model approach does\\nnot run into this problem, it suffers from a perhaps more basic deficiency: there just\\nare not enough worlds to begin with. For example, there is no world where OiOjp is\\n\\n21\\n\\n\\n\\ntrue.\\nWe consider a different approach in the next section that attempts to deal with\\n\\nboth problems.\\n\\n5 What Properties Should Only Knowing Have?\\n\\nUp to now, we have provided two semantics for only knowing. While both have\\nproperties we view as desirable, they also have properties that seem somewhat un-\\ndesirable. This leads to an obvious question: What properties should only knowing\\nhave? Roughly speaking, we would like to have the multi-agent version of Levesque’s\\naxioms, and no more. Of course, the problem here is axiom A5n. It is not so clear\\nwhat the multi-agent version of that should be. The problem is one of circularity:\\nWe would like to be able to say that Niϕ ⇒ ¬Liϕ should hold for any consistent\\ni-objective formula. The problem is that in order to say what the consistent formulas\\nare, we need to define the axiom system. In particular, we have to make precise what\\nthis axiom should be.\\n\\nTo deal with this problem, we extend the language so that we can explicitly talk\\nabout satisfiability and validity in the language. We add a modal operator Val to\\nthe language. The formula Val(ϕ) should be read “ϕ is valid”. Of course, its dual\\nSat(ϕ), defined as ¬Val(¬ϕ), should be read “ϕ is satisfiable”. With this operator in\\nthe language, we can replace A5n with\\n\\nA5′\\n\\nn. Sat(¬α) ⇒ (Niα⇒ ¬Liα) if α is i-objective.\\n\\nIn addition, we have the following rules for reasoning about validity and satisfia-\\nbility:\\n\\nV1. (Val(ϕ) ∧ Val(ϕ⇒ ψ)) ⇒ Val(ψ).\\n\\nV2. Sat(ϕ), if ϕ is a satisfiable propositional formula.10\\n\\nV3. (Sat(α ∧ β1)∧ . . .∧Sat(α ∧ βk)∧Sat(γ ∧ δ1)∧ . . .∧Sat(γ ∧ δm)∧Val(α ∨ γ)) ⇒\\nSat(Liα ∧ ¬Li¬β1 ∧ . . . ∧ ¬Li¬βk ∧Niγ ∧ ¬Ni¬δ1 ∧ . . . ∧ ¬Ni¬δm),\\nif α, β1, . . . , βk, γ, δ1, . . . , δm are i-objective formulas.\\n\\nV4. (Sat(α) ∧ Sat(β)) ⇒ Sat(α ∧ β) if α is i-objective and β is i-subjective.\\n\\nNecV . From ϕ infer Val(ϕ).\\n\\nAxiom V1 and the rule NecV make Val what is called a normal modal operator.\\nIn fact, it can be shown to satisfy all the axioms of S5. The interesting clauses are\\nclearly V2–V4, which capture the intuitive properties of validity and satisfiability.\\n\\nIf we restrict to basic formulas, then V3 simplifies to (Sat(α ∧ β1)∧. . .∧Sat(α ∧ βk)) ⇒\\nSat(Liα ∧ ¬Li¬β1 ∧ . . . ∧ ¬Li¬βk) (we can take γ, δ1, . . . , δm to be true to get this).\\nThe soundness of this axiom (interpreting Sat as satisfiability) follows using much the\\nsame arguments as those in the proof of Proposition 4.2. The soundness of V4 if we\\nrestrict to basic formulas follows from Lemma 3.4. More interestingly, it follows from\\n\\n10We can replace this by the simpler Sat(p′\\n1\\n∧ . . . ∧ p′\\n\\nk\\n), where p′\\n\\ni\\nis a literal—either a primitive\\n\\nproposition or its negation—and p′\\n1\\n∧ . . . ∧ p′\\n\\nk\\nis consistent.\\n\\n22\\n\\n\\n\\nthe completeness proof given below that these axioms completely characterize satisfi-\\nability in K45n; together with the K45n axioms, they provide a sound and complete\\nlanguage for the language augmented with the Val operator.\\n\\nLet AX′ consist of the axioms for ONL given earlier together with V1–V4 and\\nNecV , except that A5n is replaced by A5′\\n\\nn. AX′ is the axiom system that provides\\nwhat we claim is the desired generalization of Levesque’s axioms to the multi-agent\\ncase. In particular, A5′\\n\\nn is the appropriate generalization of A5. The question is,\\nof course, whether there is a semantics for which this is a complete axiomatization.\\nWe now provide one, in the spirit of the canonical-model construction of Section 3,\\n',\n",
       "                'except that, in the spirit of the extended situations of Section 2, we do not attempt\\nto make the set of worlds used for evaluating Li and Ni disjoint.\\n\\nLet ONL+\\nn be the extension of ONLn to include the modal operator Val. For\\n\\nthe remainder of this section, when we say “consistent”, we mean consistent with\\nthe axiom system AX′. We define the extended canonical model, denoted M e =\\n(W e, πe,Ke1, . . . ,K\\n\\ne\\nn,N\\n\\ne\\n1 , . . . ,N\\n\\ne\\nn), as follows:\\n\\n• W e consists of the maximal consistent sets of formulas in ONL+\\nn .\\n\\n• For all primitive propositions p and w ∈ W e, we have πe(w)(p) = true iff p ∈ w.\\n\\n• (w,w′) ∈ Kei iff w/Li ⊆ w′.\\n\\n• (w,w′) ∈ N e\\ni iff w/Ni ⊆ w′.\\n\\nIn this canonical model, the semantics for Li and Ni is defined in terms of the Kei\\nand N e\\n\\ni relations, respectively:\\n\\n(M e, w) |= Liα if (M e, w′) |= α for all w′ such that (w,w′) ∈ Kei .\\n(M e, w) |= Niα if (M e, w′) |= α for all w′ such that (w,w′) ∈ N e\\n\\ni .\\n\\nWe define the Val operator so that it corresponds to validity in the extended canonical\\nmodel:\\n\\n(M e, w) |= Val(α) if (M e, w′) |= α for all worlds w′ in M e.\\n\\nWe now want to show that every formula in a maximal consistent set is satisfied\\nat a world in the extended canonical model. To do this, we need one preliminary\\nresult, showing that Val and Sat really correspond to provability and consistency in\\nthis framework.\\n\\nProposition 5.1 For every formula ϕ ∈ ONLn, if ϕ is provable then so is Val(ϕ),\\nwhile if ϕ is not provable, then ¬Val(ϕ) is provable.\\n\\nProof By NecV , it is clear that if ϕ is provable, so is Val(ϕ). Thus, it remains\\nto show that if ϕ is not provable, then ¬Val(ϕ) is. Using V1, it is easy to see that\\n¬Val(ϕ) is provably equivalent to Sat(¬ϕ), so it suffices to show that if ϕ is not\\nprovable—i.e., if ¬ϕ is consistent—then Sat(¬ϕ) is provable. We prove by induction\\non ϕ that if ϕ is consistent, then Sat(ϕ) is provable.\\n\\nIf ϕ is propositional, the result is immediate from V2. For the general case, we\\nfirst use Lemma 3.12 to restrict attention to formulas in the canonical form specified\\nby the lemma. Using standard modal reasoning (V1 and NecV ) it is easy to show\\n\\n23\\n\\n\\n\\nthat ⊢ Sat(ϕ ∨ ψ) ⇔ (Sat(ϕ) ∨ Sat(ψ)). Thus, it suffices to restrict attention to a\\nconjunction in the form specified by the lemma. It is easy to see that if the conjunction\\nis consistent, then each conjunct must be consistent. Using V4, it is easy to see that\\nwe can restrict attention to i-subjective formulas. By applying Lemma 3.12, we can\\nassume without loss of generality that we are dealing with a consistent formula ϕ\\nof the form Liα ∧ ¬Li¬β1 ∧ . . . ∧ ¬Li¬βk ∧ Niγ ∧ ¬Ni¬δ1 ∧ . . . ∧ ¬Ni¬δm, where\\nα, β1, . . . , βk, γ, δ1, . . . , δm are all i-objective. We can also assume that each of α∧βi,\\ni = 1, . . . , k and γ ∧ δj, j = 1, . . . ,m are consistent, for otherwise we could easily\\nshow that ϕ is not consistent. Finally, we can show that α ∨ γ must be provable, for\\nif not, by applying A5′\\n\\nn, we can again show that ϕ is not consistent. We now apply\\nthe induction hypothesis to prove the result.\\n\\nCorollary 5.2 Each formula in ONL+\\nn is provably equivalent to a formula in ONLn.\\n\\nProof We proceed by induction on the structure of formulas. The only nontrivial\\ncase is for formulas of the form Val(ϕ). By the induction hypothesis, ϕ is provably\\nequivalent to a formula ϕ′ ∈ ONLn. By straightforward modal reasoning using V1\\n\\nand NecV , we can show that Val(ϕ) is provably equivalent to Val(ϕ′). By Proposi-\\ntion 5.1, Val(ϕ′) is provably equivalent to either true or false, depending on whether\\nϕ′ is provable.\\n\\nUsing standard modal logic techniques, we can now prove the following result.\\n\\nTheorem 5.3 M e is a K45n structure (that is, Kei and N e\\ni are Euclidean and tran-\\n\\nsitive). Moreover, for each world w ∈W e, we have (M e, w) |= α iff α ∈ w.\\n\\nProof We leave it to the reader to check that the definition of Kei guarantees that\\nM e is a K45n structure. Given Corollary 5.2, which allows us to restrict attention\\nto α ∈ ONLn, the proof that (M e, w) |= α iff α ∈ w is completely straight forward\\nand follows the same lines as the usual proofs dealing with canonical models (see, for\\nexample, [2, 9]).\\n\\nWe say that α is e-valid, denoted |=e α, if M e |= α, that is, if (M e, w) |= α for all\\nworlds w ∈W e. The following result is immediate from Theorem 5.3.\\n\\nCorollary 5.4 |=e α iff AX ′ ⊢ α.\\n\\nThus, AX′ is a sound and complete axiomatization of ONL+\\nn with respect to the |=e\\n\\nsemantics.\\nWhile AX′ is sufficient for our purposes, it comes at the expense of having to\\n\\nexplicitly axiomatize validity as part of the logic itself. While we view the ability to\\naxiomatize validity and satisfiability within the logic as a feature in our approach,\\nit is reasonable to ask whether it is really necessary. One of the anonymous referees\\nsuggested to us the following interesting variant, which may avoid this complication,\\nalthough at the expense of an infinite number of axiom schemas.\\n\\n',\n",
       "                'First we define an infinite sequence of languages ONLkn for k = 0, 1, 2 . . .:\\n\\n• ONL0\\nn= ONL−\\n\\nn\\n\\n24\\n\\n\\n\\n• ONLk+1\\nn = {α | α is a Boolean combination of formulas of ONLkn together with\\n\\nformulas of the form Liα or Niα for α ∈ ONLkn}\\n\\nRoughly, each language adds another level of nestings of only knowing with varying\\nagent indices. For example, ONLk+1\\n\\nn contains the formula Oi0Oi1 . . . Oik+1\\np, where\\n\\nij 6= ij+1, something that cannot be expressed in ONLkn.\\nLet AX∗ consist of the the axioms A1n–A4n as before together with the following\\n\\nset of axioms\\n\\nA5k+1\\nn . Niα ⇒ ¬ Liα, where α is an i-objective ONLkn formula which is\\n\\nconsistent with respect to A1n–A4n,A51\\nn, A52\\n\\nn,. . . A5kn.\\n\\nIt is not hard to show that the axioms are sound with respect to the semantics.\\nWhether they are also complete remains an open problem.\\n\\nApart from the question of axiomatization, how does the |=e semantics compare\\nto our earlier two? Clearly, they differ. It is easy to see that the formula Oi¬Ojp,\\nwhich was not satisfiable under |=c, is satisfiable under |=e. In addition, the formula\\nNi¬Ojp∧Li¬Ojp, which is satisfiable under |=′, is not satisfiable under |=e. In both\\ncases, it seems that the behavior of |=e is more appropriate. On the other hand, all\\nthree semantics agree in the case where our intuitions are strongest, ONL−\\n\\nn . Since\\nthe axiom system AX characterizes how our earlier two semantics deal with ONL−\\n\\nn ,\\nthis is shown by the following result.\\n\\nTheorem 5.5 If ϕ ∈ ONL−\\n\\nn , then AX ⊢ ϕ iff AX ′ ⊢ ϕ.\\n\\nProof It is easy to see that each axiom of AX is sound in AX′. It follows that\\nAX ⊢ ϕ implies AX′ ⊢ ϕ. For the converse, it suffices to show that if ϕ ∈ ONL−\\n\\nn\\n\\nis consistent with AX, then it is also consistent with AX′, i.e., that Sat(ϕ) holds.\\nWe show this by induction on the structure of ϕ, much in the same way we proved\\nProposition 5.1. We can assume without loss of generality that ϕ is a conjunction in\\nthe normal form described Lemma 3.12. It is easy to see that if we can deal with the\\ncase that ϕ is an i-subjective formula, then we can deal with arbitrary ϕ by repeated\\napplications of V4 followed by an application of V2. Thus, suppose that ϕ is an\\ni-subjective formula which is consistent with AX. We can assume that ϕ is of the\\nform Liα∧¬Li¬β1∧ . . .∧¬Li¬βk∧Niγ∧¬Ni¬δ1∧ . . .∧¬Ni¬δm. We must have that\\nα∧ βj is consistent for j = 1, . . . , k, and that γ ∧ δl is AX-consistent for l = 1, . . . ,m,\\nfor otherwise ϕ would not be AX-consistent. Similarly, by Lemma 3.14, we must have\\nthat α ∨ γ is K45n-provable, otherwise ϕ would not be AX-consistent. We can now\\napply V3 and the inductive hypothesis to show that α is AX′-consistent.\\n\\nThus, we maintain all the benefits of the earlier semantics with this approach.\\nMoreover, while it is just as intractable to compute whether (M e, w) |= α for a par-\\nticular world w in the extended canonical model as it was in all our other approaches,\\nwe can show that the validity problem for this logic is no harder than that for K45n\\nalone. It is PSPACE-complete.\\n\\nTheorem 5.6 The problem of deciding if AX ′ ⊢ ϕ is PSPACE-complete.\\n\\n25\\n\\n\\n\\nProof PSPACE hardness follows from the PSPACE hardness of K45n [9].11 We\\nsketch the proof of the upper bound. First of all, observe that it suffices to deal with\\nthe case that ϕ is in ONLn, since we can then apply the arguments of Corollary 5.2\\nto remove all occurrences of Val from inside out. We consider the dual problem of\\nconsistency. Thus, we want to check if Sat(α) holds. The first step is to convert α\\nto the normal form of Lemma 3.12. Observe that α is consistent iff at least one of\\nthe disjuncts is consistent. Although the conversion to normal form may result in\\nexponentially many disjuncts, each one is no longer than α. Thus, we deal with them\\none by one, without ever writing down the full disjunction. It suffices to show that we\\ncan decide if each disjunct is consistent in polynomial space, since we can then erase\\nall the work and start over for the next disjunct (with a little space necessary for\\nbookkeeping). We now proceed much as in the proof of Proposition 5.1. By applying\\nV4 repeatedly and then V2 (as in the previous theorem), it suffices to deal with\\ni-subjective formulas. We then apply V3 to get simpler formulas, and repeat the\\nprocedure. We remark that this gives another PSPACE decision procedure for K45n,\\nquite different from that presented in [9].\\n\\nTo what extent do the three properties we have been focusing on hold under the\\n|=e semantics? Suppose we take the conceivable states from i’s point of view to be the\\nmaximal consistent sets of i-objective formulas with respect to AX′, or equivalently,\\nthe set of i-objective formulas true at some world in M e. Let ob\\uf6beei (M\\n\\ne, w) consist of all\\nthe i-objective formulas true at world w in the extended canonical model (under the\\n|=e semantics) and let Ob\\uf6beei (M\\n\\ne, w) = {ob\\uf6beei (M\\ne, w′) | w′ ∈ Kei (w)}. It is easy to see\\n\\n',\n",
       "                'that the first two properties we isolated hold under this interpretation of conceivable\\nstate. However, it is quite possible that the “possible states” at a world (M c, w), that\\nis, Ob\\uf6beei (M\\n\\nc, w), and the “impossible states”, that is, {ob\\uf6beei (M\\nc, w′) | w′ ≈i w,w /∈\\n\\nKei (w)} are not disjoint.\\nInterestingly, this semantics does not satisfy the third property we isolated. Not\\n\\nall subsets of conceivable states arise as the set of possible states at some situation\\n(M e, w). A proof analogous to that of Lemma 3.7 shows that Ob\\uf6beei (M,w) is always\\nlimit closed. In the canonical model approach, limit closure prevents an agent from\\nconsidering certain desirable sets of states. Now this is no longer the case, despite\\nlimit closure. Roughly speaking, we avoid problems by having in a precise sense\\n“enough” possibilities. More precisely, given any consistent i-objective formula α, it\\nis possible for agent i to only know α by virtue of considering all maximal sets of i-\\nobjective formulas which contain α. Thus, as we suggested earlier, the third property\\nwe isolated in the beginning turns out to be somewhat too strong—it is sufficient but\\nnot necessary once we allow for enough possibilities.\\n\\n6 Multi-Agent Nonmonotonic Reasoning\\n\\nIn this section, we demonstrate that the logic developed in Section 5 captures multi-\\nagent autoepistemic reasoning in a reasonable way. We do this in two ways. First we\\nshow by example that the logic can be used to derive some reasonable nonmonotonic\\ninferences in a multi-agent context. We then show that the logic can be used to\\n\\n11The result in [9] is proved only for KD45n, but the same proof applies to K45n.\\n\\n26\\n\\n\\n\\nextend the definitions of stable sets and stable expansions originally developed for\\nsingle agent autoepistemic logic to the multi-agent setting.\\n\\n6.1 Formal Derivations of Nonmonotonic Inferences\\n\\nIn this section, we provide two examples of how the logic can be used for nonmonotonic\\nreasoning.\\n\\nExample 6.1 Let p be agent i’s secret and suppose i makes the following assumption:\\nunless I know that j knows my secret assume that j does not know it. We can prove\\nthat if this assumption is all i believes then he indeed believes that j does not know\\nhis secret. Formally, we can show\\n\\n⊢ Oi(¬LiLjp⇒ ¬Ljp) ⇒ Li¬Ljp.12\\n\\nA formal derivation of this theorem can be obtained as follows. Let α = ¬LiLjp⇒ ¬Ljp.\\nThe justifications in the following derivation indicate which axioms or previous deriva-\\ntions have been used to derive the current line. PL or K45n indicate that reasoning\\nin either standard propositional logic or K45n, which are subsumed by AX′, is used\\nwithout further analysis.\\n\\n1. Oiα⇒ Liα PL\\n2. Oiα⇒ Ni¬α PL\\n3. (Liα ∧ ¬LiLjp) ⇒ Li¬Ljp K45n\\n4. Ni¬α⇒ (Ni¬LiLjp ∧NiLjp) K45n\\n5. Sat(p) V2\\n\\n6. Sat(p) ⇒ Sat(¬Ljp) V3\\n\\n7. Sat(¬Ljp) V1, PL\\n8. Sat(¬Ljp) ⇒ (NiLjp⇒ ¬LiLjp) A5′\\n\\nn\\n\\n9. NiLjp⇒ ¬LiLjp PL\\n10. Oiα⇒ ¬LiLjp 2; 4; 9; PL\\n11. Oiα⇒ Li¬Ljp 1; 3; 10; PL\\n\\nTo see that i’s beliefs may evolve nonmonotonically given that i knows only α, assume\\nthat i finds out that j has found out about the secret. Then i’s belief that j does\\nnot believe the secret will be retracted. In fact, i will believe that j does believe the\\nsecret. Formally, we can show\\n\\n⊢ Oi(Ljp ∧ α) ⇒ LiLjp.\\n\\nNotice that the logic itself is a regular monotonic logic; the nonmonotonicity of agent\\ni’s beliefs is hidden within the Oi-operator.\\n\\nAll the formulas that appear in the proof above are in ONL−\\n\\nn . Thus, we could\\nhave used the somewhat simpler proof theory of Section 3.1. To obtain an example\\nwhere we need the full power of AX′, simply replace Ljp by Ojp, that is i now uses\\nthe default that unless he knows that j only knows p, then he assumes that j does not\\nonly know p. In other words, i (prudently) makes rather cautious assumptions about\\ni’s epistemic state and assumes that i usually knows more than just p. The proof is\\nvery similar to the one above. The only difference is that we now have to establish\\nthat Sat(¬Ojp) is provable, which is straightforward.\\n\\n12Note that if we replace Ljp by p we obtain regular single-agent autoepistemic reasoning.\\n\\n27\\n\\n\\n\\nExample 6.2 Now let p stand for “Tweety flies”.13 We want to show that if j knows\\nthat all i knows about Tweety is that by default it flies, then j knows that i believes\\nthat Tweety flies. As before, we capture the fact that all i believes is that, by default,\\nTweety flies, by saying that all i believes is that, unless i believes that Tweety does\\nnot fly, then Tweety flies. Thus, we want to show\\n\\n⊢ LjOi(¬Li¬p⇒ p) ⇒ LjLip.\\n\\nWe proceed as follows:\\n1. Oi(¬Li¬p ⇒ p) ⇒ Lip as above, with Ljp replaced by ¬p\\n2. Lj(Oi(¬Li¬p⇒ p) ⇒ Lip) 1; Necn\\n3. LjOi(¬Li¬p⇒ p) ⇒ LjLip 2; K45n\\n\\nIn a sense, i is able to reason about j’s ability to reason nonmonotonically essentially\\nby simulating j’s reasoning pattern.\\n\\nA situation where i knows that all j knows is α seems hardly attainable in practice,\\nsince an agent usually has at best incomplete information about another agent’s be-\\nliefs. ',\n",
       "                'It would seem much more reasonable if we could say that i knows that α is\\nall j knows about some relevant subject, say Tweety. This issue is dealt with in [13],\\nwhere the canonical-model approach is extended to allow statements of the kind that\\nall agent i knows about x is y. It is shown that the forms of nonmonotonic reasoning\\njust described, when restricted to ONL−\\n\\nn , go through just as well with the weaker\\nnotion of only knowing about.\\n\\n6.2 i-Stable Sets and i-Stable Expansions\\n\\nSingle-agent autoepistemic logic was developed by Moore [15] using the concepts of\\nstable sets and stable expansions. Levesque proved that there is a close relationship\\nbetween stable sets and only-knowing in the single-agent case. Here we prove an\\nanalogous relationship for the multi-agent case. We first need to define a multi-agent\\nanalogue of stable sets.\\n\\nIn the single-agent case, it is well known that a stable set is a complete set of\\nformulas that agent i could know in some situation; that is, a set S is stable if\\nand only if there is a situation (W,w) such that S = {α | (W,w) |= Lα}. This is\\nthe intuition that we want to extend to the multi-agent setting, where the underlying\\nlanguage is now ONLn. First we define logical consequence in the extended canonical\\nmodel in the usual way: If Γ is a set of formulas, we write M e |= Γ if M e |= γ′ for\\neach formula γ′ ∈ Γ. We say that γ is an e-consequence of Γ, and write Γ |=e γ,\\nexactly if M e |= Γ implies M e |= γ.\\n\\nDefinition 6.3 Let Γ be a set of formulas in ONLn. Γ is called i-stable iff\\n\\n(a) if Γ |=e γ then γ ∈ Γ,\\n\\n(b) if α ∈ Γ then Liα ∈ Γ,\\n\\n(c) if α 6∈ Γ then ¬Liα ∈ Γ.\\n\\n13Regular readers of papers on nonmonotonic logic will no doubt be gratified to see Tweety’s\\nreappearance.\\n\\n28\\n\\n\\n\\nNote that the only difference between i-stable sets and the original definition\\nof stable sets is in condition (a), which requires i-stable sets to be closed under e-\\nconsequence instead of tautological consequence (i.e., logical consequence in proposi-\\ntional logic) as in the single-agent case. Using e-consequence rather than tautological\\nconsequence makes no difference in the single-agent case; in the multi-agent case it\\ndoes. Intuitively, we want to allow the agents to use e-consequence here to capture\\nthe intuition that it is common knowledge that all agents are perfect reasoners under\\nthe extended canonical model semantics. For example, if agent i believes ¬Ljp for a\\ndifferent agent j, then we want him to also believe Nj¬Ljp. To do this, we need to\\nclose off under e-consequence.\\n\\nThe next theorem shows that i-stable sets do indeed satisfy the intuitive require-\\nment. We define an i-epistemic state to be a set Γ of ONLn-formulas such that for\\nsome situation (M e, w) in the extended canonical model, Γ = {α ∈ ONLn | (M e, w) |=\\nLiα}; in this case, we say that Γ is the i-epistemic situation corresponding to (M e, w).\\nFor a set of ONLn-formulas Γ, let Γ = {γ | γ ∈ ONLn and γ 6∈ Γ}, LiΓ = {Liγ | γ ∈\\nΓ}, and ¬LiΓ = {¬Liγ | γ ∈ Γ}.\\n\\nTheorem 6.4 Let Γ be a set of ONLn-formulas. Γ is i-stable iff Γ is an i-epistemic\\nstate.\\n\\nProof It is straightforward to show that every i-epistemic state is i-stable. To show\\nthe converse, let Γ be i-stable. We need to show that it is also an i-epistemic state.\\nCertainly LiΓ is consistent. If Γ contains all ONLn-formulas, that is, if agent i\\nis inconsistent, then let (M e, w) be a situation where Kei (w) = ∅; such a situation\\nclearly exists. Then Γ is the i-epistemic situation corresponding to (M e, w). If Γ\\nis a proper subset of the ONLn-formulas, then Γ must be consistent. (If Γ were\\ninconsistent, by the first property of stable sets, Γ would contain all formulas.) In\\nparticular, this means that p ∧ ¬p /∈ Γ for a primitive proposition p. The second\\nproperty of stable sets guarantees that LiΓ ⊆ Γ, while the third guarantees that\\n¬Li(p ∧ ¬p) ∈ Γ. Since Γ is consistent, so is LiΓ ∪ {¬Li(p ∧ ¬p)}. W e consists\\nof all the maximal consistent sets (with respect to AX′); thus, there must be some\\nw∗ ∈W e that contains LiΓ∪{¬Li(p∧¬p)}. We claim that Γ is the i-epistemic state\\ncorresponding to (M e, w∗). Thus, we must show that ϕ ∈ Γ iff (M e, w∗) |= Liϕ. To\\nsee this, first suppose that ϕ ∈ Γ. Thus, Liϕ ∈ LiΓ. By construction, w∗ contains\\nLiΓ. By Theorem 5.3, we have that (M e, w∗) |= Liϕ. On the other hand, if ϕ /∈ Γ,\\nthen, since Γ is i-stable, we have that ¬Liϕ ∈ Γ. By the previous argument, it follows\\nthat (M e, w∗) |= Li¬Liϕ. From A4n, it follows that (M e, w∗) |= ¬Liϕ, and hence\\n(M e, w∗) 6|= Liϕ. This proves the claim.\\n\\nMoore [15] defined the notion of a stable expansion of a set A of formulas in the\\nsingle-agent case. Intuitively, a stable expansion of A is a stable set containing A all\\nof whose formulas can be justified, given A and the formulas believed in that stable\\nset. Further discussion and justification of the notion of stable expansion can be\\nfound in [6, 15]. Rather than discussing this here, we go directly to our multi-agent\\n',\n",
       "                'generalization of Moore’s notion.\\n\\nDefinition 6.5 Let A be a set of ONLn-formulas. Γ is called an i-stable expansion\\nof A iff Γ = {γ ∈ ONLn | A ∪ LiΓ ∪ ¬LiΓ |=e γ}.\\n\\n29\\n\\n\\n\\nIt is easy to see that an i-stable expansion is an i-stable set. The definition of i-stable\\nexpansions looks exactly like Moore’s definition of stable expansions except that we\\nagain use e-consequence instead of tautological consequence. As in the case of stable\\nsets, this is necessary to capture the fact that it is common knowledge that all agents\\ncan do reasoning under the extended canonical model semantics.\\n\\nWe now generalize a result of Levesque’s [14] (who proved it for the single-agent\\ncase), showing that the i-stable expansions of a formula α correspond precisely to the\\ndifferent situations where i only knows α. We first need a lemma.\\n\\nLemma 6.6 Let (M e, w) be a situation with\\n\\nΣ = {Liγ | (M e, w)|=Liγ} ∪ {¬Liγ | (M e, w)|=¬Liγ}.\\n\\nFor any α, there is an i-objective formula α∗ such that\\n\\n(a) Σ |=e α⇔ α∗,\\n\\n(b) (M e, w) |= (Liα⇔ Liα\\n∗) ∧ (Niα⇔ Niα\\n\\n∗).\\n\\nProof Given a formula ϕ, we say that a subformula Liψ of ϕ occurs at top level if\\nit is not in the scope of any modal operators. Let α∗ be the result of replacing each\\ntop-level subformula of α of the form Liγ (resp., Niγ) by true if Σ |=e Liγ (resp.,\\nΣ |=e Niγ) and by false otherwise. Clearly α∗ is i-objective. Moreover, a trivial\\nargument by induction on the structure of α shows that Σ |= α ⇔ α∗: If α is a\\nprimitive proposition then α∗ = α; if α is of the form α1 ∧ α2 or ¬α′, then the result\\nfollows easily by the induction hypothesis; if α is of the form Ljβ for j 6= i, then\\nα = α∗, since α has no top-level subformulas of the form Liϕ; finally, if α is of the\\nform Liβ, then α∗ is either true or false, depending on whether Liβ is in Σ. Since\\neither Liβ or ¬Liβ must be in Σ, the result is immediate in this case too. Part (b)\\nfollows immediately from part (a), since if w′ ≈i w, we must have (M e, w′) |= Σ, so\\n(M e, w′) |= α⇔ α∗.\\n\\nTheorem 6.7 Let w be a world in the extended canonical model and let Γ be the\\ni-epistemic state corresponding to (M e, w). Then, for every ONLn-formula α, we\\nhave that (M e, w)|=Oiα iff (a) Γ is an i-stable expansion of {α} and (b) Kei (w) and\\nN e\\ni (w) are disjoint.\\n\\nProof Let Σ = LiΓ∪¬LiΓ. To prove the “only if” direction, suppose (M e, w)|=Oiα.\\nThe disjointness of Kei (w) and N e\\n\\ni (w) follows immediately from the fact that (M e, w)|=Liα∧\\nNi¬α. To prove that Γ is an i-stable expansion of {α}, it suffices to show that for all\\nONLn-formulas β, we have (M e, w)|=Liβ iff {α} ∪ Σ |=e β.\\n\\nFirst suppose that {α} ∪ Σ |=e β. Since (M e, w)|={Oiα} ∪ Σ, and every for-\\nmula in Σ is of the form Liγ or ¬Liγ, it easily follows that (M e, w)|=Liα and\\n(M e, w)|=LiΣ. Hence, (M e, w′)|=α and (M e, w′)|=Σ for every w′ ∈ Kei (w). It follows\\nthat (M e, w′)|=β and, therefore, (M e, w)|=Liβ.\\n\\nFor the converse, suppose that (M e, w)|=Liβ. We want to show that {α}∪Σ |=e β.\\nBy Lemma 6.6, we can assume without loss of generality that β is i-objective. (For\\n\\n30\\n\\n\\n\\nif not, we can replace β by an i-objective β∗ such that Σ |=e β ⇔ β∗ and (M e, w) |=\\nLiβ ⇔ Liβ\\n\\n∗, prove the result for β∗, and conclude that it holds for β as well.) To show\\nthat {α}∪Σ |=e β, we must show that for all worlds w′ such that (M e, w′)|={α}∪Σ,\\nwe have (M e, w′) |= β. By Lemma 6.6, there is an i-objective formula α∗ such that\\n(M e, w) |= Oα ⇔ Oα∗ and Σ |=e α ⇔ α∗. Thus, (M e, w) |= Niα\\n\\n∗ ∧ Liβ. By the\\narguments of Lemma 3.14 (which apply without change to the extended canonical\\nmodel semantics), it must be the case that |=e α∗ ⇒ β. Since Σ |=e α ⇔ α∗, it\\nfollows that {α} ∪ Σ |=e β. Since (M e, w′)|={α} ∪ Σ by assumption, we have that\\n(M e, w′)|=β, as desired.\\n\\nTo prove the “if” direction of the theorem, suppose that Kei (w) and N e\\ni (w) are\\n\\ndisjoint and that for all ONLn-formulas β, we have (M e, w)|=Liβ iff {α} ∪ Σ |=e β.\\nWe need to show that (M e, w)|=Oiα, that is, (M e, w)|=Liα ∧Ni¬α.\\n\\nSince {α} ∪ Σ |=e α, the fact that (M e, w)|=Liα follows immediately. To prove\\nthat (M e, w)|=Ni¬α, let w′ ∈ N e\\n\\ni (w) and assume, to the contrary, that (M e, w′)|=α.\\nSince w′ ∈ N e\\n\\ni (w), it follows that Σ ⊆ w′. Hence w/Li ⊆ w′, from which w′ ∈ Kei (w)\\nfollows, contradicting the assumption that Kei (w) and N e\\n\\ni (w) are disjoint.\\n\\n7 Conclusion\\n\\nWe have provided three semantics for multi-agent only-knowing. All agree on the\\nsubset ONL−\\n\\nn , but they differ on formulas involving nested Ni’s. Although a case\\ncan be made that the |=e semantics comes closest to capturing our intuitions for\\n“knowing at most”, our intuitions beyond ONL−\\n\\nn are not well grounded. It would\\ncertainly help to have more compelling semantics corresponding to AX′.\\n\\nOn the other hand, it can be argued that semantics does not play quite as crucial\\na role when dealing with knowing at most as in other cases. The reason is that\\nthe structures we must deal with, in general, have uncountably many worlds. For\\n',\n",
       "                'example, whichever of the three semantics we use, there must be uncountably many\\nworlds i-accessible from a situation (M,w) satisfying Oip, at least one for every i-set\\nthat includes p. To the extent that we are interested in proof theory, the proof theory\\nassociated with |=e, characterized by the axiom system AX′, seems quite natural.\\nThe fact that the validity problem is no harder in this setting than that for K45n\\nadds further support to its usefulness. Of course, as we suggested above, rather\\nthan only knowing, it seems more appropriate to reason about only knowing about\\na certain topic. Lakemeyer [13] provides a semantics for only knowing about, using\\nthe canonical-model approach. It would be interesting to see if this can also be done\\nusing the other approaches we have explored here.\\n\\nReferences\\n\\n[1] S. Ben-David and Y. Gafni. All we believe fails in impossible worlds. Manuscript,\\n1989.\\n\\n[2] B. F. Chellas. Modal Logic. Cambridge University Press, Cambridge, U.K., 1980.\\n\\n[3] R. Fagin, J. Geanakoplos, J. Y. Halpern, and M. Y. Vardi. The expressive\\npower of the hierarchical approach to modeling knowledge and common knowl-\\n\\n31\\n\\n\\n\\nedge. In Y. Moses, editor, Theoretical Aspects of Reasoning about Knowledge:\\nProc. Fourth Conference, pages 229–244. Morgan Kaufmann, San Francisco,\\nCalif., 1992.\\n\\n[4] R. Fagin, J. Y. Halpern, and M. Y. Vardi. What can machines know? On the\\nproperties of knowledge in distributed systems. Journal of the ACM, 39(2):328–\\n376, 1992.\\n\\n[5] J. Y. Halpern. Reasoning about only knowing with many agents. In Proceedings,\\nEleventh National Conference on Artificial Intelligence (AAAI ’93), pages 655–\\n661, 1993.\\n\\n[6] J. Y. Halpern. A theory of knowledge and ignorance for many agents. Research\\nReport RJ 9894, IBM, 1994. To appear, Journal of Logic and Computation.\\n\\n[7] J. Y. Halpern and G. Lakemeyer. Levesque’s axiomatization of only knowing is\\nincomplete. Artificial Intelligence, 74(2):381–387, 1995.\\n\\n[8] J. Y. Halpern and Y. Moses. Towards a theory of knowledge and ignorance. In\\nProc. AAAI Workshop on Non-monotonic Logic, pages 125–143, 1984. Reprinted\\nin K. R. Apt (Ed.), Logics and Models of Concurrent Systems, Springer-Verlag,\\nBerlin/New York, pp. 459–476, 1985.\\n\\n[9] J. Y. Halpern and Y. Moses. A guide to completeness and complexity for modal\\nlogics of knowledge and belief. Artificial Intelligence, 54:319–379, 1992.\\n\\n[10] G. E. Hughes and M. J. Cresswell. An Introduction to Modal Logic. Methuen,\\nLondon, 1968.\\n\\n[11] I. L. Humberstone. A more discriminating approach to modal logic. Journal of\\nSymbolic Logic, 51(2):503–504, 1986. (Abstract only.) There is also an expanded,\\nbut unpublished, manuscript.\\n\\n[12] G. Lakemeyer. All they know: a study in multi-agent autoepestemic reasoning. In\\nProc. Thirteenth International Joint Conference on Artificial Intelligence (IJCAI\\n’93), pages 376–381, 1993.\\n\\n[13] G. Lakemeyer. All they know about. In Proceedings, Eleventh National Confer-\\nence on Artificial Intelligence (AAAI ’93), pages 662–667, 1993.\\n\\n[14] H. J. Levesque. All I know: a study in autoepistemic logic. Artificial Intelligence,\\n42(3):263–309, 1990.\\n\\n[15] R. C. Moore. Semantical considerations on nonmonotonic logic. Artificial Intel-\\nligence, 25:75–94, 1985.\\n\\n32\\n\\n\\n'],\n",
       "               'language': 'en',\n",
       "               'score': 1.1530330181121826,\n",
       "               'vectorized': True}),\n",
       "             ('aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDE0djIucGRm0',\n",
       "              {'title': 'arXiv:cs/0001014v2  [cs.CC]  21 Apr 2000',\n",
       "               'name': '0001014v2.pdf',\n",
       "               'location': 'https://blobstorageyhyufoqh6yjr6.blob.core.windows.net/arxivcs/0001/0001014v2.pdf',\n",
       "               'caption': 'This is a polynomial p such that p(x) 6= 0 iff f(x) = 1. Let the non-deterministic degree of f , de- noted ndeg(f), be the minimum degree among all non- deterministic polynomials p for f . Without loss of gener- ality we can assume p(x) ∈ [−1, 1] for all x ∈ {0, 1}n (if not, just divide by maxx |p(x)|).',\n",
       "               'index': 'cogsrch-index-files',\n",
       "               'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n00\\n\\n01\\n01\\n\\n4v\\n2 \\n\\n [\\ncs\\n\\n.C\\nC\\n\\n] \\n 2\\n\\n1 \\nA\\n\\npr\\n 2\\n\\n00\\n0\\n\\nCharacterization of Non-Deterministic Quantum Query and Quantum\\nCommunication Complexity\\n\\nRonald de Wolf∗\\n\\nCentrum voor Wiskunde en Informatica (CWI)\\nKruislaan 413\\n\\n1098 SJ Amsterdam, the Netherlands\\nrdewolf@cwi.nl\\n\\nAbstract\\n\\nIt is known that the classical and quantum query com-\\nplexities of a total Boolean function f are polynomially re-\\nlated to the degree of its representing polynomial, but the\\noptimal exponents in these relations are unknown. We show\\nthat the non-deterministic quantum query complexity of f is\\nlinearly related to the degree of a “non-deterministic” poly-\\nnomial for f . We also prove a quantum-classical gap of 1\\nvs. n for non-deterministic query complexity for a total f .\\nIn the case of quantum communication complexity there is a\\n(partly undetermined) relation between the complexity of f\\nand the logarithm of the rank of its communication matrix.\\nWe show that the non-deterministic quantum communica-\\ntion complexity of f is linearly related to the logarithm of\\nthe rank of a non-deterministic version of the communica-\\ntion matrix, and that it can be exponentially smaller than its\\nclassical counterpart.\\n\\n1 Introduction and statement of results\\n\\nThere are two ways to view a classical non-deterministic\\nalgorithm for some Boolean function (or language) f . First,\\nwe may think of it as a deterministic algorithm A which re-\\nceives the input x and a “certificate” y. For all inputs x, if\\nf(x) = 1 then there is a certificate y such that A(x, y) = 1;\\nif f(x) = 0 then A(x, y) = 0 for all y. Secondly, we\\nmay view A as a randomized algorithm whose acceptance\\nprobability P (x) is positive if f(x) = 1 and P (x) = 0\\nif f(x) = 0. It is easy to see that these two views are\\nequivalent in the case of classical computation: there is a\\nview 1 algorithm for f iff there is a view 2 algorithm for f\\nof roughly the same complexity.\\n\\n∗Partially supported by the EU fifth framework project QAIP, IST–\\n1999–11234. Also affiliated with the University of Amsterdam (ILLC).\\n\\nBoth views may be generalized to the quantum case,\\nyielding three possibly non-equivalent definitions of non-\\ndeterministic quantum algorithms. The quantum algorithm\\nmay be required to output the right answer f(x) when given\\nan appropriate certificate (which may be quantum or clas-\\nsical); or the quantum algorithm may be required to have\\npositive acceptance probability iff f(x) = 1. An exam-\\nple is given by two alternative definitions of “quantum NP”.\\nKitaev [28] (see also [26]) defines this class as the set of\\nlanguages which are accepted by polynomial-time quantum\\nalgorithms that are given a polynomial-size quantum cer-\\ntificate. On the other hand, Adleman et.al. [1] and Fenner\\net.al. [21] define quantum NP as the set of languages L for\\nwhich there is a polynomial-time quantum algorithm whose\\nacceptance probability is positive iff x ∈ L. This quan-\\ntum class was shown equal to the classical counting class\\nco-C=P in [21], using tools from [22].\\n\\nWe will here adopt the latter view: a non-deterministic\\nquantum algorithm for f is a quantum algorithm which out-\\nputs 1 with positive probability if f(x) = 1 and which al-\\nways outputs 0 if f(x) = 0. (In the appendix we will show\\nthat for non-uniform settings, this definition is at least as\\nstrong as the other possible definitions.) We will study the\\ncomplexity of such non-deterministic quantum algorithms\\nin two different settings: query complexity and communi-\\ncation complexity. Our main results are characterizations\\nof these complexities in algebraic terms and large gaps be-\\ntween quantum and classical non-deterministic complexity\\nin both settings.\\n\\nFirst consider the model of query complexity, also known\\nas decision tree complexity or black-box complexity. Most\\nexisting quantum algorithms can naturally be expressed in\\nthis model and achieve provable speed-ups there over the\\nbest classical algorithms (e.g. [19, 39, 23, 7, 8, 9] and also\\nthe order-finding problem on which Shor’s factoring algo-\\nrithm is based [38, 15]). Let Dq(f) and Qq(f) denote the\\nquery complexities of optimal deterministic and quantum\\n\\nhttp://arxiv.org/abs/cs/0001014v2\\n\\n\\nalgorithms that compute some f : {0, 1}n → {0, 1} ex-\\nactly.1 Let deg(f) denote the degree of the multilinear poly-\\nnomial that represents f . The following relations are known\\n(see [3]; the last inequality is due to Nisan and Smolensky—\\nunpublished, but see [13]):\\n\\ndeg(f)\\n\\n2\\n≤ Qq(f) ≤ Dq(f) ≤ O(deg(f)4).\\n\\nThus deg(f), Qq(f) and Dq(f) are all polynomially re-\\nlated for all total f (the situation is very different for partial\\nf [19, 39]). A function is known with a near-quadratic gap\\nbetween Dq(f) and deg(f) [33], but no function is known\\nwhere Qq(f) is significantly larger than deg(f), and it may\\nin fact be true that Qq(f) and deg(f) are linearly related. In\\nSection 3 we show that such a linear relation holds between\\nthe non-deterministic versions of Qq(f) and deg(f):\\n\\nndeg(f)\\n\\n2\\n',\n",
       "                '≤ NQq(f) ≤ ndeg(f) ≤ Nq(f).\\n\\nHere Nq(f) and NQq(f) denote the query complexities of\\noptimal non-deterministic classical and quantum algorithms\\nfor f , respectively, and ndeg(f) is the minimal degree of a\\npolynomial p which is non-zero iff f(x) = 1. Thus we have\\nan algebraic characterization of the non-deterministic quan-\\ntum query complexity NQq(f), up to a factor of 2. We also\\nshow that NQq(f) may be much smaller than Nq(f): we\\nexhibit an f where NQq(f) = 1 and Nq(f) = n, which\\nis the biggest possible gap allowed by this model. Accord-\\ningly, while the case of exact computation allows at most\\npolynomial quantum-classical gaps, the non-deterministic\\ncase allows unbounded gaps.\\n\\nIn the case of communication complexity, the goal is for\\ntwo distributed parties, Alice and Bob, to compute some\\nfunction f : {0, 1}n × {0, 1}n → {0, 1}. Alice receives an\\nx ∈ {0, 1}n and Bob receives a y ∈ {0, 1}n, and they want\\nto compute f(x, y), exchanging as few bits of communica-\\ntion as possible. This setting was introduced by Yao [41]\\nand is fairly well understood for the case where Alice and\\nBob are classical players exchanging classical bits [30].\\nMuch less is known about quantum communication com-\\nplexity, where Alice and Bob have a quantum computer and\\ncan exchange qubits. This was first studied by Yao [42] and\\nit was shown later that quantum communication complexity\\ncan be significantly smaller than classical communication\\ncomplexity [16, 10, 2, 35].\\n\\nLet Dc(f) and Qc(f) denote the communication re-\\nquired for optimal deterministic and quantum protocols for\\ncomputing f , respectively (we assume Alice and Bob do\\nnot share any prior entanglement). Let rank(f) be the\\n\\n1Unfortunately, the notation D(f) is used for deterministic complexity\\nin both the field of decision tree complexity and in communication com-\\nplexity. To avoid confusion, we will consistently add subscripts ‘q’ for\\nquery complexity and ‘c’ for communication complexity.\\n\\nrank of the 2n × 2n communication matrix Mf defined by\\nMf(x, y) = f(x, y). The following relations are known:\\n\\nlog rank(f)\\n\\n2\\n≤ Qc(f) ≤ Dc(f).\\n\\nThe first inequality follows from work of Kremer [29] and\\nYao [42], as first noted in [10] (in [12] it is shown that\\nthis lower bound also holds if the quantum protocol can\\nmake use of unlimited prior entanglement between Alice\\nand Bob). It is an open question whether Dc(f) can in\\nturn be upper bounded by some polynomial in log rank(f).\\nThis is known as the log-rank conjecture. If this conjec-\\nture holds, then Dc(f) and Qc(f) are polynomially related\\nfor all total f (which may well be true). It is known that\\nlog rank(f) and Dc(f) are not linearly related [34]. In\\nSection 4 we show that the non-deterministic versions of\\nlog rank(f) and Qc(f) are in fact linearly related:\\n\\nlog nrank(f)\\n\\n2\\n≤ NQc(f) ≤ log nrank(f) ≤ Nc(f).\\n\\nHere nrank(f) denotes the minimal rank of a matrix whose\\n(x, y)-entry is non-zero iff f(x, y) = 1. Thus we can\\ncharacterize the non-deterministic quantum communica-\\ntion complexity as the logarithm of the rank of its non-\\ndeterministic matrix. Two other log-rank-style characteri-\\nzations of certain variants of communication complexity are\\nknown: the communication complexity of quantum sam-\\npling [2] and modular communication complexity [31].\\n\\nWe also show an exponential gap between quantum and\\nclassical non-deterministic communication complexity: we\\nexhibit an f where NQc(f) ≤ log(n + 1) and Nc(f) ∈\\nΩ(n). Cleve and Massar [18] earlier found another gap:\\nNQc(NE) = 1 versus Nc(NE) = log n + 1, where NE is\\nthe non-equality function.\\n\\n2 Preliminaries\\n\\n2.1 Functions and polynomials\\n\\nFor x ∈ {0, 1}n we use |x| for the Hamming weight\\n(number of 1s) of x, and xi for its ith bit, i ∈ {1, . . . , n}.\\nWe use~0 for a string of n zeroes. If x, y ∈ {0, 1}n then x∧y\\ndenotes the n-bit string obtained by bitwise ANDing x and\\ny. Let f : {0, 1}n → {0, 1} be a total Boolean function.\\nFor example, OR(x) = 1 iff |x| ≥ 1, AND(x) = 1 iff\\n|x| = n, PARITY(x) = 1 iff |x| is odd. We use f for the\\nfunction 1 − f .\\n\\nFor b ∈ {0, 1}, a b-certificate for f is an assignment\\nC : S → {0, 1} to some set S of variables, such that\\nf(x) = b whenever x is consistent with C. The size of\\nC is |S|. The certificate complexity Cx(f) of f on input\\nx is the minimal size of an f(x)-certificate that is consis-\\ntent with x. We define the 1-certificate complexity of f\\n\\n\\n\\nas C(1)(f) = maxx:f(x)=1 Cx(f). Similarly we define\\nC(0)(f). For example, C(1)(OR) = 1 and C(0)(OR) = n.\\n\\nAn n-variate multilinear polynomial is a function p :\\nR\\n\\nn → R which can be written as\\n\\np(x) =\\n∑\\n\\nS⊆{1,...,n}\\n\\naSXS .\\n\\nHere S ranges over all sets of indices of variables, aS is a\\nreal number, and the monomial XS is the product Πi∈Sxi\\n\\nof all variables in S. The degree deg(p) of p is the degree\\nof a largest monomial with non-zero coefficient. It is well\\nknown that every total Boolean f has a unique polynomial\\np such that p(x) = f(x) for all x ∈ {0, 1}n. Let deg(f)\\n',\n",
       "                'be the degree of this polynomial, which is at most n. For\\nexample, OR(x1, x2) = x1 + x2 − x1x2, which has degree\\n2. Every multilinear polynomial p =\\n\\n∑\\n\\nS aSXS can also\\nbe written out uniquely in the so-called Fourier basis:\\n\\np(x) =\\n∑\\n\\nS\\n\\ncS(−1)x·S.\\n\\nAgain S ranges over all sets of indices of variables (we often\\nidentify a set S with its characteristic n-bit vector), cS is a\\nreal number, and x ·S denotes the inner product of the n-bit\\nstrings x and S, equivalently x·S = |x∧S| =\\n\\n∑\\n\\ni∈S xi. It is\\neasy to see that deg(p) = max{|S| | cS 6= 0}. For example,\\nOR(x1, x2) = 3\\n\\n4 − 1\\n4 (−1)x1 − 1\\n\\n4 (−1)x2 − 1\\n4 (−1)x1+x2 in\\n\\nthe Fourier basis. We refer to [4, 33, 13] for more details\\nabout polynomial representations of Boolean functions.\\n\\nWe introduce the notion of a non-deterministic polyno-\\nmial for f . This is a polynomial p such that p(x) 6= 0\\niff f(x) = 1. Let the non-deterministic degree of f , de-\\nnoted ndeg(f), be the minimum degree among all non-\\ndeterministic polynomials p for f . Without loss of gener-\\nality we can assume p(x) ∈ [−1, 1] for all x ∈ {0, 1}n (if\\nnot, just divide by maxx |p(x)|).\\n\\nWe mention some upper and lower bounds for ndeg(f).\\nFor example, p(x) =\\n\\n∑\\n\\ni xi/n is a non-deterministic poly-\\nnomial for OR, hence ndeg(OR) = 1. More generally, let\\nf be a non-constant symmetric function (i.e. f(x) only de-\\npends on |x|). Suppose f achieves value 0 on z Hamming\\nweights, k1, . . . , kz . Since |x| =\\n\\n∑\\n\\ni xi, it is easy to see\\nthat (|x|−k1)(|x|−k2) · · · (|x|−kz) is a non-deterministic\\npolynomial for f , hence ndeg(f) ≤ z. This upper bound\\nis tight for AND (see below) but not for PARITY. For ex-\\nample, p(x1, x2) = x1 −x2 is a degree-1 non-deterministic\\npolynomial for PARITY on 2 variables: it assumes value\\n0 on x-weights 0 and 2, and ±1 on weight 1. Using\\nstandard symmetrization techniques (as used for instance\\nin [32, 33, 3]) we can also show the general lower bound\\nndeg(f) ≥ z/2 for symmetric f . Furthermore, it is easy to\\nshow that ndeg(f) ≤ C(1)(f) for every f (take a polyno-\\nmial which is the “sum” over all 1-certificates for f ).\\n\\nFinally, we mention a general lower bound on ndeg(f).\\nLet Pr[p 6= 0] = |{x ∈ {0, 1}n | p(x) 6= 0}|/2n denote the\\nprobability that a random Boolean input x makes a func-\\ntion p non-zero. A lemma of Schwartz [37] (see also [33,\\nSection 2.2]) states that if p is a non-constant multilinear\\npolynomial of degree d, then Pr[p 6= 0] ≥ 2−d, hence\\nd ≥ log(1/ Pr[p 6= 0]). Since a non-deterministic poly-\\nnomial p for f is non-zero iff f(x) = 1, it follows that\\n\\nndeg(f) ≥ log(1/ Pr[f 6= 0]) = log(1/ Pr[f = 1]).\\n\\nAccordingly, functions with a very small fraction of 1-\\ninputs will have high non-deterministic degree. For in-\\nstance, Pr[AND = 1] = 2−n, so ndeg(AND) = n.\\n\\n2.2 Query complexity\\n\\nWe assume familiarity with classical computation and\\nbriefly sketch the setting of quantum computation (see\\ne.g. [5, 27, 14] for more details). An m-qubit state is a\\nlinear combination of all classical m-bit states\\n\\n|φ〉 =\\n∑\\n\\ni∈{0,1}m\\n\\nαi|i〉,\\n\\nwhere |i〉 denotes the basis state i (a classical m-bit string),\\nand αi is a complex number which is called the amplitude\\nof |i〉. We require\\n\\n∑\\n\\ni |αi|\\n2 = 1. Viewing |φ〉 as a 2m-\\n\\ndimensional column vector, we use 〈φ| for the row vector\\nwhich is the conjugate transpose of |φ〉. Note that the inner\\nproduct 〈i||j〉 is 1 if i = j and is 0 otherwise. When we ob-\\nserve |φ〉 we will see |i〉 with probability |〈i||φ〉|2 = |αi|\\n\\n2,\\nand the state will collapse to the observed |i〉. A quan-\\ntum operation which is not an observation, corresponds to\\na unitary (=norm-preserving) transformation U on the 2m-\\ndimensional vector of amplitudes.\\n\\nFor some input x ∈ {0, 1}n, a query corresponds\\nto the unitary transformation O which maps |i, b, z〉 →\\n|i, b ⊕ xi, z〉. Here b ∈ {0, 1}; the z-part corresponds\\nto the workspace, which is not affected by the query.\\nWe assume that the input can only be accessed via such\\nqueries. A T -query quantum algorithm has the form A =\\nUT OUT−1 . . . OU1OU0, where the Uk are fixed unitary\\ntransformations, independent of the input x. This A de-\\npends on x via the T applications of O. We sometimes\\nwrite Ax to emphasize this. The algorithm starts in initial\\nstate |~0〉 and its output is the bit obtained from observing\\nthe leftmost qubit of the final superposition A|~0〉. The ac-\\nceptance probability of A (on input x) is its probability of\\noutputting 1 (on x).\\n\\nWe will consider classical and quantum algorithms, and\\nwill only count the number of queries these algorithms\\nmake on the worst-case input (see [3, 13] for more details).\\nLet Dq(f) and Qq(f) be the query complexities of optimal\\n\\n\\n\\ndeterministic classical and quantum algorithms for comput-\\ning f , respectively. Dq(f) is also known as the decision tree\\ncomplexity of f . A non-deterministic algorithm for f is an\\nalgorithm that has positive acceptance probability on input\\nx iff f(x) = 1. Let Nq(f) and NQq(f) be the query com-\\nplexities of optimal non-deterministic classical and quan-\\n',\n",
       "                'tum algorithms for f , respectively (in the appendix we show\\nthat this definition of NQq(f) is at least as powerful as the\\nother possible definitions).\\n\\nThe 1-certificate complexity characterizes the classical\\nnon-deterministic complexity of f :\\n\\nProposition 1 Nq(f) = C(1)(f).\\n\\nProof\\nNq(f) ≤ C\\n\\n(1)(f): a classical algorithm that guesses\\na 1-certificate, queries its variables, and outputs 1 iff the\\ncertificate holds, is a non-deterministic algorithm for f .\\n\\nNq(f) ≥ C\\n(1)(f): a non-deterministic algorithm for f\\n\\ncan only output 1 if the outcomes of the queries that it has\\nmade force the function to 1. Hence if x is an input where\\nall 1-certificates have size at least C(1)(f), then the algo-\\nrithm will have to query at least C(1)(f) variables before it\\ncan output 1 (which it must do on some runs). ✷\\n\\nIn Section 3 we will characterize NQq(f) in terms of\\nndeg(f), using the following result from [3].\\n\\nLemma 1 (BBCMW) The amplitudes of the basis states in\\nthe final superposition of a T -query quantum algorithm can\\nbe written as multilinear complex-valued polynomials of de-\\ngree ≤ T in the n xi-variables. Therefore the acceptance\\nprobability of the algorithm (which is the sum of squares of\\nsome of those amplitudes) can be written as an n-variate\\nmultilinear polynomial P (x) of degree ≤ 2T .\\n\\n2.3 Communication complexity\\n\\nBelow we sketch the setting of communication complex-\\nity. For more details and results we refer to the book of\\nKushilevitz and Nisan [30].\\n\\nLet f : {0, 1}n × {0, 1}n → {0, 1}. For example,\\nEQ(x, y) = 1 iff x = y, NE(x, y) = 1 iff x 6= y,\\nDISJ(x, y) = 1 iff |x ∧ y| = 0. A rectangle is a subset\\nR = S × T of the domain of f . R is a 1-rectangle (for f )\\nif f(x, y) = 1 for all (x, y) ∈ R. A 1-cover for f is a set of\\n1-rectangles which covers all 1-inputs of f . C1(f) denotes\\nthe minimal size (i.e. minimal number of rectangles) of a 1-\\ncover for f . Similarly we define 0-rectangles, 0-covers, and\\nC0(f). (These C1(f) and C0(f) should not be confused\\nwith the certificate complexities C(1)(f) and C(0)(f).)\\n\\nThe communication matrix Mf of f is the 2n × 2n\\n\\nBoolean matrix whose x, y entry is f(x, y), and rank(f)\\ndenotes the rank of Mf over the reals. An 2n × 2n matrix\\n\\nM is called a non-deterministic communication matrix for\\nf if it has the property that M(x, y) 6= 0 iff f(x, y) = 1.\\nThus M is any matrix obtainable by replacing 1-entries in\\nMf by non-zero reals. Let the non-deterministic rank of\\nf , denoted nrank(f), be the minimum rank over all non-\\ndeterministic matrices M for f . Without loss of generality\\nwe can assume all M -entries are in [−1, 1].\\n\\nWe consider classical and quantum communication pro-\\ntocols, and only count the amount of communication (bits\\nor qubits) these protocols make on the worst-case input. For\\nclassical randomized protocols we assume Alice and Bob\\neach have their own private coin flips. Let Dc(f) and Qc(f)\\nbe the communication complexities of optimal determinis-\\ntic classical and quantum protocols for computing f , re-\\nspectively. A non-deterministic protocol for f is a protocol\\nthat has positive acceptance probability iff f(x, y) = 1. Let\\nNc(f) and NQc(f) be the communication complexities of\\noptimal non-deterministic classical and quantum protocols\\nfor f , respectively. Nc(f) is called N1(f) in [30].\\n\\nIt is not hard to show that Nc(f) = ⌈log C1(f)⌉. In Sec-\\ntion 4 we will characterize NQc(f) in terms of nrank(f).\\nAs noticed in [10], the following very useful lemma is im-\\nplied by results in [42, 29]:\\n\\nLemma 2 (Kremer/Yao) The acceptance probabilities of\\nan ℓ-qubit quantum communication protocol can be written\\nas a 2n × 2n matrix P (x, y) of rank ≤ 22ℓ.\\n\\n3 Non-deterministic quantum query com-\\nplexity\\n\\nHere we show a tight relation between non-deterministic\\nquantum query complexity NQq(f) and non-deterministic\\ndegree ndeg(f). The upper bound uses a trick similar to the\\none used in [21] to show co-C=P ⊆ quantum-NP.\\n\\nTheorem 1\\nndeg(f)\\n\\n2\\n≤ NQq(f) ≤ ndeg(f).\\n\\nProof Suppose we have an NQq(f)-query non-\\ndeterministic quantum algorithm A for f . By Lemma 1, its\\nacceptance probability can be written as a polynomial P (x)\\nof degree ≤ 2NQq(f). Because A is a non-deterministic\\nalgorithm for f , P (x) is a non-deterministic polynomial for\\nf . Hence ndeg(f) ≤ 2NQq(f).\\n\\nFor the upper bound: let p(x) be a non-deterministic\\npolynomial for f of degree d = ndeg(f). Recall that x · S\\ndenotes |x ∧ S|, identifying S ⊆ {1, . . . , n} with its char-\\nacteristic n-bit vector. We write p in the Fourier basis:\\n\\np(x) =\\n∑\\n\\nS\\n\\ncS(−1)x·S.\\n\\nSince deg(p) = max{|S| | cs 6= 0}, we have that cS 6= 0\\nonly if |S| ≤ d.\\n\\n\\n\\nWe can make a unitary transformation F which uses d\\nqueries and maps |S〉 → (−1)x·S|S〉 whenever |S| ≤ d.\\nInformally, this transformation does a controlled parity-\\ncomputation: it computes |x · S| (mod 2) using |S|/2\\nqueries [3, 20] and then reverses the computation to clean\\nup the workspace (at the cost of another |S|/2 queries). By\\na standard trick, the answer |x · S| (mod 2) can then be\\n',\n",
       "                'turned into a phase factor (−1)|x·S| (mod 2) = (−1)x·S .\\n\\nNow consider the following quantum algorithm:\\n\\n1. Start with c\\n∑\\n\\nS cS |S〉 (an n-qubit state, where c =\\n\\n1/\\n√\\n∑\\n\\nS c2\\nS is a normalizing constant)\\n\\n2. Apply F to the state\\n\\n3. Apply a Hadamard transform H to each qubit\\n\\n4. Measure the final state and output 1 if the outcome is\\nthe all-zero state |~0〉 and output 0 otherwise.\\n\\nThe acceptance probability (i.e. the probability of observing\\n|~0〉 at the end) is\\n\\nP (x) = |〈~0|H⊗nFc\\n∑\\n\\nS\\n\\ncS |S〉|\\n2\\n\\n=\\nc2\\n\\n2n\\n|\\n∑\\n\\nS′\\n\\n〈S′|\\n∑\\n\\nS\\n\\ncS(−1)x·S|S〉|2\\n\\n=\\nc2\\n\\n2n\\n|\\n∑\\n\\nS\\n\\ncS(−1)x·S|2 =\\nc2p(x)2\\n\\n2n\\n.\\n\\nSince p(x) is non-zero iff f(x) = 1, P (x) will be positive\\niff f(x) = 1. Hence we have a non-deterministic quantum\\nalgorithm for f with d = ndeg(f) queries. ✷\\n\\nThe upper bound in this theorem is tight: by a proof\\nsimilar to [3, Proposition 6.1] we can show NQq(AND) =\\nndeg(AND) = n. We do not know if the factor of 2 in the\\nlower bound can be dispensed with. If we were to change\\nthe output requirement of the quantum algorithm a little bit,\\nby saying that the algorithm accepts iff measuring the final\\nsuperposition gives basis state |~0〉, then the required number\\nof queries is exactly ndeg(f). The upper bound of ndeg(f)\\nqueries in this changed model is the same as above. The\\nlower bound of ndeg(f) queries follows since the ampli-\\ntude of the basis state |~0〉 in the final superposition must\\nnow be non-zero iff f(x) = 1, and this polynomial has de-\\ngree at most the number of queries (Lemma 1).\\n\\nWhat is the biggest possible gap between quantum and\\nclassical non-deterministic query complexity? Consider the\\nBoolean function f defined by\\n\\nf(x) = 1 iff |x| 6= 1.\\n\\nIt is easy to see that Nq(f) = C(1)(f) = C(0)(f) =\\nn. On the other hand, the following is a degree-1 non-\\ndeterministic polynomial for f :\\n\\np(x) =\\n\\n∑\\n\\ni xi − 1\\n\\nn − 1\\n. (1)\\n\\nThus ndeg(f) = 1 and by Theorem 1 we have NQq(f) =\\n1. For the complement of f , we can easily show NQq(f) ≥\\nn/2 using Lemma 1, since the acceptance probability of a\\nnon-deterministic algorithm for f must be 0 on n Hamming\\nweights and hence have degree at least n (this NQq(f) ≥\\nn/2 is tight for n = 2, witness p(x) = x1 − x2). In sum:\\n\\nTheorem 2 For the above f we have NQq(f) = 1,\\nNQq(f) ≥ n/2 and Nq(f) = Nq(f) = n.\\n\\nA slightly smaller gap holds for the function defined by\\nDeJo(x) = 1 iff |x| 6= n/2. This is a total version of the\\nwell known Deutsch-Jozsa promise problem [19]. The al-\\ngorithm of [19] (in its 1-query version [17]) turns out to be a\\nnon-deterministic algorithm for DeJo, so NQq(DeJo) = 1.\\nIn contrast, Nq(DeJo) = C(1)(DeJo) = n/2 + 1.\\n\\n4 Non-deterministic quantum communica-\\ntion complexity\\n\\nHere we characterize the non-deterministic quantum\\ncommunication complexity NQc(f) in terms of the non-\\ndeterministic rank nrank(f):\\n\\nTheorem 3 log nrank(f)\\n2 ≤ NQc(f) ≤ ⌈log nrank(f)⌉.\\n\\nProof Consider an NQc(f)-qubit non-deterministic quan-\\ntum protocol for f . By Lemma 2, its acceptance probability\\nP (x, y) determines a matrix of rank ≤ 22NQc(f). It is easy\\nto see that this is a non-deterministic matrix for f , hence\\nnrank(f) ≤ 22NQc(f) and the first inequality follows.\\n\\nFor the upper bound, let r = nrank(f) and M be a rank-\\nr non-deterministic matrix for f . Let MT = UΣV be the\\nsingular value decomposition of MT (see [25, Chapter 3]),\\nso U and V are unitary, and Σ is a diagonal matrix whose\\nfirst r diagonal entries are positive real numbers and whose\\nother diagonal entries are 0. Below we describe a 1-round\\nnon-deterministic protocol for f , using ⌈log r⌉ qubits. First\\nAlice prepares the vector |φx〉 = cxΣV |x〉, where cx > 0 is\\na normalizing real number that depends on x. Because only\\nthe first r diagonal entries of Σ are non-zero, only the first r\\namplitudes of |φx〉 are non-zero, so |φx〉 can be compressed\\ninto ⌈log r⌉ qubits. Alice sends these qubits to Bob. Bob\\nthen applies U to |φx〉 and measures the resulting state. If\\nhe observes |y〉 then he outputs 1, otherwise he outputs 0.\\nThe acceptance probability of this protocol is\\n\\nP (x, y) = |〈y|U |φx〉|\\n2 = c2\\n\\nx|〈y|UΣV |x〉|2\\n\\n= c2\\nx|M\\n\\nT (y, x)|2 = c2\\nx|M(x, y)|2.\\n\\n\\n\\nSince M(x, y) is non-zero iff f(x, y) = 1, P (x, y) will be\\npositive iff f(x, y) = 1. Thus we have a non-deterministic\\nprotocol for f with ⌈log r⌉ qubits. ✷\\n\\nThus classically we have Nc(f) = ⌈log C1(f)⌉ and\\nquantumly we have NQc(f) ≈ log nrank(f). We now\\ngive an f with an exponential gap between Nc(f) and\\nNQc(f). For n > 1, define f by\\n\\nf(x, y) = 1 iff |x ∧ y| 6= 1.\\n\\nWe first show that the quantum complexity NQc(f) is low:\\n\\nTheorem 4 For the above f we have NQc(f) ≤\\n⌈log(n + 1)⌉.\\n\\nProof By Theorem 3, it suffices to prove nrank(f) ≤ n +\\n1. We will derive a low-rank non-deterministic matrix from\\nthe polynomial p of equation 1, using a technique from [34].\\nLet Mi be the matrix defined by Mi(x, y) = 1 if xi = yi =\\n1, and Mi(x, y) = 0 otherwise. Notice that Mi has rank 1.\\nNow define a 2n × 2n matrix M by\\n\\nM(x, y) =\\n\\n∑\\n\\ni Mi(x, y) − 1\\n\\nn − 1\\n.\\n\\nNote that M(x, y) = p(x ∧ y). Since p is a non-\\n',\n",
       "                'deterministic polynomial for the function which is 1 iff its\\ninput does not have weight 1, it can be seen that M is a non-\\ndeterministic matrix for f . Because M is the sum of n + 1\\nrank-1 matrices, M itself has rank at most n + 1. ✷\\n\\nNow we show that the classical Nc(f) is high (both for\\nf and its complement):\\n\\nTheorem 5 For the above f we have Nc(f) ∈ Ω(n) and\\nNc(f) ≥ n − 1.\\n\\nProof Let R1, . . . , Rk be a minimal 1-cover for f . We\\nuse the following result from [30, Example 3.22 and Sec-\\ntion 4.6], which is essentially due to Razborov [36].\\n\\nThere exist sets A, B ⊆ {0, 1}n × {0, 1}n and a\\nprobability distribution µ : {0, 1}n × {0, 1}n →\\n[0, 1] such that all (x, y) ∈ A have |x ∧ y| = 0,\\nall (x, y) ∈ B have |x∧y| = 1, µ(A) = 3/4, and\\nthere are α, δ > 0 such that for all rectangles R,\\nµ(R ∩ B) ≥ α · µ(R ∩ A) − 2−δn.\\n\\nSince the Ri are 1-rectangles, they cannot contain elements\\nfrom B. Hence µ(Ri ∩ B) = 0 and µ(Ri ∩ A) ≤ 2−δn/α.\\nBut since all elements of A are covered by the Ri we have\\n\\n3\\n\\n4\\n= µ(A) = µ\\n\\n(\\n\\nk\\n⋃\\n\\ni=1\\n\\n(Ri ∩ A)\\n\\n)\\n\\n≤\\n\\nk\\n∑\\n\\ni=1\\n\\nµ(Ri∩A) ≤ k·\\n2−δn\\n\\nα\\n.\\n\\nTherefore Nc(f) = ⌈log k⌉ ≥ δn + log(3α/4).\\nFor the lower bound on Nc(f), consider the set S =\\n\\n{(x, y) | x1 = y1 = 1, xi = yi for i > 1}. This S contains\\n2n−1 elements, all of which are 1-inputs for f . Note that if\\n(x, y) and (x′, y′) are two elements from S then |x∧y′| > 1\\nor |x′ ∧ y| > 1, so a 1-rectangle for f can contain at most\\none element of S. This shows that a minimal 1-cover for f\\nrequires at least 2n−1 rectangles and Nc(f) ≥ n − 1. ✷\\n\\nAnother quantum-classical separation was obtained ear-\\nlier by Richard Cleve and Serge Massar [18]:\\n\\nTheorem 6 (Cleve & Massar) For the non-equality prob-\\nlem on n bits, we have NQc(NE) = 1 versus Nc(NE) =\\nlog n + 1.\\n\\nProof Nc(NE) = log n + 1 is well known (see [30, Ex-\\nample 2.5]). Below we give Cleve and Massar’s 1-qubit\\nnon-deterministic protocol for NE.\\n\\nViewing her input x as a number ∈ [0, 2n − 1], Alice\\nrotates a |0〉-qubit over an angle xπ/2n, obtaining a qubit\\ncos(xπ/2n)|0〉 + sin(xπ/2n)|1〉 which she sends to Bob.\\nBob rotates the qubit back over an angle yπ/2n, obtaining\\ncos((x−y)π/2n)|0〉+sin((x−y)π/2n)|1〉. Bob now mea-\\nsures the qubit and outputs the observed bit. If x = y then\\nsin((x − y)π/2n) = 0, so Bob will always output 0. If\\nx 6= y then sin((x − y)π/2n) 6= 0, so Bob will output 1\\nwith positive probability. ✷\\n\\nNote that nrank(EQ) = 2n, since any non-deterministic\\nmatrix for equality will be a diagonal 2n × 2n ma-\\ntrix with non-zero diagonal entries. Thus NQc(EQ) ≥\\n(log nrank(EQ))/2 = n/2, which contrasts sharply with\\nthe non-deterministic quantum complexity NQc(NE) = 1\\nof its complement.\\n\\n5 Future work\\n\\nOne of the main reasons for the usefulness of non-\\ndeterministic query and communication complexities in the\\nclassical case, is the tight relation of these complexities with\\ndeterministic complexity. In the query complexity (decision\\ntree) setting we have\\n\\nmax{Nq(f), Nq(f)} ≤ Dq(f) ≤ Nq(f)Nq(f).\\n\\nThis was independently shown in [6, 24, 40]. We conjecture\\nthat something similar holds in the quantum case:\\n\\nmax\\n\\n{\\n\\nndeg(f)\\n\\n2\\n,\\nndeg(f)\\n\\n2\\n\\n}\\n\\n≤\\ndeg(f)\\n\\n2\\n≤ Qq(f) ≤ Dq(f)\\n\\n?\\n≤ O(NQq(f)NQq(f)) = O(ndeg(f)ndeg(f)).\\n\\n\\n\\nHere the ?-part is open. This conjecture would imply\\nDq(f) ∈ O(Q0(f)2) (Q0(f) is zero-error quantum query\\ncomplexity; the quadratic relation would be close to opti-\\nmal [11]). It would also imply Dq(f) ∈ O(deg(f)2), which\\nis again close to optimal [33]. The currently best known re-\\nlations have a fourth power instead of a square.\\n\\nSimilarly, for communication complexity the following\\nis known [30, Section 2.11]:\\n\\nmax{Nc(f), Nc(f)} ≤ Dc(f) ≤ O(Nc(f)Nc(f)).\\n\\nAn analogous result might be true for quantum, but we have\\nbeen unable to prove it.\\n\\nAcknowledgments. I thank Harry Buhrman, Richard\\nCleve, Wim van Dam, and John Watrous for useful discus-\\nsions and pointers to the literature.\\n\\nReferences\\n\\n[1] L. M. Adleman, J. Demarrais, and M. A. Huang. Quantum\\ncomputability. SIAM Journal on Computing, 26(5):1524–\\n1540, 1997.\\n\\n[2] A. Ambainis, L. Schulman, A. Ta-Shma, U. Vazirani, and\\nA. Wigderson. The quantum communication complexity of\\nsampling. In Proceedings of 39th FOCS, pages 342–351,\\n1998.\\n\\n[3] R. Beals, H. Buhrman, R. Cleve, M. Mosca, and R. de Wolf.\\nQuantum lower bounds by polynomials. In Proceedings of\\n39th FOCS, pages 352–361, 1998. quant-ph/9802049.\\n\\n[4] R. Beigel. The polynomial method in circuit complexity. In\\nProceedings of the 8th IEEE Structure in Complexity Theory\\nConference, pages 82–95, 1993.\\n\\n[5] A. Berthiaume. Quantum computation. In A. Selman and\\nL. Hemaspaandra, editors, Complexity Theory Retrospective\\nII, pages 23–51. Springer, 1997.\\n\\n[6] M. Blum and R. Impagliazzo. Generic oracles and oracle\\nclasses (extended abstract). In Proceedings of 28th FOCS,\\npages 118–126, 1987.\\n\\n[7] G. Brassard and P. Høyer. An exact quantum polynomial-\\ntime algorithm for Simon’s problem. In Proceedings of the\\n5th Israeli Symposium on Theory of Computing and Systems\\n(ISTCS’97), pages 12–23, 1997. ',\n",
       "                'quant-ph/9704027.\\n\\n[8] G. Brassard, P. Høyer, and A. Tapp. Quantum algorithm\\nfor the collision problem. ACM SIGACT News (Cryptology\\nColumn), 28:14–19, 1997. quant-ph/9705002.\\n\\n[9] G. Brassard, P. Høyer, and A. Tapp. Quantum counting.\\nIn Proceedings of 25th ICALP, volume 1443 of Lecture\\nNotes in Computer Science, pages 820–831. Springer, 1998.\\nquant-ph/9805082.\\n\\n[10] H. Buhrman, R. Cleve, and A. Wigderson. Quantum vs.\\nclassical communication and computation (preliminary ver-\\nsion). In Proceedings of 30th STOC, pages 63–68, 1998.\\nquant-ph/9802040.\\n\\n[11] H. Buhrman, R. Cleve, R. de Wolf, and C. Zalka. Bounds for\\nsmall-error and zero-error quantum algorithms. In Proceed-\\nings of 40th FOCS, pages 358–368, 1999. cs.CC/9904019.\\n\\n[12] H. Buhrman and R. de Wolf. Communication complexity\\nlower bounds by polynomials. cs.CC/9910010, 1999.\\n\\n[13] H. Buhrman and R. de Wolf. Complexity measures and de-\\ncision tree complexity: A survey. Submitted. Available at\\nhttp://www.cwi.nl/∼rdewolf, 1999.\\n\\n[14] R. Cleve. An introduction to quantum complexity theory.\\nquant-ph/9906111, 28 Jun 1999.\\n\\n[15] R. Cleve. The query complexity of order-finding. quant-\\nph/9911124, 30 Nov 1999.\\n\\n[16] R. Cleve and H. Buhrman. Substituting quantum entangle-\\nment for communication. Physical Review A, 56(2):1201–\\n1204, 1997. quant-ph/9704026.\\n\\n[17] R. Cleve, A. Ekert, C. Macchiavello, and M. Mosca. Quan-\\ntum algorithms revisited. In Proceedings of the Royal Soci-\\nety of London, volume A454, pages 339–354, 1998. quant-\\nph/9708016.\\n\\n[18] R. Cleve and S. Massar. Paper in preparation, 1999.\\n[19] D. Deutsch and R. Jozsa. Rapid solution of problems by\\n\\nquantum computation. In Proceedings of the Royal Society\\nof London, volume A439, pages 553–558, 1992.\\n\\n[20] E. Farhi, J. Goldstone, S. Gutmann, and M. Sipser. A limit\\non the speed of quantum computation in determining par-\\nity. Physical Review Letters, 81:5442–5444, 1998. quant-\\nph/9802045.\\n\\n[21] S. Fenner, F. Green, S. Homer, and R. Pruim. Determining\\nacceptance possibility for a quantum computation is hard for\\nthe polynomial hierarchy. In Proceedings of the 6th Italian\\nConference on Theoretical Computer Science, pages 241–\\n252, 1998. quant-ph/9812056.\\n\\n[22] L. Fortnow and J. Rogers. Complexity limitations on quan-\\ntum computation. Journal of Computer and Systems Sci-\\nences, 59(2):240–252, 1999. Earlier version in Complex-\\nity’98. Also cs.CC/9811023.\\n\\n[23] L. K. Grover. A fast quantum mechanical algorithm for\\ndatabase search. In Proceedings of 28th STOC, pages 212–\\n219, 1996. quant-ph/9605043.\\n\\n[24] J. Hartmanis and L. Hemachandra. One-way functions, ro-\\nbustness and the non-isomorphism of NP-complete sets. In\\nProceedings of the 2nd IEEE Structure in Complexity The-\\nory Conference, pages 160–174, 1987.\\n\\n[25] R. A. Horn and C. R. Johnson. Topics in Matrix Analysis.\\nCambridge University Press, 1991.\\n\\n[26] A. Kitaev and J. Watrous. Parallelization, amplification, and\\nexponential time simulation of quantum interactive proof\\nsystems. In Proceedings of 32nd STOC, 2000. To appear.\\n\\n[27] A. Y. Kitaev. Quantum computations: Algorithms and er-\\nror correction. Russian Mathematical Surveys, 52(6):1191–\\n1249, 1997.\\n\\n[28] A. Y. Kitaev. Quantum NP, January 1999. Talk given at\\nAQIP’99, DePaul University, Chicago.\\n\\n[29] I. Kremer. Quantum communication. Master’s thesis, He-\\nbrew University, Computer Science Department, 1995.\\n\\n[30] E. Kushilevitz and N. Nisan. Communication Complexity.\\nCambridge University Press, 1997.\\n\\n[31] C. Meinel and S. Waack. The “log rank” conjecture for mod-\\nular communication complexity. In Proceedings of 13th An-\\nnual Symposium on Theoretical Aspects of Computer Sci-\\nence (STACS’96), volume 1046 of Lecture Notes in Com-\\nputer Science, pages 619–630. Springer, 1996.\\n\\nhttp://arxiv.org/abs/quant-ph/9802049\\nhttp://arxiv.org/abs/quant-ph/9704027\\nhttp://arxiv.org/abs/quant-ph/9705002\\nhttp://arxiv.org/abs/quant-ph/9805082\\nhttp://arxiv.org/abs/quant-ph/9802040\\nhttp://arxiv.org/abs/cs/9904019\\nhttp://arxiv.org/abs/cs/9910010\\nhttp://www.cwi.nl/~rdewolf\\nhttp://arxiv.org/abs/quant-ph/9906111\\nhttp://arxiv.org/abs/quant-ph/9911124\\nhttp://arxiv.org/abs/quant-ph/9704026\\nhttp://arxiv.org/abs/quant-ph/9708016\\nhttp://arxiv.org/abs/quant-ph/9802045\\nhttp://arxiv.org/abs/quant-ph/9812056\\nhttp://arxiv.org/abs/cs/9811023\\nhttp://arxiv.org/abs/quant-ph/9605043\\n\\n\\n[32] M. Minsky and S. Papert. Perceptrons. MIT Press, Cam-\\nbridge, MA, 1968. Second, expanded edition 1988.\\n\\n[33] N. Nisan and M. Szegedy. On the degree of Boolean\\nfunctions as real polynomials. Computational Complexity,\\n4(4):301–313, 1994. Earlier version in STOC’92.\\n\\n[34] N. Nisan and A. Wigderson. On rank vs. communication\\ncomplexity. Combinatorica, 15(4):557–565, 1995. Earlier\\nversion in FOCS’94.\\n\\n[35] R. Raz. Exponential separation of quantum and classical\\ncommunication complexity. In Proceedings of 31st STOC,\\npages 358–367, 1999.\\n\\n[36] A. Razborov. On the distributional complexity of disjoint-\\nness. Theoretical Computer Science, 106(2):385–390, 1992.\\n\\n',\n",
       "                '[37] J. T. Schwartz. Fast probabilistic algorithms for verification\\nof polynomial identities. Journal of the ACM, 27:701–717,\\n1980.\\n\\n[38] P. W. Shor. Polynomial-time algorithms for prime factoriza-\\ntion and discrete logarithms on a quantum computer. SIAM\\nJournal on Computing, 26(5):1484–1509, 1997. Earlier ver-\\nsion in FOCS’94. quant-ph/9508027.\\n\\n[39] D. Simon. On the power of quantum computation. SIAM\\nJournal on Computing, 26(5):1474–1483, 1997. Earlier ver-\\nsion in FOCS’94.\\n\\n[40] G. Tardos. Query complexity, or why is it difficult to sepa-\\nrate NP\\n\\nA\\n∩ coNP\\n\\nA from P\\nA by random oracles A? Com-\\n\\nbinatorica, 9(4):385–392, 1989.\\n[41] A. C.-C. Yao. Some complexity questions related to dis-\\n\\ntributive computing. In Proceedings of 11th STOC, pages\\n209–213, 1979.\\n\\n[42] A. C.-C. Yao. Quantum circuit complexity. In Proceedings\\nof 34th FOCS, pages 352–360, 1993.\\n\\nA Comparison with alternative definitions\\n\\nAs mentioned in the introduction, three different defi-\\nnitions of non-deterministic quantum complexity are pos-\\nsible. We may consider the complexity of quantum algo-\\nrithms which either:\\n\\n1. output 1 iff given an appropriate classical certificate\\n(such certificates must exist iff f(x) = 1)\\n\\n2. output 1 iff given an appropriate quantum certificate\\n(such certificates must exist iff f(x) = 1)\\n\\n3. output 1 with positive probability iff f(x) = 1\\n\\nThe third definition is the one we adopted for this paper.\\nClearly the second definition is at least as strong as the\\nfirst. Here we will show that the third definition is at least\\nas strong as the second. (We give the proof for the query\\ncomplexity setting, but the same proof works for communi-\\ncation complexity and other non-uniform settings as well.)\\nThus our NQq(f) is in fact the most powerful definition of\\nnon-deterministic quantum query complexity.\\n\\nWe formalize the second definition as follows: a T -query\\nquantum verifier for f is a T -query quantum algorithm V\\n\\ntogether with a set C of m-qubit states, such that for all\\nx ∈ {0, 1}n we have: (1) if f(x) = 1 then there is a\\n|φx〉 ∈ C such that Vx|φx〉 has acceptance probability 1,\\nand (2) if f(x) = 0 then Vx|φ〉 has acceptance probabil-\\nity 0 for every |φ〉 ∈ C. Informally: the set C contains all\\npossible certificates, (1) for every 1-input there is a verifi-\\nable 1-certificate in C, and (2) for 0-inputs there aren’t any.\\nWe do not put any constraints on C. However, note that the\\ndefinition implies that if f(x) = 0 for some x, then C can-\\nnot contain all m-qubit states: otherwise |φx〉 = V −1\\n\\nx |1~0〉\\nwould be a 1-certificate in C even for x with f(x) = 0.\\n\\nWe now prove that a T -query quantum verifier can be\\nturned into a T -query non-deterministic quantum algorithm\\naccording to our third definition. This shows that the third\\ndefinition is at least as powerful as the second (in fact, this\\neven holds if we replace the acceptance probability 1 in\\nclause (1) of the definition of a quantum verifier by just pos-\\nitive acceptance probability — in this case both definitions\\nare equivalent).\\n\\nTheorem 7 Suppose there exists a T -query quantum veri-\\nfier V for f . Then NQq(f) ≤ T .\\n\\nProof The verifier V and the associated set C satisfy:\\n\\n1. if f(x) = 1 then there is a |φx〉 ∈ C such that Vx|φx〉\\nhas acceptance probability 1\\n\\n2. if f(x) = 0 then Vx|φ〉 has acceptance probability 0\\nfor all |φ〉 ∈ C\\n\\nLet X1 = {z | f(z) = 1}. For each z ∈ X1 choose one\\nspecific 1-certificate |φz〉 ∈ C. Now let us consider some\\ninput x and see what happens if we run Vx ⊗ I (where I is\\nthe 2n × 2n identity operation) on the m + n-qubit state\\n\\n|φ〉 =\\n1\\n\\n√\\n\\n|X1|\\n\\n∑\\n\\nz∈X1\\n\\n|φz〉|z〉.\\n\\nVx only acts on the first m qubits of |φ〉, the |z〉-part re-\\nmains unaffected. Therefore running Vx⊗I on |φ〉 gives the\\nsame acceptance probabilities as when we first randomly\\nchoose some z ∈ X1 and then apply Vx to |φz〉. In case\\nf(x) = 0, this Vx|φz〉 will have acceptance probability 0,\\nso (Vx ⊗ I)|φ〉 will have acceptance probability 0 as well.\\nIn case the input x is such that f(x) = 1, the specific certifi-\\ncate |φz〉 that we chose for this x will satisfy that Vx|φx〉 has\\nacceptance probability 1. But then (Vx ⊗ I)|φ〉 has accep-\\ntance probability at least 1/|X1|. Accordingly, (Vx ⊗ I)|φ〉\\nhas positive acceptance probability iff f(x) = 1. By pre-\\nfixing Vx ⊗ I with a unitary transformation which maps\\n|~0〉 (of m + n qubits) to |φ〉, we have constructed a non-\\ndeterministic quantum algorithm for f with T queries. ✷\\n\\nhttp://arxiv.org/abs/quant-ph/9508027\\n\\n'],\n",
       "               'language': 'en',\n",
       "               'score': 1.034313678741455,\n",
       "               'vectorized': True})])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the below line if you want to inspect the ordered results\n",
    "# ordered_results\n",
    "#len(ordered_results['aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDcwMS8wNzAxMDgydjEucGRm0']['chunks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "208f196d-4ec7-4a83-8394-6be467178a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDcwMS8wNzAxMDgydjEucGRm0 0701082v1.pdf 5\n",
      "aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMi8wMDEyMDE0djEucGRm0 0012014v1.pdf 9\n",
      "aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMS8wMDExMDMwdjEucGRm0 0011030v1.pdf 8\n",
      "aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDMxMC8wMzEwMDQydjEucGRm0 0310042v1.pdf 11\n",
      "5ed5k9tq metadata.csv 1\n",
      "vnmg0zid metadata.csv 1\n",
      "aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDA5djEucGRm0 0001009v1.pdf 11\n",
      "u2g30x1j metadata.csv 1\n",
      "5o38ihe0 metadata.csv 1\n",
      "4mnaicki metadata.csv 1\n",
      "gdsfkw1b metadata.csv 1\n",
      "t35n7bk9 metadata.csv 1\n",
      "wutnzzhg metadata.csv 1\n",
      "bbvxu8op metadata.csv 1\n",
      "2su7oqbz metadata.csv 1\n",
      "aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDE1djEucGRm0 0001015v1.pdf 20\n",
      "aHR0cHM6Ly9ibG9ic3RvcmFnZXloeXVmb3FoNnlqcjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDE0djIucGRm0 0001014v2.pdf 8\n"
     ]
    }
   ],
   "source": [
    "for OR in ordered_results:\n",
    "    print(OR, ordered_results[OR]['name'], len(ordered_results[OR]['chunks']))"
   ]
  },
  {
   "attachments": {
    "08672412-e456-4b5a-ac7c-00dfc2a276b4.png": {
     "image/png": "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"
    },
    "3239695b-7457-402b-b0ee-78f74bf450d4.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "da70e7a8-7536-4688-b30c-01ba28e9b9f8",
   "metadata": {},
   "source": [
    "# Notiamo che finora non abbiamo ancora calcolato gli embeddings: abbiamo solo spezzato in chunk\n",
    "## Adesso quindi possiamo partire da questo ordered_results per riempire il Vector Index di Azure Cognitive Search, calcolando \"al volo\" tutti i chunk e scrivendoli appunto in quell'indice *-vector*\n",
    "\n",
    "Now we can fill up the vector-based index as users lookup documents using the text-based index. This approach although it requires two searches per user query (one on the text-based indexes and the other one on the vector-based indexes), it is simpler to implement and will be incrementatly faster as user use the system.\n",
    "\n",
    "# How it works\n",
    "Per ciascuno dei documenti inseriti in *order_documents\", dove ogni documento include l'array di chunk, calcola l'embedding del chunk e lo inserisce, insieme al chunk stesso, all'interno del nuovo indice \"-vector\".<br/>\r\n",
    "Se per ragioni di test vogliamo resettare \"vectorize=false\" per evitare che \"salti\" i documenti già tracciati come vettorizzati, si può eseguire questo pezzo di codice\n",
    "```\n",
    "for key,value in ordered_results.items():\r\n",
    "    print(value[\"vectorized\"])\r\n",
    "    upload_payload = {        \r\n",
    "        \"value\": [\r\n",
    "            {\r\n",
    "                \"id\": key,\r\n",
    "                \"vectorized\": False,\r\n",
    "                \"@search.action\": \"merge\"\r\n",
    "            },\r\n",
    "        ]\r\n",
    "    }    \r\n",
    "\r\n",
    "    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + value[\"index\"]+ \"/docs/index\",\r\n",
    "                     data=json.dumps(upload_payload), headers=headers, params=params)\r\n",
    "\r\n",
    "ordered_results = get_search_results(QUESTION, indexes, k=10, reranke```\n",
    "\n",
    "Il payload è di questo tipo:\n",
    "```\n",
    "{\r\n",
    "  \"value\": [\r\n",
    "    {\r\n",
    "      \"id\": \"aHR0cHM6Ly9ibG9ic3RvcmFnZTV1Y3ptempiY3hkMnMuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAwMS8wMDAxMDE0djIucGRm0\",\r\n",
    "      \"vectorized\": \"False\",\r\n",
    "      \"@search.action\": \"merge\"\r\n",
    "    }\n",
    "\r\n",
    " \n",
    "\n",
    "Otteniamo i nuovi valori dove ogni documento è un chunk con relativo embedding:\n",
    "![image.png](attachment:3239695b-7457-402b-b0ee-78f74bf450d4.png)![image.png](attachment:08672412-e456-4b5a-ac7c-00dfc2a276b4.png) ]\r\n",
    "}```hreshold=1)\n",
    "''':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937ba3b-098d-43f8-8498-3534882a5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664df30-99c3-4a30-8cb0-42ba3044e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for key,value in ordered_results.items():\n",
    "    if value[\"vectorized\"] != True: # If the document has not been vectorized yet\n",
    "        i = 0\n",
    "        print(\"Vectorizing\",len(value[\"chunks\"]),\"chunks from Document:\",value[\"location\"])\n",
    "        for chunk in value[\"chunks\"]: # Iterate over the document's text chunks\n",
    "            try:\n",
    "                upload_payload = {  # Insert the chunk and its vector in the vector-based index\n",
    "                    \"value\": [\n",
    "                        {\n",
    "                            \"id\": key + \"_\" + str(i),\n",
    "                            \"title\": f\"{value['title']}_chunk_{str(i)}\",\n",
    "                            \"chunk\": chunk,\n",
    "                            \"chunkVector\": embedder.embed_query(chunk if chunk!=\"\" else \"-------\"),\n",
    "                            \"name\": value[\"name\"],\n",
    "                            \"location\": value[\"location\"],\n",
    "                            \"@search.action\": \"upload\"\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "                r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + value[\"index\"]+\"-vector\" + \"/docs/index\",\n",
    "                                     data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "                \n",
    "                if r.status_code != 200:\n",
    "                    print(r.status_code)\n",
    "                    print(r.text)\n",
    "                else:\n",
    "                    i = i + 1 # increment chunk number\n",
    "                    \n",
    "                    # Update document in text-based index and mark it as \"vectorized\"\n",
    "                    upload_payload = {\n",
    "                        \"value\": [\n",
    "                            {\n",
    "                                \"id\": key,\n",
    "                                \"vectorized\": True,\n",
    "                                \"@search.action\": \"merge\"\n",
    "                            },\n",
    "                        ]\n",
    "                    }\n",
    "\n",
    "                    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + value[\"index\"]+ \"/docs/index\",\n",
    "                                     data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "                    \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(\"Exception:\",e)\n",
    "                print(content)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490b7fe-eec2-4c96-a2f2-f8ab0a1b2098",
   "metadata": {},
   "source": [
    "**Note**: How the text-based and the vector-based indexes stay in sync?\n",
    "For document changes, the problem is already taken care of, since Azure Engine will update the text-based index automatically if a file has a new version. This puts the vectorized field in None and the next time that the file is searched it will be vectorized again into the vector-based index.\n",
    "\n",
    "However for deletion of files, the problem is half solved. Azure Search engine would delete the documents in the text-based index if the file is deleted on the source, however you will need to code a script that runs on a fixed schedule that looks for deleted ids in the text-based index and deletes the corresponding chunks in the vector-based index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67f3a2-0023-4f5a-b52f-3fb071cfd8e1",
   "metadata": {},
   "source": [
    "Now we search on the vector-based indexes and get the top k most similar chunks to our question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61098bb4-33da-4eb4-94cf-503587337aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_indexes = [index+\"-vector\" for index in indexes]\n",
    "\n",
    "k = 10 \n",
    "similarity_k = 3\n",
    "ordered_results = get_search_results(QUESTION, vector_indexes,\n",
    "                                        k=k, # Number of results per vector index\n",
    "                                        reranker_threshold=1,\n",
    "                                        vector_search=True, \n",
    "                                        similarity_k=similarity_k,\n",
    "                                        query_vector = embedder.embed_query(QUESTION)\n",
    "                                        )\n",
    "print(\"Number of results:\",len(ordered_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87dc08-b051-4039-98ee-ad84640db843",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279ac20-19d5-43bb-bb1b-37b8eadfa392",
   "metadata": {},
   "source": [
    "# How is the new ordered_results made?\n",
    "Anche se è estratto dagli indici *-vector*, **ordered_results** non contiene embeddings, ma solo la coppia\n",
    "- chunk_id\n",
    "- dictionary(title, name, location, caption, index, **chunk**, score)\n",
    "\n",
    "L'implementazione di get_search_results() in /common/utils.py è di circa 80 righe. Notiamo che:\n",
    "- gli abbiamo passato *query_vector* già trasformata in embeddings\\n\",\n",
    "- se vector_search=True (come in questo caso), allora i campi restituiti sono 5 (più score in automatico), altrimenti sono 7\n",
    "- la risposta della funzione (ovvero il nuovo *ordered_content*) è totalmente costruita nella funzione\n",
    "```\n",
    "if vector_search:\n",
    "    search_payload[\"vectors\"]= [{\"value\": query_vector, \"fields\": \"chunkVector\",\"k\": k}]\n",
    "    search_payload[\"select\"]= \"id, title, chunk, name, location\"\n",
    "else:\n",
    "    search_payload[\"select\"]= \"id, title, chunks, language, name, location, vectorized\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847197f2-d097-4ee5-921a-1df81f5c97e9",
   "metadata": {},
   "source": [
    "Nella prossima cella usiamo **ordered_results OrderedDict()** per costruire un **array di oggetti Document** dove ogni documento ha solo 2 chiavi:\n",
    "- page_content, which contains the selected chunk\n",
    "- metadata (with the \\\"source\\\" key only)\n",
    "\n",
    "For vector search is not recommended to give more than k=5 chunks (of max 5000 characters each) to the LLM as context. Otherwise you can have issues later with the token limit trying to have a conversation with memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb9e39-2542-469d-8f64-4c0c26d79535",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(top_docs))\n",
    "print(f\"top_docs: {top_docs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880885fe-16bd-44bb-9556-7cb3d4989993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of tokens of our docs\n",
    "if(len(top_docs)>0):\n",
    "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
    "    prompt_tokens = num_tokens_from_string(COMBINE_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
    "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
    "    \n",
    "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
    "    \n",
    "    chain_type = \"map_reduce\" if requested_tokens > 0.8 * tokens_limit else \"stuff\"  \n",
    "    \n",
    "    print(\"System prompt token count:\",prompt_tokens)\n",
    "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
    "    print(\"Combined docs (context) token count:\",context_tokens)\n",
    "    print(\"--------\")\n",
    "    print(\"Requested token count:\",requested_tokens)\n",
    "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Chain Type selected:\", chain_type)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e232424-c7ba-4153-b23b-fb1fa2ebc64b",
   "metadata": {},
   "source": [
    "Now we will use our Utility Chain from LangChain `qa_with_sources`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab6e2bb-cae0-45b3-8093-e1ab070f683a",
   "metadata": {},
   "source": [
    "Questo **Documents() array** (top_docs) costruito sopra è il formato necessario per richiamare la Utility Chain da LangChain [`qa_with_sources`](https://python.langchain.com/docs/use_cases/question_answering/how_to/question_answering).<br/>\n",
    "Qui sotto introduciamo anche il prompt (che trovamo in common /prompts.py) per richiedere meglio la risposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511273b3-256d-4e60-be72-ccd4a74cb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"using {chain_type}...\")\n",
    "\n",
    "if chain_type == \"stuff\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       prompt=COMBINE_PROMPT)\n",
    "elif chain_type == \"map_reduce\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       question_prompt=COMBINE_QUESTION_PROMPT,\n",
    "                                       combine_prompt=COMBINE_PROMPT,\n",
    "                                       return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a0c19-d48c-41e9-8d6c-6d9f13d29da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Try with other language as well\n",
    "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"English\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f7fa67-f67b-402e-89e3-266d5d6d21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response['output_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e27c75-bfd9-4304-b2fd-c8e30bcc0558",
   "metadata": {},
   "source": [
    "**Please Note**: There are some instances where, despite the answer's high accuracy and quality, the references are not done according to the instructions provided in the COMBINE_PROMPT. This behavior is anticipated when dealing with GPT-3.5 models. We will provide a more detailed explanation of this phenomenon towards the conclusion of Notebook 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11345374-6420-4b36-b061-795d2a804c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to inspect the results from map_reduce chain type, each top similar chunk summary (k=4 by default)\n",
    "\n",
    "if chain_type == \"map_reduce\":\n",
    "    for step in response['intermediate_steps']:\n",
    "        display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
    "- Utilizing Azure Cognitive Search, we conduct a multi-index text-based search that identifies the top documents from each index.\n",
    "- Utilizing Azure Cognitive Search's vector search, we extract the most relevant chunks of information.\n",
    "- Subsequently, Azure OpenAI utilizes these extracted chunks as context, comprehends the content, and employs it to deliver optimal answers.\n",
    "- Best of two worlds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6e2fe-1c34-4952-99ad-14940f022379",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "In the next notebook, we are going to see how we can treat complex and large documents separately, also using Vector Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivbd",
   "language": "python",
   "name": "openaivbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
