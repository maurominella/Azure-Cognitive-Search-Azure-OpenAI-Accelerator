{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40772662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureOpenAI Endpoint and version: https://mmopenaiaue.openai.azure.com/, version 2023-12-01-preview\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials_my.env\")\n",
    "\n",
    "from IPython.display import Markdown, HTML, display \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "# Reminder: gpt-35-turbo models will create parsing errors and won't follow instructions correctly \n",
    "MODEL = os.environ[\"GPT4-1106-128k\"] # check the other possible values in <model_tokens_limit()> of common/utils.py\n",
    "QUESTION = \"How Markov chains work? Please report the source where you extract this information from.\"\n",
    "QUESTION = \"What is a CLP?\"\n",
    "\n",
    "index_name = \"cogsrch-index-files-vector-onestep\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "print(f'AzureOpenAI Endpoint and version: {os.environ[\"AZURE_OPENAI_ENDPOINT\"]}, version {os.environ[\"OPENAI_API_VERSION\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fa3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import OrderedDict\n",
    "\n",
    "    \n",
    "def get_search_results_fc(\n",
    "    query: str,\n",
    "    indexes: list,\n",
    "    query_type: str = \"simple\",\n",
    "    k_per_index: int = 5, # nr of results for EACH index\n",
    "    reranker_threshold: int = 1,\n",
    "    sas_token: str = \"\",    \n",
    "    k_all_indexes: int = 3, # nr of returned results from ALL indexes\n",
    "    query_vector: list = []\n",
    ") -> List[dict]:\n",
    "    \n",
    "    import requests, json\n",
    "\n",
    "    # Setup the Payloads header\n",
    "    headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "    params  = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}\n",
    "    \n",
    "    agg_search_results = dict() # each index will contain a maximum of k_per_index results\n",
    "    \n",
    "    for index in indexes:\n",
    "        # search query payload\n",
    "        if (query_type == \"simple\"):\n",
    "            search_payload = {\n",
    "                \"count\": \"true\",\n",
    "                \"select\": \"id, name, title, chunk, language, location\",\n",
    "                \"top\": k_per_index,\n",
    "                \"search\": query,\n",
    "                \"queryType\": query_type,\n",
    "                \"captions\": \"extractive\",\n",
    "                \"answers\": \"extractive\" # we may also use f\"extractive|count-{answers}\"\n",
    "            }\n",
    "            \n",
    "        elif (query_type == \"semantic\"):\n",
    "            search_payload = {\n",
    "                \"count\": \"true\",\n",
    "                \"select\": \"id, name, title, chunk, language, location\",\n",
    "                \"top\": k_per_index,\n",
    "                \"search\": query,\n",
    "                \"queryType\": query_type,\n",
    "                \"semanticConfiguration\": \"my-semantic-config\",\n",
    "                \"captions\": \"extractive\",\n",
    "                \"answers\": \"extractive\" # we may also use f\"extractive|count-{answers}\"\n",
    "            }\n",
    "\n",
    "        elif (query_type == \"vector_raw\"):\n",
    "            params  = {'api-version': os.environ['AZURE_SEARCH_API_VERSION_OLD']} # needed for skillset creation with projection\n",
    "            search_payload = {                \n",
    "                \"count\": \"true\",\n",
    "                \"select\": \"id, name, title, chunk, language, location\",\n",
    "                \"vectorQueries\": [\n",
    "                    {\n",
    "                        \"kind\": \"vector\",\n",
    "                        \"k\": k_per_index,      \n",
    "                        \"fields\": \"chunkVector\", \n",
    "                        \"vector\": query_vector\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "        elif (query_type == \"vector_text\"):\n",
    "            params  = {'api-version': os.environ['AZURE_SEARCH_API_VERSION_OLD']} # needed for skillset creation with projection\n",
    "            search_payload = {\n",
    "                \"count\": \"true\",\n",
    "                \"select\": \"id, name, title, chunk, language, location\",\n",
    "                \"vectorQueries\": [\n",
    "                    {\n",
    "                        \"kind\": \"text\",\n",
    "                        \"k\": k_per_index,      \n",
    "                        \"fields\": \"chunkVector\", \n",
    "                        \"text\": query\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            raise Exception(f\"ERROR: <{query_type}> is a wrong query type\")\n",
    "\n",
    "        resp = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index + \"/docs/search.post.search\",\n",
    "                             data=json.dumps(search_payload), headers=headers, params=params)\n",
    "        \n",
    "        search_results = resp.json()\n",
    "        agg_search_results[index] = search_results\n",
    "    \n",
    "    content = dict() # this (NOT ORDERED) dictionary contains the FLATTEN results from all indexes\n",
    "    \n",
    "    for index,search_results in agg_search_results.items():\n",
    "        for result in search_results['value']:\n",
    "            \n",
    "            include_result = True\n",
    "            caption = \"\"\n",
    "            if '@search.rerankerScore' in result: \n",
    "                # Show results that are at least N% of the max possible score=4                \n",
    "                if result['@search.rerankerScore'] < reranker_threshold:\n",
    "                    include_result = False \n",
    "                else:\n",
    "                    caption = result['@search.captions'][0]['text'],\n",
    "                \n",
    "            if include_result: \n",
    "                content[result['id']]={\n",
    "                                        \"title\": result['title'], \n",
    "                                        \"name\": result['name'], \n",
    "                                        \"location\": result['location'] + sas_token if result['location'] else \"\",\n",
    "                                        \"caption\": caption,\n",
    "                                        \"index\": index\n",
    "                                    }\n",
    "                content[result['id']][\"chunk\"]= result['chunk']\n",
    "                content[result['id']][\"score\"]= result['@search.score'] # Uses the Hybrid RRF score\n",
    "\n",
    "    ordered_content = OrderedDict() # similar to \"content\" dictionary, but this is 1) ordered 2) limited to k_all_indexes results\n",
    "    count = 0  # To keep track of the number of results added    \n",
    "    for id in sorted(content, key=lambda x: content[x][\"score\"], reverse=True):\n",
    "        ordered_content[id] = content[id]\n",
    "        count += 1\n",
    "        if count >= k_all_indexes:  # Keep a total of similarity_k results out of ALL indexes\n",
    "            break\n",
    "    \n",
    "    return ordered_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e794ab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n",
      "\n",
      "Here are the 4 results:\n",
      "OrderedDict([('8aa8217ce2db_aHR0cHM6Ly9ibG9ic3RvcmFnZXkyNGJpNTc3anN6ZjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMi8wMDEyMDE0djEucGRm0_chunks_1', {'title': 'arXiv:cs/0012014v1  [cs.SE]  18 Dec 2000', 'name': '0012014v1.pdf', 'location': 'https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0012/0012014v1.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D', 'caption': '', 'index': 'cogsrch-index-files-vector-onestep', 'chunk': 'then discusses relations to other work. Finally in Section 8 we present our conclusions and sugges-\\ntions for future work.\\n\\n2 Constraint Logic Programs\\n\\nThe cornerstone of Constraint Logic Programming (CLP) [9, 13] is the notion of constraint. Con-\\nstraints are formulae constructed with some constraint predicates with a predefined interpreta-\\ntion. A typical example of a constraint is a linear arithmetic equation or inequality with rational\\ncoefficients where the constraint predicate used is equality interpreted over rational numbers, e.g.\\nX − Y = 1. The variables of a constraint range over the domain of interpretation. A valuation of\\na set S of variables is a mapping θ from S to the interpretation domain. A set of constraints C is\\nsatisfiable if there exists a valuation θ for the set of variables occurring in C, such that θ(C) holds\\nin the constraint domain.\\n\\nA constraint logic program is a set of clauses of the form h : −b1, ..., bn, n ≥ 0 , where\\nh, b1, ..., bn are atomic formulae. The predicates used to construct b1, ..., bn are either constraint\\npredicates or other predicates (sometimes called defined predicates). The predicate of h is a defined\\npredicate. A goal is a clause without h. This syntax extends logic programs with the possibility of\\nincluding constraints into the clauses.\\n\\nExample 1 In the following constraint program the equality constraint and symbols of arithmetic\\noperations are interpreted over the domain of rational numbers. This simple example is chosen to\\nsimplify the forthcoming illustration of slicing concepts and techniques. The constraints are distin-\\nguished by the curly brackets {}.\\n\\np(X,Y,Z):- {X-Y=1}, q(X,Y), r(Z).\\nq(U,V):- {U+V=3}.\\nr(42).\\n\\nSlicing refers to computations. Abstractly, a computation can be seen as construction of a tree,\\nfrom renamed instances of clauses. We explain briefly the idea discussed formally in [3].\\n\\nIntuitively, a clause c can be seen as a tree with root h head and leaves b1, ..., bn body atoms. If\\nthe predicate of bi appears in the head of a clause c′ then a renamed copy c′′ of c′ can be composed\\nwith c by attaching the head of c′′ to bi. This implicitly adds equality constraints for the corresponding\\narguments of the atoms. This process can be repeated for the leaves of the resulting tree. More\\nformally this is captured by the following notion. A skeleton for a program P is a labeled ordered\\ntree with the root labeled by a goal clause and with the nodes labeled by (renamed) clauses of the\\nprogram; some leaves may instead be labeled ”?” in which case they are called incomplete nodes.\\n\\n\\n\\n4 AADEBUG 2000\\n\\nEach non-leaf node has as many children as the non-constraint atoms of its body. The head predicate\\nof the i-th child of a node is the same as the predicate of the i-th non-constraint body atom of the\\nclause labeling the node.\\n\\nFor a given skeleton S the set C(S) of constraints, which will be called the set of constraints of\\nS, consists of :\\n\\n• the constraints of all clauses labeling the nodes of S\\n\\n• all equations ~x = ~y where ~x are the arguments of the i-th body atom of the clause labeling a\\nnode n of S, and ~y are the arguments of the head atom of the clause labeling the i-th child of\\nn. (No equation is created if the i-th child of n is an incomplete node).\\n\\nA derivation tree for a program P is a skeleton for P whose set of constraints is satisfiable. If the\\nskeleton is complete (i.e. it has no incomplete node) the derivation tree is called a proof tree. Figure\\n1 shows a complete skeleton tree for the program in Example 1.\\n\\nq(U,V) :- {U + V = 3}\\n\\np(X,Y,Z) :- {X - Y = 1}, q(X,Y), r(Z)\\n\\nr(42)\\n\\nFigure 1: A skeleton for the CLP program of Example 1.\\n\\nThe set of constraints of this skeleton is: C(S) = {X − Y = 1, X = U, Y = V, U + V = 3, Z =\\n42} and it is satisfiable. Thus the skeleton is a proof tree.\\n\\nFor the presentation of the slicing techniques we need to refer to program positions and to\\nderivation tree positions. A slice is defined with respect to some particular occurrence of a variable\\n(in a program or derivation tree), and positions are used to identify these ocurrences. Positions also\\nidentify arguments of the atomic formulae and their subterms.\\n\\nTo define the notion of position we assume that some standard way of enumeration of the nodes\\nof any given tree T is adopted. The indices of the nodes of T are called positions of T and the set of\\nall positions is denoted Pos(T ). Each position determines a unique subtree of T . On the other hand,\\nT may have several identical subtrees T0 at different positions.\\n\\nThis notation extends also for atomic formulae and terms, where the positions determine unique\\nsubterms. A position of a term such that the corresponding subterm is a variable will be called a\\nvariable position. We extend the adopted way of enumeration to clauses and programs; a program\\nposition is an index in this enumeration that identifies an atomic formula or a term in a clause of the\\nprogram.\\n\\n', 'score': 0.8292332}), ('5320065f0901_aHR0cHM6Ly9ibG9ic3RvcmFnZXkyNGJpNTc3anN6ZjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMS8wMDExMDMwdjEucGRm0_chunks_7', {'title': 'arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000', 'name': '0011030v1.pdf', 'location': 'https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0011/0011030v1.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D', 'caption': '', 'index': 'cogsrch-index-files-vector-onestep', 'chunk': 'Reasoning, special track on Abductive Reasoning, Breckenridge, Colorado, USA,\\n2000. Workshop associated with KR’2000.\\n\\n\\n\\n[22] H. Vandecasteele. Constraint Logic Programming: Applications and Implementa-\\ntion. PhD thesis, K.U.Leuven, 1999.\\n\\n[23] H. Vandecasteele and D. De Schreye. Implementing a finite-domain CLP-language\\non top of Prolog: a transformational approach. In F. Pfenning, editor, Proceedings\\nof Logic Programming and Automated Reasoning, volume 822 of Lecture Notes in\\nArtificial Intelligence, pages 84–98, Kiev, Ukraine, 1994. Springer-Verlag.\\n\\n[24] J. Zhang and H. Zhang. Constraint propagation in model generation. In U. Mon-\\ntanari and F. Rossi, editors, Proc. of 1st International Conference on Principles\\nand Practice of Constraint Programming, volume 976 of Lecture Notes in Com-\\nputer Science, pages 398–414, France, Sept. 1995. Springer.\\n\\n\\n', 'score': 0.8166054}), ('5320065f0901_aHR0cHM6Ly9ibG9ic3RvcmFnZXkyNGJpNTc3anN6ZjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMS8wMDExMDMwdjEucGRm0_chunks_3', {'title': 'arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000', 'name': '0011030v1.pdf', 'location': 'https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0011/0011030v1.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D', 'caption': '', 'index': 'cogsrch-index-files-vector-onestep', 'chunk': 'The ACLP representation is in the middle of the declarative FOL representation\\nand the more procedural CLP representation.\\n\\n\\n\\n3 Experiments\\n\\n3.1 The Systems\\n\\nThe finite domain CLP package is the one provided with ECLiPSe version 4.2.\\nBoth abductive systems, ACLP [10] and SLDNFAC, [3] are meta interpreters\\n\\nwritten in Prolog, running on ECLiPSe version 4.2 and making use of its fi-\\nnite domain library. For all these systems, a search strategy which first selects\\nvariables with the smallest domain which participate in the largest number of\\nconstraints was used.\\n\\nThe model generator SEM version 1.7 is a fine tuned package written in C.\\nsmodels version 2.25, the system for computing stable models, is implemented in\\nC++ and the associated program used for grounding is lparse version 0.99.54.\\nAll experiments have been done on the same hardware, namely Pentium II.\\n\\n3.2 Graph Coloring\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n10000\\n\\n10 100 1000\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nNodes\\n\\nGraph Coloring\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 1. Graph coloring\\n\\nOur first experiment is done with 4-colorable graphs. We used a graph gen-\\nerator1 program which is available from address http://web.cs.ualberta.ca/\\n1 The graphs have been generated with the following parameters: 0, 13, 6, n, 4, 0.2, 1,\\n\\n0 where n is the number of vertices. Graph-coloring problems generated with these\\nparameters are difficult.\\n\\n\\n\\n~joe/Coloring/Generators/generate.html. We applied the systems in a se-\\nquence of experiments with graphs of increasing size and constant number of\\ncolors. We have modified only one parameter of the problem namely the number\\nof vertices. Figure 1 gives the results of solving the problem with the different\\nsystems. Both axes are plotted in a logarithmic scale. On the x-axis we have put\\nthe number of vertices. Not surprisingly, CLP is the fastest system. The times\\nfor smodels is second best on this problem. We assume it is in part because of\\nthe very concise formulation. Using the so called technique of rules with excep-\\ntions [14], the two rules needed to describe the space of candidate solutions also\\nencode the constraint that the color is a function of the vertex. Hence there is\\nonly one other rule, namely the constraint that two adjacent vertices must have\\na different color. The difference with CLP is almost two orders of magnitude\\nfor the largest problems. The times reported for smodels do not include the\\ntime for grounding the problem, these times only consist of a small part of the\\ntotal time. Grounding the problem for 650 nodes takes only 10 seconds, whereas\\nsolving the problem takes over 100 seconds. SLDNFAC is slightly worse than\\nsmodels. Although meta-interpretation overhead tends to increase with prob-\\nlems size, the difference with smodels grows very slowly. The model generator\\nSEM deteriorates much faster and runs out of memory for the larger problems.\\nThe fact that it grounds the whole theory is a likely explanation. The differ-\\nence with smodels supports the claim that smodels has better techniques for\\ngrounding. ACLP performs substantially worse than SLDNFAC and also dete-\\nriorates faster. The difference is likely due to the function-specification available\\nin SLDNFAC. Contrary to ACLP, SLDNFAC exploits the knowledge that the\\nabducible encodes a function to reduce the number of explicitly stored integrity\\nconstraints.\\n\\n3.3 N-Queens\\n\\nFigure 2 gives the running times for the different systems for finding a first\\nsolution. Both axes are plotted on a linear scale. The time consumed while\\ngrounding is again not included in the graph (for 18 queens, half a second).\\nAgain, CLP gives the best results. SLDNFAC is second best and, although meta-\\ninterpretation overhead increases with problem size, deteriorates very slowly.\\nACLP is third2, with a small difference, probably due to the lack of the function-\\nspecification mentioned in the section above. The next one is SEM. It runs out\\nof memory for large problems (it needs about 120MB for 27 queens). smodels\\n\\nperforms very poorly on this problem, in particular when compared with its\\nperformance on the graph coloring problem. It is well-known that to obtain good\\nresults for computing the first solution for the n-queens problem, a good search\\nheuristic is needed, like the first fail principle used by the systems based on CLP.\\nWe believe that the bad performance of smodels is explained by the absence of\\n\\n2 The results with ACLP are substantially better than those in the previous paper [17].\\nThis is due to the removal of a redundant and time consuming complete consistency\\ncheck after the processing of each new CLP constraint.\\n\\n\\n\\n0\\n\\n2\\n\\n4\\n\\n6\\n\\n8\\n\\n10\\n\\n10 15 20 25 30\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 2. N-queens: one solution\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n4 5 6 7 8 9 10 11 12 13\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens (all solutions)\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 3. N-queens: all solutions\\n\\n\\n\\nappropriate heuristics. ', 'score': 0.8156465}), ('5320065f0901_aHR0cHM6Ly9ibG9ic3RvcmFnZXkyNGJpNTc3anN6ZjYuYmxvYi5jb3JlLndpbmRvd3MubmV0L2FyeGl2Y3MvMDAxMS8wMDExMDMwdjEucGRm0_chunks_0', {'title': 'arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000', 'name': '0011030v1.pdf', 'location': 'https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0011/0011030v1.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D', 'caption': '', 'index': 'cogsrch-index-files-vector-onestep', 'chunk': '\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n00\\n\\n11\\n03\\n\\n0v\\n1 \\n\\n [\\ncs\\n\\n.A\\nI]\\n\\n  2\\n1 \\n\\nN\\nov\\n\\n 2\\n00\\n\\n0\\n\\nLogic Programming Approaches for\\n\\nRepresenting and Solving Constraint\\n\\nSatisfaction Problems: A Comparison\\n\\nNikolay Pelov, Emmanuel De Mot, and Marc Denecker\\n\\nDepartment of Computer Science, K.U.Leuven\\nCelestijnenlaan 200A, B-3001 Heverlee, Belgium\\n\\nE-mail: {pelov,emmanuel,marcd}@cs.kuleuven.ac.be\\n\\nAbstract. Many logic programming based approaches can be used to\\ndescribe and solve combinatorial search problems. On the one hand there\\nis constraint logic programming which computes a solution as an answer\\nsubstitution to a query containing the variables of the constraint satis-\\nfaction problem. On the other hand there are systems based on stable\\nmodel semantics, abductive systems, and first order logic model gen-\\nerators which compute solutions as models of some theory. This paper\\ncompares these different approaches from the point of view of knowledge\\nrepresentation (how declarative are the programs) and from the point of\\nview of performance (how good are they at solving typical problems).\\n\\n1 Introduction\\n\\nConsistency techniques are widely used for solving finite domain constraint sat-\\nisfaction problems (CSP) [19]. These techniques have been integrated in logic\\nprogramming, resulting in finite domain constraint logic programming (CLP)\\n[20]. In this paradigm, a program typically creates a data structure holding the\\nvariables of the CSP to be solved, sets up the constraints and uses a labelling\\ntechnique to assign values to the variables. The constraint solver uses consistency\\ntechniques to prune the search. This leads to a rather procedural programming\\nstyle. Moreover, the problem description is not very declarative because the map-\\nping between domain variables and their value has an indirect representation in\\na term structure.\\n\\nIn this paper, we compare CLP and three computational paradigms allowing\\nproblem solving based on more declarative representations. A common feature of\\nthese approaches is that the relation between the CSP variables and their values\\nis encoded as a predicate or function relating identifiers of the CSP variables\\nwith their value. E.g. in the graph coloring problem, the predicate relates node\\nnumbers with colors. This representation allows for a more natural declarative\\nrepresentation of the problem.\\n\\nOne approach is specification in first order logic. As pointed out in [12], one\\ncan represent a CSP as a first order logic theory such that (part of) its models\\n\\nhttp://arXiv.org/abs/cs/0011030v1\\n\\n\\ncorrespond to the solutions of the CSP. Hence first order model generators such\\nas SEM [24] can be used to solve such problems.\\n\\nThe two other approaches use extensions of logic programming. Recently, a\\nlogic programming paradigm based on stable model semantics [6] has emerged.\\nNiemelä [14] proposes it as a constraint programming paradigm, Marek and\\nTruszczyński [13] introduce Stable Logic Programming and Lifschitz [11] pro-\\nposes Answer Set Programming. As described in [13], the methodology of these\\napproaches is to encode a computational problem by a logic program such that\\nits stable models represent the solutions. A number of efficient systems for com-\\nputing stable models have been developed. Of these, Niemelä’s smodels [15, 14]\\nis considered one of the most performant systems.\\n\\nAbduction [8] uses a similar predicate representation for the relation between\\nthe identifiers of CSP variables and their value. This predicate is declared to be\\nopen or abducible. Constraining this relation to be a solution, an abductive\\nsystem will return models of the abducible which are solutions of the CSP.\\n\\nWe use some typical CSP problems to compare the merits of the various\\napproaches. One experiment is in graph coloring. We have compared the rep-\\nresentation and the performance of CLP with the three other approaches in a\\nsequence of experiments where the size of the graph increases and the number\\nof colors remains constant. Another experiment is the n-queens problem where\\nboth the domain size and the number of constraints increases with increasing\\nproblem size. We also report on experiments using CLP, stable logic program-\\nming and abduction for solving a complex real world scheduling problem. For\\neach different system, we have tried to use any special features provided by it.\\n\\nIn Section 2 we review in more detail the various approaches and systems,\\nfocusing mainly on the knowledge representation aspects. Section 3 reports on\\nthe experiments and we conclude in Section 4.\\n\\nWe are not aware of any previous work which compares this wide range of\\nlogic based systems for their suitability in solving CSP problems. Mackworth [12]\\nexplores the space of possible CSP formalizations but assesses neither the quality\\nfrom point of view of knowledge representation nor the performance of actual\\nsystems. Also, approaches based on stable model semantics and abduction are\\nnot included in his work. ', 'score': 0.806802})])\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings # deprecated\n",
    "# from langchain_openai import AzureOpenAIEmbeddings # new library\n",
    "embedder = AzureOpenAIEmbeddings(model=\"text-embedding-ada-002\", skip_empty=True)\n",
    "query_type = \"vector_text\"\n",
    "\n",
    "if (query_type == \"vector_text\"): # options are: simple - semantic - vector_raw - vextor_text\n",
    "    query_vector = embedder.embed_query(QUESTION)\n",
    "else:\n",
    "    query_vector = []\n",
    "\n",
    "ordered_results = get_search_results_fc (\n",
    "    query              = QUESTION,\n",
    "    indexes            = [index_name],\n",
    "    query_type         = query_type,\n",
    "    k_per_index        = 5,\n",
    "    reranker_threshold = 0,\n",
    "    sas_token          = os.environ[\"BLOB_SAS_TOKEN\"],\n",
    "    k_all_indexes      = 4,\n",
    "    query_vector       = query_vector\n",
    ")\n",
    "\n",
    "print(f\"\\nHere are the {len(ordered_results)} results:\\n{ordered_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e759f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI # https://github.com/openai/openai-python\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, HTML, display\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key        = os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    api_version    = os.environ['AZURE_OPENAI_API_VERSION']\n",
    ")\n",
    "\n",
    "def printmd(string):\n",
    "    # string = string.replace('\\n', '<br/>')\n",
    "    display(Markdown(string))\n",
    "      \n",
    "def printmd_indented(string):\n",
    "    # Split the string into lines, indent each line, and then join them back into a single string\n",
    "    indented_string = '\\n'.join(f\"> {line}\" for line in string.strip().split('\\n'))\n",
    "    display(Markdown(indented_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ac0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "# SYSTEM MESSAGE\n",
    "SYSTEM_MESSAGE = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "Your answer must be well formatted using markdown codes because I have a markdown renderer to show your final answer.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "## About your output format:\n",
    "- Be concise (no more than three sentences), anche create a beautiful and thorough response using Markdown.\n",
    "- You have access to Markdown rendering elements to present information in a visually appealing way. For example:\n",
    "  - You can use headings when the response is long and can be organized into sections.\n",
    "  - You can use compact tables to display data or information in a structured manner.\n",
    "  - You can bold relevant parts of responses to improve readability, like \"... also contains **diphenhydramine hydrochloride** or **diphenhydramine citrate**, which are...\".\n",
    "  - You must respond in the same language of the question.\n",
    "  - You can use short lists to present multiple items or options concisely.\n",
    "  - You can use code blocks to display formatted content such as poems, code snippets, lyrics, etc.\n",
    "  - You use LaTeX to write mathematical expressions and formulas like $$\\sqrt{{3x-1}}+(1+x)^2$$\n",
    "- You do not include images in markdown responses as the chat box does not support images.\n",
    "- Your output should follow GitHub-flavored Markdown.\n",
    "- Try to extract some pieces of information from **ALL** different sources provided.\n",
    "- Next to each text block that you built form a given context, insert a hyperlink to the location provided at the beginning of each context. Use sequential numbers as the text of the hyperlinks.\\n\\n\n",
    "- These hyperlinks should be generated using the Markdown syntax used in the following example: \"This book is on the table<sup>[(1)](https://www.example.com)</sup>, while the cat is on the floor<sup>[(2)](https://www.example2.com)</sup>!\"\n",
    "Context:\\n\"\"\"\n",
    "\n",
    "i = 1\n",
    "for context in ordered_results:\n",
    "    # print(ordered_results[context]['chunk'])\n",
    "    SYSTEM_MESSAGE = f\"{SYSTEM_MESSAGE}\\n*****************\\n1) Location <{ordered_results[context]['location']}>:\\n{ordered_results[context]['chunk']}\\n\\n\"\n",
    "\n",
    "message_system = {\"role\": \"system\", \"content\": SYSTEM_MESSAGE}\n",
    "messages.append(message_system)\n",
    "\n",
    "# USER MESSAGE\n",
    "message_user = {\"role\": \"user\", \"content\": QUESTION}\n",
    "messages.append(message_user)\n",
    "\n",
    "\n",
    "# messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4ff407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Constraint Logic Programming (CLP)** is a combination of two paradigms: constraint solving and logic programming. In CLP, the fundamental concept is a constraint - a formula constructed with constraint predicates that have a predefined interpretation. Constraints can include linear arithmetic equations or inequalities with rational coefficients, among others. The framework extends logic programming by integrating constraints into the logic program's clauses, allowing the representation and solving of problems involving constraints on the values of variables<sup>[(1)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0012/0012014v1.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 ms, sys: 0 ns, total: 23.9 ms\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model       = MODEL,\n",
    "    messages    = messages,\n",
    "    # tools       = tools,\n",
    "    # tool_choice = 'auto'\n",
    ")\n",
    "\n",
    "printmd(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e29a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Constraint Logic Programming (CLP)** is a combination of two paradigms: constraint solving and logic programming. In CLP, the fundamental concept is a constraint - a formula constructed with constraint predicates that have a predefined interpretation. Constraints can include linear arithmetic equations or inequalities with rational coefficients, among others. The framework extends logic programming by integrating constraints into the logic program's clauses, allowing the representation and solving of problems involving constraints on the values of variables<sup>[(1)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0012/0012014v1.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c41485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_internal_docs(question, index):\n",
    "    \"\"\" Returns a complete answer, searching in the internal documentation and in the index provided \"\"\"\n",
    "    import json\n",
    "    \n",
    "    query_type = \"vector_text\"\n",
    "    \n",
    "    ordered_results = get_search_results_fc (\n",
    "        query              = question,\n",
    "        indexes            = [index],\n",
    "        query_type         = query_type,\n",
    "        k_per_index        = 5,\n",
    "        reranker_threshold = 0,\n",
    "        sas_token          = os.environ[\"BLOB_SAS_TOKEN\"],\n",
    "        k_all_indexes      = 4,\n",
    "        query_vector       = query_vector\n",
    "    )  \n",
    "    \n",
    "    \n",
    "    messages = []\n",
    "\n",
    "    # SYSTEM MESSAGE\n",
    "    SYSTEM_MESSAGE = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question.\n",
    "    Your answer must be well formatted using markdown codes because I have a markdown renderer to show your final answer.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    ## About your output format:\n",
    "    - Be concise (no more than three sentences), anche create a beautiful and thorough response using Markdown.\n",
    "    - You have access to Markdown rendering elements to present information in a visually appealing way. For example:\n",
    "      - You can use headings when the response is long and can be organized into sections.\n",
    "      - You can use compact tables to display data or information in a structured manner.\n",
    "      - You can bold relevant parts of responses to improve readability, like \"... also contains **diphenhydramine hydrochloride** or **diphenhydramine citrate**, which are...\".\n",
    "      - You must respond in the same language of the question.\n",
    "      - You can use short lists to present multiple items or options concisely.\n",
    "      - You can use code blocks to display formatted content such as poems, code snippets, lyrics, etc.\n",
    "      - You use LaTeX to write mathematical expressions and formulas like $$\\sqrt{{3x-1}}+(1+x)^2$$\n",
    "    - You do not include images in markdown responses as the chat box does not support images.\n",
    "    - Your output should follow GitHub-flavored Markdown.\n",
    "    - Try to extract some pieces of information from **ALL** different sources provided.\n",
    "    - Next to each text block that you built form a given context, insert a hyperlink to the location provided at the beginning of each context. Use sequential numbers as the text of the hyperlinks.\\n\\n\n",
    "    - These hyperlinks should be generated using the Markdown syntax used in the following example: \"This book is on the table<sup>[(1)](https://www.example.com)</sup>, while the cat is on the floor<sup>[(2)](https://www.example2.com)</sup>!\"\n",
    "    Context:\\n\"\"\"\n",
    "\n",
    "    i = 1\n",
    "    for context in ordered_results:\n",
    "        # print(ordered_results[context]['chunk'])\n",
    "        SYSTEM_MESSAGE = f\"{SYSTEM_MESSAGE}\\n*****************\\n1) Location <{ordered_results[context]['location']}>:\\n{ordered_results[context]['chunk']}\\n\\n\"\n",
    "\n",
    "    message_system = {\"role\": \"system\", \"content\": SYSTEM_MESSAGE}\n",
    "    messages.append(message_system)\n",
    "\n",
    "    # USER MESSAGE\n",
    "    message_user = {\"role\": \"user\", \"content\": question}\n",
    "    messages.append(message_user)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model       = MODEL,\n",
    "        messages    = messages,\n",
    "        # tools       = tools,\n",
    "        # tool_choice = 'auto'\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    final_answer = {\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    return json.dumps(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0afdda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_in_internal_docs\",            \n",
    "            \"description\": \"Returns a complete answer, searching in the internal documentation and in the index provided\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\"type\": \"string\", \"description\": \"the search string to look for\"},\n",
    "                    \"index\": {\"type\": \"string\", \"description\": \"the index we should look into\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"question\", \"index\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f580ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8eewZIodMiDsclDAl74C6vsWn6SDq', choices=[Choice(finish_reason='tool_calls', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_hMJSmi7YxQmTwyuGk8IanPnI', function=Function(arguments='{\"question\":\"What is a CLP\",\"index\":\"cogsrch-index-files-vector-onestep\"}', name='search_in_internal_docs'), type='function')]), content_filter_results={})], created=1704701199, model='gpt-4', object='chat.completion', system_fingerprint='fp_50a4261de5', usage=CompletionUsage(completion_tokens=33, prompt_tokens=107, total_tokens=140), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model  = MODEL,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"The answer to the question 'What is a CLP' should be included in the 'cogsrch-index-files-vector-onestep' index\"\n",
    "        }\n",
    "    ],\n",
    "    tools = tools,\n",
    "    tool_choice = \"auto\"\n",
    ")\n",
    "\n",
    "completion # includes the selected function(s) and corresponding arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e3c5d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h1><span style=\"color:darkblue;\">Given this SYSTEM_MESSAGE...</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> You are an AI assistant that helps people find information.\n",
       "> Please provide two kinds of answers:\n",
       "> \n",
       "> 1. First, give just a concise and high level response following these rules:   \n",
       ">    - **JUST** detail the high level steps you would follow to achieve this result, next to the reason why you identified each one. \n",
       ">    - **ALWAYS** think step by step.\n",
       ">    - Do **NOT** provide any details about the sub-tasks you would do to achieve each step.\n",
       ">    - Do **NOT** provide any examples to explain how you will implement the solution.\n",
       ">    - Do **NOT** do any calculations or simulations.\n",
       ">    - Do **NOT** use any external tools to do this, just use your internal knowledge.\n",
       "> \n",
       "> 2. Second, implement one by one the needed steps, harnessing the tools provided. Furthermore, for each step:   \n",
       ">    - Explain the reason why you chose that action and the functions.\n",
       ">    - **NEVER** call a function if you do not have **all** required parameters of that function.\n",
       ">    - **NEVER** use your internal knowledge to guess any date-related information.\n",
       ">    \n",
       "> At the end, **ALWAYS** provide a detailed description of the whole process that you followed to achieve the result, \n",
       "> using well formatted markup language. \n",
       "> **ALWAYS** make sure you include, in the final answer, **ALL**  Markdown-formatted text collected in the last message, including citations and hyperlinks.\n",
       "> Use wonderful formatted markdown answers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h1><span style=\"color:darkblue;\">...and your QUESTION...</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> *<span style=\"font-size:larger;color:blue;\">The answer to the question 'What are some examples of reinforcement learning?' should be included in the 'cogsrch-index-files-vector-onestep' index</span>*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h1><span style=\"color:darkblue;\">...now, the fun BEGINS!</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h2><span style=\"color:darkgreen;\">Creating completion request #1...</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> 1. Use the `functions.search_in_internal_docs` to search for examples of reinforcement learning within the 'cogsrch-index-files-vector-onestep' index.\n",
       ">    - Reason: To find concrete examples of reinforcement learning from the specified index."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-size:larger;color:orange;\">...which consumed **408** prompt + **87** completion tokens (=**495** total tokens)<br/>and terminated with finish_reason = `tool_calls`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-size:larger;color:darkgreen;\">As a result, the assistant indentified `1 function(s)`, that I'm now going to run:</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> <span style=\"color:darkgreen;\">1) Running function `search_in_internal_docs({'question': 'What are some examples of reinforcement learning?', 'index': 'cogsrch-index-files-vector-onestep'})` in completion `#1`, that returns...</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> >...<span style=\"color:darkblue;\">{\"answer\": \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties as feedback. Here are a few examples:\\n\\n- **Robotics**: Multi-robot systems utilize reinforcement learning for tasks like coordinating movements and achieving group behaviors, as explored in Mataric\\u0301's studies<sup>[(1)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\\n\\n- **Model-based Learning**: Carmel and Markovitch deployed model-based learning where agents build models of other agents and use this learned information to inform their decisions<sup>[(2)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\\n\\n- **Multi-Agent Systems (MAS)**: Learning in MAS for coordinated system-wide optimal behavior was demonstrated by Sen and Sekaran, where agents applied Q-learning or classifier systems<sup>[(1)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\\n\\n- **Economic Markets**: Hu and Wellman explored how reinforcement learning can apply to agents operating in market-based systems, dealing with initial biases and agent models<sup>[(2)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\\n\\n- **Game Playing**: Reinforcement learning is also applied to teach agents how to play games, such as AlphaGo, which learned to play the board game Go at a level surpassing human grandmasters.\\n\\n- **Autonomous Vehicles**: Reinforcement learning helps autonomous vehicles learn how to navigate and make safe driving decisions based on the rewards tied to safety and efficiency metrics.\\n\\nThese examples illustrate the versatility of reinforcement learning across different fields and applications.\"}</span><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h2><span style=\"color:darkgreen;\">Creating completion request #2...</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-size:larger;color:orange;\">...which consumed **1330** prompt + **272** completion tokens (=**1602** total tokens)<br/>and terminated with finish_reason = `stop`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h2><span style=\"color:darkgreen;\">Hooray! All completions were successfully executed. We have reached the end of the chain!</span></h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h1><span style=\"color:blue;\">Now I have the final answer, which used 495 cumulative tokens</span></h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The process to find examples of reinforcement learning in the 'cogsrch-index-files-vector-onestep' index involved one key step:\n",
       "\n",
       "1. I used the `functions.search_in_internal_docs` function with the question \"What are some examples of reinforcement learning?\" and specified the index 'cogsrch-index-files-vector-onestep'. This was done to retrieve relevant information on examples of reinforcement learning from the selected index. The search yielded the following results:\n",
       "\n",
       "Reinforcement learning is leveraged in various domains with examples including:\n",
       "\n",
       "- **Robotics**: Utilized in multi-robot systems for tasks like movement coordination and achieving group behaviors.\n",
       "  \n",
       "- **Model-based Learning**: Agents build models of other agents' behaviors to inform their decisions.\n",
       "\n",
       "- **Multi-Agent Systems (MAS)**: Agents learn coordinated system-wide optimal behaviors using algorithms like Q-learning.\n",
       "\n",
       "- **Economic Markets**: Applied to agents in market-based systems to handle initial biases and create agent models.\n",
       "\n",
       "- **Game Playing**: Teaching agents to play and master games, notably the AlphaGo program's achievement in Go.\n",
       "\n",
       "- **Autonomous Vehicles**: Employed in the development of autonomous vehicles for navigation and decision-making tied to safety and efficiency.\n",
       "\n",
       "These diverse applications demonstrate the broad utility of reinforcement learning in different fields.\n",
       "\n",
       "For further details, including citations, please refer to the full answer provided above."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Reinforcement learning is a type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties as feedback. Here are a few examples:\n",
       "> \n",
       "> - **Robotics**: Multi-robot systems utilize reinforcement learning for tasks like coordinating movements and achieving group behaviors, as explored in Matarić's studies<sup>[(1)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\n",
       "> \n",
       "> - **Model-based Learning**: Carmel and Markovitch deployed model-based learning where agents build models of other agents and use this learned information to inform their decisions<sup>[(2)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\n",
       "> \n",
       "> - **Multi-Agent Systems (MAS)**: Learning in MAS for coordinated system-wide optimal behavior was demonstrated by Sen and Sekaran, where agents applied Q-learning or classifier systems<sup>[(1)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\n",
       "> \n",
       "> - **Economic Markets**: Hu and Wellman explored how reinforcement learning can apply to agents operating in market-based systems, dealing with initial biases and agent models<sup>[(2)](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)</sup>.\n",
       "> \n",
       "> - **Game Playing**: Reinforcement learning is also applied to teach agents how to play games, such as AlphaGo, which learned to play the board game Go at a level surpassing human grandmasters.\n",
       "> \n",
       "> - **Autonomous Vehicles**: Reinforcement learning helps autonomous vehicles learn how to navigate and make safe driving decisions based on the rewards tied to safety and efficiency metrics.\n",
       "> \n",
       "> These examples illustrate the versatility of reinforcement learning across different fields and applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 8.58 ms, total: 110 ms\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "QUESTION = \"\"\"The answer to the question 'What are some examples of reinforcement learning?' should be included in the 'cogsrch-index-files-vector-onestep' index\"\"\"\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"You are an AI assistant that helps people find information.\n",
    "Please provide two kinds of answers:\n",
    "\n",
    "1. First, give just a concise and high level response following these rules:   \n",
    "   - **JUST** detail the high level steps you would follow to achieve this result, next to the reason why you identified each one. \n",
    "   - **ALWAYS** think step by step.\n",
    "   - Do **NOT** provide any details about the sub-tasks you would do to achieve each step.\n",
    "   - Do **NOT** provide any examples to explain how you will implement the solution.\n",
    "   - Do **NOT** do any calculations or simulations.\n",
    "   - Do **NOT** use any external tools to do this, just use your internal knowledge.\n",
    "\n",
    "2. Second, implement one by one the needed steps, harnessing the tools provided. Furthermore, for each step:   \n",
    "   - Explain the reason why you chose that action and the functions.\n",
    "   - **NEVER** call a function if you do not have **all** required parameters of that function.\n",
    "   - **NEVER** use your internal knowledge to guess any date-related information.\n",
    "   \n",
    "At the end, **ALWAYS** provide a detailed description of the whole process that you followed to achieve the result, \n",
    "using well formatted markup language. \n",
    "**ALWAYS** make sure you include, in the final answer, **ALL**  Markdown-formatted text collected in the last message, including citations and hyperlinks.\n",
    "Use wonderful formatted markdown answers.\"\"\"\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "# SYSTEM MESSAGE\n",
    "message_system = {\"role\": \"system\", \"content\": SYSTEM_MESSAGE}\n",
    "messages.append(message_system)\n",
    "\n",
    "# USER MESSAGE\n",
    "message_user = {\"role\": \"user\", \"content\": QUESTION}\n",
    "messages.append(message_user)\n",
    "\n",
    "printmd(f'<h1><span style=\"color:darkblue;\">Given this SYSTEM_MESSAGE...</h1>')\n",
    "printmd_indented(f'{message_system[\"content\"]}')\n",
    "\n",
    "printmd(f'<h1><span style=\"color:darkblue;\">...and your QUESTION...</h1>')\n",
    "printmd_indented(f'*<span style=\"font-size:larger;color:blue;\">{message_user[\"content\"]}</span>*')\n",
    "\n",
    "printmd(f'<h1><span style=\"color:darkblue;\">...now, the fun BEGINS!</h1>')\n",
    "\n",
    "keep_asking_completions = True\n",
    "\n",
    "cumulative_total_tokens = 0\n",
    "completion_count        = 1\n",
    "max_attempts            = 10 # we accept up to these attempts by completion\n",
    "attempt_nr              = 1\n",
    "\n",
    "while (attempt_nr <= max_attempts):\n",
    "    try:        \n",
    "        while keep_asking_completions: # run the below block until finish_reason='stop', or just the first time\n",
    "            totaltokens_toolcalls = 0\n",
    "            \n",
    "            if (attempt_nr == 1): # we use green color if this is the first attempt\n",
    "                printmd(f'<h2><span style=\"color:darkgreen;\">Creating completion request #{completion_count}...</h2>')\n",
    "            else: # we use purple color if this is NOT the first attempt\n",
    "                printmd(f'<h2><span style=\"color:purple;\">Creating completion request #{completion_count} *again* (attempt #{attempt_nr}) ...</h2>')\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model       = MODEL,\n",
    "                messages    = messages,\n",
    "                tools       = tools,\n",
    "                tool_choice = 'auto'\n",
    "            )            \n",
    "            \n",
    "            prompt_tokens     = response.usage.prompt_tokens\n",
    "            completion_tokens = response.usage.completion_tokens\n",
    "            total_tokens      = response.usage.total_tokens\n",
    "            totaltokens_toolcalls = totaltokens_toolcalls + total_tokens\n",
    "            \n",
    "            finish_reason = response.choices[0].finish_reason\n",
    "            \n",
    "            if completion_count==1: # print the steps just after the first call\n",
    "                # printmd_indented(f'<span style=\"color:darkgreen;\">{response.choices[0].message.content}</span><br/>')\n",
    "                if (finish_reason == \"stop\"):                    \n",
    "                    raise Exception(\"Error: first call to OpenAI didn't choose any tools to run\")\n",
    "                else:\n",
    "                    printmd_indented(response.choices[0].message.content)\n",
    "            \n",
    "\n",
    "            printmd(f'<span style=\"font-size:larger;color:orange;\">...which consumed **{prompt_tokens}** prompt + **{completion_tokens}** completion tokens (=**{total_tokens}** total tokens)<br/>and terminated with finish_reason = `{finish_reason}`')\n",
    "            \n",
    "            if finish_reason == \"stop\":\n",
    "                printmd(f'<h2><span style=\"color:darkgreen;\">Hooray! All completions were successfully executed. We have reached the end of the chain!</span></h2>')\n",
    "                keep_asking_completions = False\n",
    "                break # exit while: all calls terminated well and we have our final solution\n",
    "            \n",
    "            message_assistant = response.choices[0].message.model_dump()\n",
    "            message_assistant.pop('function_call') # <<<--- ASSISTANT MESSAGE IS READY, WE ADD IT IF ALL FUNCTIONS WORK WELL\n",
    "            \n",
    "            messages_toolcalls = [] # we need to create a \"tool\" message for each function in message_assistant.tool_calls\n",
    "            \n",
    "            printmd(f'<span style=\"font-size:larger;color:darkgreen;\">As a result, the assistant indentified `{len(message_assistant[\"tool_calls\"])} function(s)`, that I\\'m now going to run:</span>')\n",
    "            # printmd(f'<h2><span style=\"color:darkgreen;\">The assistant indentified **{len(message_assistant['tool_calls'])}** function(s), that I\\'m now going to run:</h2>')\n",
    "            function_nr = 1\n",
    "            for tc in message_assistant['tool_calls']:\n",
    "                    function_name = tc[\"function\"][\"name\"]\n",
    "                    function_args = json.loads(tc[\"function\"][\"arguments\"])\n",
    "                    \n",
    "                    printmd_indented (f'<span style=\"color:darkgreen;\">{function_nr}) Running function `{function_name}({function_args})` in completion `#{completion_count}`, that returns...</span>')\n",
    "                    function_resp = eval(function_name)(**function_args) # THIS IS THE CALL TO OUR LOCAL FUNCTIONS!\n",
    "                    printmd_indented (f'>...<span style=\"color:darkblue;\">{function_resp}</span><br/>')\n",
    "\n",
    "                    message_tool = {   \n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"tool_call_id\": tc[\"id\"],\n",
    "                        \"content\": function_resp\n",
    "                    }     \n",
    "                    messages_toolcalls.append(message_tool)\n",
    "                    function_nr = function_nr + 1\n",
    "                    \n",
    "            messages.append(message_assistant)\n",
    "            for mt in messages_toolcalls:\n",
    "                messages.append(mt)\n",
    "                \n",
    "            \n",
    "            # We are at the end of the completion, which executed all its functions without any errors    \n",
    "            cumulative_total_tokens = cumulative_total_tokens + totaltokens_toolcalls\n",
    "            completion_count = completion_count + 1\n",
    "            attempt_nr = 1 # here we reset the attempt number to allow max_attempts for each completion\n",
    "        \n",
    "        break # exit the attempts loop\n",
    "        \n",
    "    except Exception as e:\n",
    "        cumulative_total_tokens = cumulative_total_tokens + totaltokens_toolcalls\n",
    "        printmd_indented(f'><span style=\"color:red;\">The following error occurred in completion #{completion_count} during the execution of `{function_name}{function_args}`: `{e}`. I will now try the attempt #{attempt_nr+1}...</span>')\n",
    "        attempt_nr = attempt_nr + 1\n",
    "        keep_asking_completions = True\n",
    "\n",
    "if (attempt_nr<=max_attempts):    \n",
    "    printmd(f'<h1><span style=\"color:blue;\">Now I have the final answer, which used {cumulative_total_tokens} cumulative tokens</span></h1></span>')\n",
    "    printmd(response.choices[0].message.content)\n",
    "    printmd_indented((json.loads(messages[-1]['content']))['answer']) # for double testing, e.g. for checking markdown formatting\n",
    "else:\n",
    "    printmd(f'<h1><span style=\"color:red;\">Unfortunately, we exeeded the amount of allowed errors ({max_attempts}) in completion {completion_count}, so we couldn\\'t get to the final solution. Please analyze the erros, fix your tools and retry.</span></h1></span>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe34456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Use the `functions.search_in_internal_docs` function to search for examples of reinforcement learning in the 'cogsrch-index-files-vector-onestep' index.\n",
       "    - Reason: This function can retrieve information from a specific index within the internal documentation, which is suitable for finding examples of a given topic."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivbd_20231215",
   "language": "python",
   "name": "openaivbd_20231215"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
